{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import librosa\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ravdess_mfcc_40_chroma_def=pd.read_csv('audio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma3</th>\n",
       "      <th>chroma4</th>\n",
       "      <th>chroma5</th>\n",
       "      <th>chroma6</th>\n",
       "      <th>chroma7</th>\n",
       "      <th>chroma8</th>\n",
       "      <th>chroma9</th>\n",
       "      <th>chroma10</th>\n",
       "      <th>chroma11</th>\n",
       "      <th>chroma12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>03-01-01-01-01-01-01.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.598800</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>3435.943088</td>\n",
       "      <td>2600.929791</td>\n",
       "      <td>6264.656291</td>\n",
       "      <td>0.326237</td>\n",
       "      <td>-697.984245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570387</td>\n",
       "      <td>0.562410</td>\n",
       "      <td>0.551299</td>\n",
       "      <td>0.531241</td>\n",
       "      <td>0.589565</td>\n",
       "      <td>0.640624</td>\n",
       "      <td>0.644353</td>\n",
       "      <td>0.608717</td>\n",
       "      <td>0.611980</td>\n",
       "      <td>0.606167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>03-01-01-01-01-02-01.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.578452</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>3231.037280</td>\n",
       "      <td>2646.981271</td>\n",
       "      <td>6162.832642</td>\n",
       "      <td>0.340786</td>\n",
       "      <td>-693.069755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586752</td>\n",
       "      <td>0.530952</td>\n",
       "      <td>0.529118</td>\n",
       "      <td>0.552281</td>\n",
       "      <td>0.497320</td>\n",
       "      <td>0.549519</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.633122</td>\n",
       "      <td>0.632074</td>\n",
       "      <td>0.617527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>03-01-01-01-02-01-01.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.587585</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>3203.154528</td>\n",
       "      <td>2605.181241</td>\n",
       "      <td>6117.338659</td>\n",
       "      <td>0.356861</td>\n",
       "      <td>-691.770194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579290</td>\n",
       "      <td>0.590824</td>\n",
       "      <td>0.573292</td>\n",
       "      <td>0.528130</td>\n",
       "      <td>0.516716</td>\n",
       "      <td>0.578961</td>\n",
       "      <td>0.639646</td>\n",
       "      <td>0.640274</td>\n",
       "      <td>0.563098</td>\n",
       "      <td>0.562465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>03-01-01-01-02-02-01.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.573247</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>3080.483081</td>\n",
       "      <td>2644.191743</td>\n",
       "      <td>6094.210838</td>\n",
       "      <td>0.366200</td>\n",
       "      <td>-685.237871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518804</td>\n",
       "      <td>0.521994</td>\n",
       "      <td>0.584694</td>\n",
       "      <td>0.590593</td>\n",
       "      <td>0.537656</td>\n",
       "      <td>0.589734</td>\n",
       "      <td>0.611182</td>\n",
       "      <td>0.560056</td>\n",
       "      <td>0.568192</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>03-01-02-01-01-01-01.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.561084</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>3192.620354</td>\n",
       "      <td>2601.322629</td>\n",
       "      <td>6003.471105</td>\n",
       "      <td>0.313122</td>\n",
       "      <td>-727.317945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586327</td>\n",
       "      <td>0.547133</td>\n",
       "      <td>0.522434</td>\n",
       "      <td>0.539025</td>\n",
       "      <td>0.501785</td>\n",
       "      <td>0.554183</td>\n",
       "      <td>0.575118</td>\n",
       "      <td>0.618561</td>\n",
       "      <td>0.654716</td>\n",
       "      <td>0.552219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  label  emotion  chroma_stft_mean  rmse_mean  \\\n",
       "0  03-01-01-01-01-01-01.wav      1  neutral          0.598800   0.002257   \n",
       "1  03-01-01-01-01-02-01.wav      1  neutral          0.578452   0.002420   \n",
       "2  03-01-01-01-02-01-01.wav      1  neutral          0.587585   0.002810   \n",
       "3  03-01-01-01-02-02-01.wav      1  neutral          0.573247   0.002618   \n",
       "4  03-01-02-01-01-01-01.wav      2     calm          0.561084   0.001654   \n",
       "\n",
       "   spec_cent_mean  spec_bw_mean  rolloff_mean  zcr_mean       mfcc1  ...  \\\n",
       "0     3435.943088   2600.929791   6264.656291  0.326237 -697.984245  ...   \n",
       "1     3231.037280   2646.981271   6162.832642  0.340786 -693.069755  ...   \n",
       "2     3203.154528   2605.181241   6117.338659  0.356861 -691.770194  ...   \n",
       "3     3080.483081   2644.191743   6094.210838  0.366200 -685.237871  ...   \n",
       "4     3192.620354   2601.322629   6003.471105  0.313122 -727.317945  ...   \n",
       "\n",
       "    chroma3   chroma4   chroma5   chroma6   chroma7   chroma8   chroma9  \\\n",
       "0  0.570387  0.562410  0.551299  0.531241  0.589565  0.640624  0.644353   \n",
       "1  0.586752  0.530952  0.529118  0.552281  0.497320  0.549519  0.584854   \n",
       "2  0.579290  0.590824  0.573292  0.528130  0.516716  0.578961  0.639646   \n",
       "3  0.518804  0.521994  0.584694  0.590593  0.537656  0.589734  0.611182   \n",
       "4  0.586327  0.547133  0.522434  0.539025  0.501785  0.554183  0.575118   \n",
       "\n",
       "   chroma10  chroma11  chroma12  \n",
       "0  0.608717  0.611980  0.606167  \n",
       "1  0.633122  0.632074  0.617527  \n",
       "2  0.640274  0.563098  0.562465  \n",
       "3  0.560056  0.568192  0.592452  \n",
       "4  0.618561  0.654716  0.552219  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_ravdess_mfcc_40_chroma_def.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 61)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_ravdess_mfcc_40_chroma_def.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ravdess_mfcc_chroma_40=pd.read_csv('myexp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 89)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_ravdess_mfcc_chroma_40.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma31</th>\n",
       "      <th>chroma32</th>\n",
       "      <th>chroma33</th>\n",
       "      <th>chroma34</th>\n",
       "      <th>chroma35</th>\n",
       "      <th>chroma36</th>\n",
       "      <th>chroma37</th>\n",
       "      <th>chroma38</th>\n",
       "      <th>chroma39</th>\n",
       "      <th>chroma40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>03-01-03-02-01-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.385386</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>2592.308325</td>\n",
       "      <td>2360.097245</td>\n",
       "      <td>4995.771702</td>\n",
       "      <td>0.246548</td>\n",
       "      <td>-560.09265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464910</td>\n",
       "      <td>0.475772</td>\n",
       "      <td>0.437146</td>\n",
       "      <td>0.477294</td>\n",
       "      <td>0.468137</td>\n",
       "      <td>0.397129</td>\n",
       "      <td>0.374605</td>\n",
       "      <td>0.363818</td>\n",
       "      <td>0.353714</td>\n",
       "      <td>0.350808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>03-01-03-02-02-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.399802</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>3158.102896</td>\n",
       "      <td>2509.477352</td>\n",
       "      <td>5908.204274</td>\n",
       "      <td>0.304351</td>\n",
       "      <td>-539.44464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421390</td>\n",
       "      <td>0.443214</td>\n",
       "      <td>0.441170</td>\n",
       "      <td>0.453948</td>\n",
       "      <td>0.446627</td>\n",
       "      <td>0.423123</td>\n",
       "      <td>0.409154</td>\n",
       "      <td>0.380438</td>\n",
       "      <td>0.364385</td>\n",
       "      <td>0.329913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>03-01-03-01-02-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.432610</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>3155.010040</td>\n",
       "      <td>2500.076212</td>\n",
       "      <td>5856.358337</td>\n",
       "      <td>0.369135</td>\n",
       "      <td>-652.92870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398528</td>\n",
       "      <td>0.452733</td>\n",
       "      <td>0.453803</td>\n",
       "      <td>0.451015</td>\n",
       "      <td>0.450011</td>\n",
       "      <td>0.447997</td>\n",
       "      <td>0.456473</td>\n",
       "      <td>0.446581</td>\n",
       "      <td>0.428503</td>\n",
       "      <td>0.459803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>03-01-05-01-01-02-01.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.389468</td>\n",
       "      <td>0.009704</td>\n",
       "      <td>3435.518747</td>\n",
       "      <td>2619.287507</td>\n",
       "      <td>6348.558278</td>\n",
       "      <td>0.303829</td>\n",
       "      <td>-526.54034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422416</td>\n",
       "      <td>0.412361</td>\n",
       "      <td>0.386799</td>\n",
       "      <td>0.383563</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>0.372256</td>\n",
       "      <td>0.367946</td>\n",
       "      <td>0.360153</td>\n",
       "      <td>0.373736</td>\n",
       "      <td>0.369871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>03-01-08-01-02-02-01.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.491953</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>3524.545799</td>\n",
       "      <td>2647.952102</td>\n",
       "      <td>6432.624460</td>\n",
       "      <td>0.284329</td>\n",
       "      <td>-666.63245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530399</td>\n",
       "      <td>0.520594</td>\n",
       "      <td>0.468319</td>\n",
       "      <td>0.440439</td>\n",
       "      <td>0.431363</td>\n",
       "      <td>0.439305</td>\n",
       "      <td>0.463814</td>\n",
       "      <td>0.481968</td>\n",
       "      <td>0.456423</td>\n",
       "      <td>0.451458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  label    emotion  chroma_stft_mean  rmse_mean  \\\n",
       "0  03-01-03-02-01-02-01.wav      3      happy          0.385386   0.008209   \n",
       "1  03-01-03-02-02-02-01.wav      3      happy          0.399802   0.010222   \n",
       "2  03-01-03-01-02-02-01.wav      3      happy          0.432610   0.003754   \n",
       "3  03-01-05-01-01-02-01.wav      5      angry          0.389468   0.009704   \n",
       "4  03-01-08-01-02-02-01.wav      8  surprised          0.491953   0.003929   \n",
       "\n",
       "   spec_cent_mean  spec_bw_mean  rolloff_mean  zcr_mean      mfcc1  ...  \\\n",
       "0     2592.308325   2360.097245   4995.771702  0.246548 -560.09265  ...   \n",
       "1     3158.102896   2509.477352   5908.204274  0.304351 -539.44464  ...   \n",
       "2     3155.010040   2500.076212   5856.358337  0.369135 -652.92870  ...   \n",
       "3     3435.518747   2619.287507   6348.558278  0.303829 -526.54034  ...   \n",
       "4     3524.545799   2647.952102   6432.624460  0.284329 -666.63245  ...   \n",
       "\n",
       "   chroma31  chroma32  chroma33  chroma34  chroma35  chroma36  chroma37  \\\n",
       "0  0.464910  0.475772  0.437146  0.477294  0.468137  0.397129  0.374605   \n",
       "1  0.421390  0.443214  0.441170  0.453948  0.446627  0.423123  0.409154   \n",
       "2  0.398528  0.452733  0.453803  0.451015  0.450011  0.447997  0.456473   \n",
       "3  0.422416  0.412361  0.386799  0.383563  0.390801  0.372256  0.367946   \n",
       "4  0.530399  0.520594  0.468319  0.440439  0.431363  0.439305  0.463814   \n",
       "\n",
       "   chroma38  chroma39  chroma40  \n",
       "0  0.363818  0.353714  0.350808  \n",
       "1  0.380438  0.364385  0.329913  \n",
       "2  0.446581  0.428503  0.459803  \n",
       "3  0.360153  0.373736  0.369871  \n",
       "4  0.481968  0.456423  0.451458  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_ravdess_mfcc_chroma_40.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rav_sav_mfcc_chroma_40=pd.read_csv('myexpfinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 89)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rav_sav_mfcc_chroma_40.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma31</th>\n",
       "      <th>chroma32</th>\n",
       "      <th>chroma33</th>\n",
       "      <th>chroma34</th>\n",
       "      <th>chroma35</th>\n",
       "      <th>chroma36</th>\n",
       "      <th>chroma37</th>\n",
       "      <th>chroma38</th>\n",
       "      <th>chroma39</th>\n",
       "      <th>chroma40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>03-01-03-02-01-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.385386</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>2592.308325</td>\n",
       "      <td>2360.097245</td>\n",
       "      <td>4995.771702</td>\n",
       "      <td>0.246548</td>\n",
       "      <td>-560.09265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464910</td>\n",
       "      <td>0.475772</td>\n",
       "      <td>0.437146</td>\n",
       "      <td>0.477294</td>\n",
       "      <td>0.468137</td>\n",
       "      <td>0.397129</td>\n",
       "      <td>0.374605</td>\n",
       "      <td>0.363818</td>\n",
       "      <td>0.353714</td>\n",
       "      <td>0.350808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>03-01-03-02-02-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.399802</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>3158.102896</td>\n",
       "      <td>2509.477352</td>\n",
       "      <td>5908.204274</td>\n",
       "      <td>0.304351</td>\n",
       "      <td>-539.44464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>0.443214</td>\n",
       "      <td>0.441170</td>\n",
       "      <td>0.453948</td>\n",
       "      <td>0.446627</td>\n",
       "      <td>0.423123</td>\n",
       "      <td>0.409154</td>\n",
       "      <td>0.380438</td>\n",
       "      <td>0.364385</td>\n",
       "      <td>0.329913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>03-01-03-01-02-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.432610</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>3155.010040</td>\n",
       "      <td>2500.076212</td>\n",
       "      <td>5856.358337</td>\n",
       "      <td>0.369135</td>\n",
       "      <td>-652.92870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398528</td>\n",
       "      <td>0.452733</td>\n",
       "      <td>0.453803</td>\n",
       "      <td>0.451015</td>\n",
       "      <td>0.450011</td>\n",
       "      <td>0.447997</td>\n",
       "      <td>0.456473</td>\n",
       "      <td>0.446582</td>\n",
       "      <td>0.428503</td>\n",
       "      <td>0.459803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>03-01-05-01-01-02-01.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.389468</td>\n",
       "      <td>0.009704</td>\n",
       "      <td>3435.518747</td>\n",
       "      <td>2619.287507</td>\n",
       "      <td>6348.558278</td>\n",
       "      <td>0.303829</td>\n",
       "      <td>-526.54034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422416</td>\n",
       "      <td>0.412361</td>\n",
       "      <td>0.386799</td>\n",
       "      <td>0.383563</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>0.372256</td>\n",
       "      <td>0.367946</td>\n",
       "      <td>0.360153</td>\n",
       "      <td>0.373736</td>\n",
       "      <td>0.369871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>03-01-08-01-02-02-01.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.491953</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>3524.545799</td>\n",
       "      <td>2647.952102</td>\n",
       "      <td>6432.624460</td>\n",
       "      <td>0.284329</td>\n",
       "      <td>-666.63245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530399</td>\n",
       "      <td>0.520594</td>\n",
       "      <td>0.468319</td>\n",
       "      <td>0.440439</td>\n",
       "      <td>0.431363</td>\n",
       "      <td>0.439305</td>\n",
       "      <td>0.463814</td>\n",
       "      <td>0.481968</td>\n",
       "      <td>0.456423</td>\n",
       "      <td>0.451458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  label    emotion  chroma_stft_mean  rmse_mean  \\\n",
       "0  03-01-03-02-01-02-01.wav      3      happy          0.385386   0.008209   \n",
       "1  03-01-03-02-02-02-01.wav      3      happy          0.399802   0.010222   \n",
       "2  03-01-03-01-02-02-01.wav      3      happy          0.432610   0.003754   \n",
       "3  03-01-05-01-01-02-01.wav      5      angry          0.389468   0.009704   \n",
       "4  03-01-08-01-02-02-01.wav      8  surprised          0.491953   0.003929   \n",
       "\n",
       "   spec_cent_mean  spec_bw_mean  rolloff_mean  zcr_mean      mfcc1  ...  \\\n",
       "0     2592.308325   2360.097245   4995.771702  0.246548 -560.09265  ...   \n",
       "1     3158.102896   2509.477352   5908.204274  0.304351 -539.44464  ...   \n",
       "2     3155.010040   2500.076212   5856.358337  0.369135 -652.92870  ...   \n",
       "3     3435.518747   2619.287507   6348.558278  0.303829 -526.54034  ...   \n",
       "4     3524.545799   2647.952102   6432.624460  0.284329 -666.63245  ...   \n",
       "\n",
       "   chroma31  chroma32  chroma33  chroma34  chroma35  chroma36  chroma37  \\\n",
       "0  0.464910  0.475772  0.437146  0.477294  0.468137  0.397129  0.374605   \n",
       "1  0.421389  0.443214  0.441170  0.453948  0.446627  0.423123  0.409154   \n",
       "2  0.398528  0.452733  0.453803  0.451015  0.450011  0.447997  0.456473   \n",
       "3  0.422416  0.412361  0.386799  0.383563  0.390801  0.372256  0.367946   \n",
       "4  0.530399  0.520594  0.468319  0.440439  0.431363  0.439305  0.463814   \n",
       "\n",
       "   chroma38  chroma39  chroma40  \n",
       "0  0.363818  0.353714  0.350808  \n",
       "1  0.380438  0.364385  0.329913  \n",
       "2  0.446582  0.428503  0.459803  \n",
       "3  0.360153  0.373736  0.369871  \n",
       "4  0.481968  0.456423  0.451458  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rav_sav_mfcc_chroma_40.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_sav_mfcc_40_chroma_def=pd.read_csv('save.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 61)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_sav_mfcc_40_chroma_def.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma3</th>\n",
       "      <th>chroma4</th>\n",
       "      <th>chroma5</th>\n",
       "      <th>chroma6</th>\n",
       "      <th>chroma7</th>\n",
       "      <th>chroma8</th>\n",
       "      <th>chroma9</th>\n",
       "      <th>chroma10</th>\n",
       "      <th>chroma11</th>\n",
       "      <th>chroma12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a07.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.454161</td>\n",
       "      <td>0.219577</td>\n",
       "      <td>770.225570</td>\n",
       "      <td>1245.288464</td>\n",
       "      <td>1289.599609</td>\n",
       "      <td>0.014129</td>\n",
       "      <td>-310.76282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451283</td>\n",
       "      <td>0.532295</td>\n",
       "      <td>0.595957</td>\n",
       "      <td>0.585469</td>\n",
       "      <td>0.516790</td>\n",
       "      <td>0.472828</td>\n",
       "      <td>0.439147</td>\n",
       "      <td>0.379205</td>\n",
       "      <td>0.334979</td>\n",
       "      <td>0.369499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>su11.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.538299</td>\n",
       "      <td>0.124430</td>\n",
       "      <td>825.633466</td>\n",
       "      <td>1250.196555</td>\n",
       "      <td>1387.058989</td>\n",
       "      <td>0.013365</td>\n",
       "      <td>-374.00827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564124</td>\n",
       "      <td>0.609270</td>\n",
       "      <td>0.538288</td>\n",
       "      <td>0.526328</td>\n",
       "      <td>0.543785</td>\n",
       "      <td>0.556579</td>\n",
       "      <td>0.567067</td>\n",
       "      <td>0.560961</td>\n",
       "      <td>0.510373</td>\n",
       "      <td>0.461372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>h04.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.337713</td>\n",
       "      <td>0.199768</td>\n",
       "      <td>960.704483</td>\n",
       "      <td>1194.943258</td>\n",
       "      <td>1768.713379</td>\n",
       "      <td>0.020119</td>\n",
       "      <td>-283.00680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206731</td>\n",
       "      <td>0.241154</td>\n",
       "      <td>0.295855</td>\n",
       "      <td>0.345946</td>\n",
       "      <td>0.383043</td>\n",
       "      <td>0.354404</td>\n",
       "      <td>0.354393</td>\n",
       "      <td>0.401778</td>\n",
       "      <td>0.450322</td>\n",
       "      <td>0.436226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>d15.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.392497</td>\n",
       "      <td>0.094476</td>\n",
       "      <td>915.547283</td>\n",
       "      <td>1299.673530</td>\n",
       "      <td>1818.558757</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>-402.85272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475527</td>\n",
       "      <td>0.512193</td>\n",
       "      <td>0.450575</td>\n",
       "      <td>0.375740</td>\n",
       "      <td>0.357397</td>\n",
       "      <td>0.337109</td>\n",
       "      <td>0.310256</td>\n",
       "      <td>0.309857</td>\n",
       "      <td>0.310629</td>\n",
       "      <td>0.341707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>f15.wav</td>\n",
       "      <td>6</td>\n",
       "      <td>fearful</td>\n",
       "      <td>0.349216</td>\n",
       "      <td>0.180558</td>\n",
       "      <td>945.162458</td>\n",
       "      <td>1198.264363</td>\n",
       "      <td>1706.207275</td>\n",
       "      <td>0.014992</td>\n",
       "      <td>-317.88593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247705</td>\n",
       "      <td>0.278932</td>\n",
       "      <td>0.365006</td>\n",
       "      <td>0.551702</td>\n",
       "      <td>0.657871</td>\n",
       "      <td>0.574245</td>\n",
       "      <td>0.423041</td>\n",
       "      <td>0.272397</td>\n",
       "      <td>0.187965</td>\n",
       "      <td>0.183048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  label    emotion  chroma_stft_mean  rmse_mean  spec_cent_mean  \\\n",
       "0   a07.wav      5      angry          0.454161   0.219577      770.225570   \n",
       "1  su11.wav      8  surprised          0.538299   0.124430      825.633466   \n",
       "2   h04.wav      3      happy          0.337713   0.199768      960.704483   \n",
       "3   d15.wav      7    disgust          0.392497   0.094476      915.547283   \n",
       "4   f15.wav      6    fearful          0.349216   0.180558      945.162458   \n",
       "\n",
       "   spec_bw_mean  rolloff_mean  zcr_mean      mfcc1  ...   chroma3   chroma4  \\\n",
       "0   1245.288464   1289.599609  0.014129 -310.76282  ...  0.451283  0.532295   \n",
       "1   1250.196555   1387.058989  0.013365 -374.00827  ...  0.564124  0.609270   \n",
       "2   1194.943258   1768.713379  0.020119 -283.00680  ...  0.206731  0.241154   \n",
       "3   1299.673530   1818.558757  0.011486 -402.85272  ...  0.475527  0.512193   \n",
       "4   1198.264363   1706.207275  0.014992 -317.88593  ...  0.247705  0.278932   \n",
       "\n",
       "    chroma5   chroma6   chroma7   chroma8   chroma9  chroma10  chroma11  \\\n",
       "0  0.595957  0.585469  0.516790  0.472828  0.439147  0.379205  0.334979   \n",
       "1  0.538288  0.526328  0.543785  0.556579  0.567067  0.560961  0.510373   \n",
       "2  0.295855  0.345946  0.383043  0.354404  0.354393  0.401778  0.450322   \n",
       "3  0.450575  0.375740  0.357397  0.337109  0.310256  0.309857  0.310629   \n",
       "4  0.365006  0.551702  0.657871  0.574245  0.423041  0.272397  0.187965   \n",
       "\n",
       "   chroma12  \n",
       "0  0.369499  \n",
       "1  0.461372  \n",
       "2  0.436226  \n",
       "3  0.341707  \n",
       "4  0.183048  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_sav_mfcc_40_chroma_def.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_rav_sav_mfcc_40_chroma_def=pd.read_csv('rav_sav.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 61)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rav_sav_mfcc_40_chroma_def.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma3</th>\n",
       "      <th>chroma4</th>\n",
       "      <th>chroma5</th>\n",
       "      <th>chroma6</th>\n",
       "      <th>chroma7</th>\n",
       "      <th>chroma8</th>\n",
       "      <th>chroma9</th>\n",
       "      <th>chroma10</th>\n",
       "      <th>chroma11</th>\n",
       "      <th>chroma12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>03-01-01-01-01-01-01.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.598800</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>3435.943088</td>\n",
       "      <td>2600.929791</td>\n",
       "      <td>6264.656291</td>\n",
       "      <td>0.326237</td>\n",
       "      <td>-697.984245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570387</td>\n",
       "      <td>0.562410</td>\n",
       "      <td>0.551299</td>\n",
       "      <td>0.531241</td>\n",
       "      <td>0.589565</td>\n",
       "      <td>0.640624</td>\n",
       "      <td>0.644353</td>\n",
       "      <td>0.608717</td>\n",
       "      <td>0.611980</td>\n",
       "      <td>0.606167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>03-01-01-01-01-02-01.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.578452</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>3231.037280</td>\n",
       "      <td>2646.981271</td>\n",
       "      <td>6162.832642</td>\n",
       "      <td>0.340786</td>\n",
       "      <td>-693.069755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586752</td>\n",
       "      <td>0.530952</td>\n",
       "      <td>0.529118</td>\n",
       "      <td>0.552281</td>\n",
       "      <td>0.497320</td>\n",
       "      <td>0.549519</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.633122</td>\n",
       "      <td>0.632074</td>\n",
       "      <td>0.617527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>03-01-01-01-02-01-01.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.587585</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>3203.154528</td>\n",
       "      <td>2605.181241</td>\n",
       "      <td>6117.338659</td>\n",
       "      <td>0.356861</td>\n",
       "      <td>-691.770194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579290</td>\n",
       "      <td>0.590824</td>\n",
       "      <td>0.573292</td>\n",
       "      <td>0.528130</td>\n",
       "      <td>0.516716</td>\n",
       "      <td>0.578961</td>\n",
       "      <td>0.639646</td>\n",
       "      <td>0.640274</td>\n",
       "      <td>0.563098</td>\n",
       "      <td>0.562465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>03-01-01-01-02-02-01.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.573247</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>3080.483081</td>\n",
       "      <td>2644.191743</td>\n",
       "      <td>6094.210838</td>\n",
       "      <td>0.366200</td>\n",
       "      <td>-685.237871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518804</td>\n",
       "      <td>0.521994</td>\n",
       "      <td>0.584694</td>\n",
       "      <td>0.590593</td>\n",
       "      <td>0.537656</td>\n",
       "      <td>0.589734</td>\n",
       "      <td>0.611182</td>\n",
       "      <td>0.560056</td>\n",
       "      <td>0.568192</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>03-01-02-01-01-01-01.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.561084</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>3192.620354</td>\n",
       "      <td>2601.322629</td>\n",
       "      <td>6003.471105</td>\n",
       "      <td>0.313122</td>\n",
       "      <td>-727.317945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586327</td>\n",
       "      <td>0.547133</td>\n",
       "      <td>0.522434</td>\n",
       "      <td>0.539025</td>\n",
       "      <td>0.501785</td>\n",
       "      <td>0.554183</td>\n",
       "      <td>0.575118</td>\n",
       "      <td>0.618561</td>\n",
       "      <td>0.654716</td>\n",
       "      <td>0.552219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  label  emotion  chroma_stft_mean  rmse_mean  \\\n",
       "0  03-01-01-01-01-01-01.wav      1  neutral          0.598800   0.002257   \n",
       "1  03-01-01-01-01-02-01.wav      1  neutral          0.578452   0.002420   \n",
       "2  03-01-01-01-02-01-01.wav      1  neutral          0.587585   0.002810   \n",
       "3  03-01-01-01-02-02-01.wav      1  neutral          0.573247   0.002618   \n",
       "4  03-01-02-01-01-01-01.wav      2     calm          0.561084   0.001654   \n",
       "\n",
       "   spec_cent_mean  spec_bw_mean  rolloff_mean  zcr_mean       mfcc1  ...  \\\n",
       "0     3435.943088   2600.929791   6264.656291  0.326237 -697.984245  ...   \n",
       "1     3231.037280   2646.981271   6162.832642  0.340786 -693.069755  ...   \n",
       "2     3203.154528   2605.181241   6117.338659  0.356861 -691.770194  ...   \n",
       "3     3080.483081   2644.191743   6094.210838  0.366200 -685.237871  ...   \n",
       "4     3192.620354   2601.322629   6003.471105  0.313122 -727.317945  ...   \n",
       "\n",
       "    chroma3   chroma4   chroma5   chroma6   chroma7   chroma8   chroma9  \\\n",
       "0  0.570387  0.562410  0.551299  0.531241  0.589565  0.640624  0.644353   \n",
       "1  0.586752  0.530952  0.529118  0.552281  0.497320  0.549519  0.584854   \n",
       "2  0.579290  0.590824  0.573292  0.528130  0.516716  0.578961  0.639646   \n",
       "3  0.518804  0.521994  0.584694  0.590593  0.537656  0.589734  0.611182   \n",
       "4  0.586327  0.547133  0.522434  0.539025  0.501785  0.554183  0.575118   \n",
       "\n",
       "   chroma10  chroma11  chroma12  \n",
       "0  0.608717  0.611980  0.606167  \n",
       "1  0.633122  0.632074  0.617527  \n",
       "2  0.640274  0.563098  0.562465  \n",
       "3  0.560056  0.568192  0.592452  \n",
       "4  0.618561  0.654716  0.552219  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_rav_sav_mfcc_40_chroma_def.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVVEE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file with mfcc 40 features and chroma 12.\n",
    "data=file_sav_mfcc_40_chroma_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 61)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma3</th>\n",
       "      <th>chroma4</th>\n",
       "      <th>chroma5</th>\n",
       "      <th>chroma6</th>\n",
       "      <th>chroma7</th>\n",
       "      <th>chroma8</th>\n",
       "      <th>chroma9</th>\n",
       "      <th>chroma10</th>\n",
       "      <th>chroma11</th>\n",
       "      <th>chroma12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a07.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.454161</td>\n",
       "      <td>0.219577</td>\n",
       "      <td>770.225570</td>\n",
       "      <td>1245.288464</td>\n",
       "      <td>1289.599609</td>\n",
       "      <td>0.014129</td>\n",
       "      <td>-310.76282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451283</td>\n",
       "      <td>0.532295</td>\n",
       "      <td>0.595957</td>\n",
       "      <td>0.585469</td>\n",
       "      <td>0.516790</td>\n",
       "      <td>0.472828</td>\n",
       "      <td>0.439147</td>\n",
       "      <td>0.379205</td>\n",
       "      <td>0.334979</td>\n",
       "      <td>0.369499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>su11.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.538299</td>\n",
       "      <td>0.124430</td>\n",
       "      <td>825.633466</td>\n",
       "      <td>1250.196555</td>\n",
       "      <td>1387.058989</td>\n",
       "      <td>0.013365</td>\n",
       "      <td>-374.00827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564124</td>\n",
       "      <td>0.609270</td>\n",
       "      <td>0.538288</td>\n",
       "      <td>0.526328</td>\n",
       "      <td>0.543785</td>\n",
       "      <td>0.556579</td>\n",
       "      <td>0.567067</td>\n",
       "      <td>0.560961</td>\n",
       "      <td>0.510373</td>\n",
       "      <td>0.461372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>h04.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.337713</td>\n",
       "      <td>0.199768</td>\n",
       "      <td>960.704483</td>\n",
       "      <td>1194.943258</td>\n",
       "      <td>1768.713379</td>\n",
       "      <td>0.020119</td>\n",
       "      <td>-283.00680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206731</td>\n",
       "      <td>0.241154</td>\n",
       "      <td>0.295855</td>\n",
       "      <td>0.345946</td>\n",
       "      <td>0.383043</td>\n",
       "      <td>0.354404</td>\n",
       "      <td>0.354393</td>\n",
       "      <td>0.401778</td>\n",
       "      <td>0.450322</td>\n",
       "      <td>0.436226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>d15.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.392497</td>\n",
       "      <td>0.094476</td>\n",
       "      <td>915.547283</td>\n",
       "      <td>1299.673530</td>\n",
       "      <td>1818.558757</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>-402.85272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475527</td>\n",
       "      <td>0.512193</td>\n",
       "      <td>0.450575</td>\n",
       "      <td>0.375740</td>\n",
       "      <td>0.357397</td>\n",
       "      <td>0.337109</td>\n",
       "      <td>0.310256</td>\n",
       "      <td>0.309857</td>\n",
       "      <td>0.310629</td>\n",
       "      <td>0.341707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>f15.wav</td>\n",
       "      <td>6</td>\n",
       "      <td>fearful</td>\n",
       "      <td>0.349216</td>\n",
       "      <td>0.180558</td>\n",
       "      <td>945.162458</td>\n",
       "      <td>1198.264363</td>\n",
       "      <td>1706.207275</td>\n",
       "      <td>0.014992</td>\n",
       "      <td>-317.88593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247705</td>\n",
       "      <td>0.278932</td>\n",
       "      <td>0.365006</td>\n",
       "      <td>0.551702</td>\n",
       "      <td>0.657871</td>\n",
       "      <td>0.574245</td>\n",
       "      <td>0.423041</td>\n",
       "      <td>0.272397</td>\n",
       "      <td>0.187965</td>\n",
       "      <td>0.183048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  label    emotion  chroma_stft_mean  rmse_mean  spec_cent_mean  \\\n",
       "0   a07.wav      5      angry          0.454161   0.219577      770.225570   \n",
       "1  su11.wav      8  surprised          0.538299   0.124430      825.633466   \n",
       "2   h04.wav      3      happy          0.337713   0.199768      960.704483   \n",
       "3   d15.wav      7    disgust          0.392497   0.094476      915.547283   \n",
       "4   f15.wav      6    fearful          0.349216   0.180558      945.162458   \n",
       "\n",
       "   spec_bw_mean  rolloff_mean  zcr_mean      mfcc1  ...   chroma3   chroma4  \\\n",
       "0   1245.288464   1289.599609  0.014129 -310.76282  ...  0.451283  0.532295   \n",
       "1   1250.196555   1387.058989  0.013365 -374.00827  ...  0.564124  0.609270   \n",
       "2   1194.943258   1768.713379  0.020119 -283.00680  ...  0.206731  0.241154   \n",
       "3   1299.673530   1818.558757  0.011486 -402.85272  ...  0.475527  0.512193   \n",
       "4   1198.264363   1706.207275  0.014992 -317.88593  ...  0.247705  0.278932   \n",
       "\n",
       "    chroma5   chroma6   chroma7   chroma8   chroma9  chroma10  chroma11  \\\n",
       "0  0.595957  0.585469  0.516790  0.472828  0.439147  0.379205  0.334979   \n",
       "1  0.538288  0.526328  0.543785  0.556579  0.567067  0.560961  0.510373   \n",
       "2  0.295855  0.345946  0.383043  0.354404  0.354393  0.401778  0.450322   \n",
       "3  0.450575  0.375740  0.357397  0.337109  0.310256  0.309857  0.310629   \n",
       "4  0.365006  0.551702  0.657871  0.574245  0.423041  0.272397  0.187965   \n",
       "\n",
       "   chroma12  \n",
       "0  0.369499  \n",
       "1  0.461372  \n",
       "2  0.436226  \n",
       "3  0.341707  \n",
       "4  0.183048  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 61)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_copy.drop('name label emotion chroma_stft_mean'.split(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 57)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma3</th>\n",
       "      <th>chroma4</th>\n",
       "      <th>chroma5</th>\n",
       "      <th>chroma6</th>\n",
       "      <th>chroma7</th>\n",
       "      <th>chroma8</th>\n",
       "      <th>chroma9</th>\n",
       "      <th>chroma10</th>\n",
       "      <th>chroma11</th>\n",
       "      <th>chroma12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.219577</td>\n",
       "      <td>770.225570</td>\n",
       "      <td>1245.288464</td>\n",
       "      <td>1289.599609</td>\n",
       "      <td>0.014129</td>\n",
       "      <td>-310.76282</td>\n",
       "      <td>143.40866</td>\n",
       "      <td>4.784617</td>\n",
       "      <td>7.169190</td>\n",
       "      <td>16.058151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451283</td>\n",
       "      <td>0.532295</td>\n",
       "      <td>0.595957</td>\n",
       "      <td>0.585469</td>\n",
       "      <td>0.516790</td>\n",
       "      <td>0.472828</td>\n",
       "      <td>0.439147</td>\n",
       "      <td>0.379205</td>\n",
       "      <td>0.334979</td>\n",
       "      <td>0.369499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.124430</td>\n",
       "      <td>825.633466</td>\n",
       "      <td>1250.196555</td>\n",
       "      <td>1387.058989</td>\n",
       "      <td>0.013365</td>\n",
       "      <td>-374.00827</td>\n",
       "      <td>106.54099</td>\n",
       "      <td>11.895859</td>\n",
       "      <td>35.280777</td>\n",
       "      <td>26.597597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564124</td>\n",
       "      <td>0.609270</td>\n",
       "      <td>0.538288</td>\n",
       "      <td>0.526328</td>\n",
       "      <td>0.543785</td>\n",
       "      <td>0.556579</td>\n",
       "      <td>0.567067</td>\n",
       "      <td>0.560961</td>\n",
       "      <td>0.510373</td>\n",
       "      <td>0.461372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.199768</td>\n",
       "      <td>960.704483</td>\n",
       "      <td>1194.943258</td>\n",
       "      <td>1768.713379</td>\n",
       "      <td>0.020119</td>\n",
       "      <td>-283.00680</td>\n",
       "      <td>143.65929</td>\n",
       "      <td>15.440558</td>\n",
       "      <td>18.874882</td>\n",
       "      <td>19.533524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206731</td>\n",
       "      <td>0.241154</td>\n",
       "      <td>0.295855</td>\n",
       "      <td>0.345946</td>\n",
       "      <td>0.383043</td>\n",
       "      <td>0.354404</td>\n",
       "      <td>0.354393</td>\n",
       "      <td>0.401778</td>\n",
       "      <td>0.450322</td>\n",
       "      <td>0.436226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.094476</td>\n",
       "      <td>915.547283</td>\n",
       "      <td>1299.673530</td>\n",
       "      <td>1818.558757</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>-402.85272</td>\n",
       "      <td>151.47821</td>\n",
       "      <td>24.108850</td>\n",
       "      <td>46.296610</td>\n",
       "      <td>42.869415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475527</td>\n",
       "      <td>0.512193</td>\n",
       "      <td>0.450575</td>\n",
       "      <td>0.375740</td>\n",
       "      <td>0.357397</td>\n",
       "      <td>0.337109</td>\n",
       "      <td>0.310256</td>\n",
       "      <td>0.309857</td>\n",
       "      <td>0.310629</td>\n",
       "      <td>0.341707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.180558</td>\n",
       "      <td>945.162458</td>\n",
       "      <td>1198.264363</td>\n",
       "      <td>1706.207275</td>\n",
       "      <td>0.014992</td>\n",
       "      <td>-317.88593</td>\n",
       "      <td>131.78242</td>\n",
       "      <td>26.749844</td>\n",
       "      <td>28.435240</td>\n",
       "      <td>26.068851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247705</td>\n",
       "      <td>0.278932</td>\n",
       "      <td>0.365006</td>\n",
       "      <td>0.551702</td>\n",
       "      <td>0.657871</td>\n",
       "      <td>0.574245</td>\n",
       "      <td>0.423041</td>\n",
       "      <td>0.272397</td>\n",
       "      <td>0.187965</td>\n",
       "      <td>0.183048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rmse_mean  spec_cent_mean  spec_bw_mean  rolloff_mean  zcr_mean      mfcc1  \\\n",
       "0   0.219577      770.225570   1245.288464   1289.599609  0.014129 -310.76282   \n",
       "1   0.124430      825.633466   1250.196555   1387.058989  0.013365 -374.00827   \n",
       "2   0.199768      960.704483   1194.943258   1768.713379  0.020119 -283.00680   \n",
       "3   0.094476      915.547283   1299.673530   1818.558757  0.011486 -402.85272   \n",
       "4   0.180558      945.162458   1198.264363   1706.207275  0.014992 -317.88593   \n",
       "\n",
       "       mfcc2      mfcc3      mfcc4      mfcc5  ...   chroma3   chroma4  \\\n",
       "0  143.40866   4.784617   7.169190  16.058151  ...  0.451283  0.532295   \n",
       "1  106.54099  11.895859  35.280777  26.597597  ...  0.564124  0.609270   \n",
       "2  143.65929  15.440558  18.874882  19.533524  ...  0.206731  0.241154   \n",
       "3  151.47821  24.108850  46.296610  42.869415  ...  0.475527  0.512193   \n",
       "4  131.78242  26.749844  28.435240  26.068851  ...  0.247705  0.278932   \n",
       "\n",
       "    chroma5   chroma6   chroma7   chroma8   chroma9  chroma10  chroma11  \\\n",
       "0  0.595957  0.585469  0.516790  0.472828  0.439147  0.379205  0.334979   \n",
       "1  0.538288  0.526328  0.543785  0.556579  0.567067  0.560961  0.510373   \n",
       "2  0.295855  0.345946  0.383043  0.354404  0.354393  0.401778  0.450322   \n",
       "3  0.450575  0.375740  0.357397  0.337109  0.310256  0.309857  0.310629   \n",
       "4  0.365006  0.551702  0.657871  0.574245  0.423041  0.272397  0.187965   \n",
       "\n",
       "   chroma12  \n",
       "0  0.369499  \n",
       "1  0.461372  \n",
       "2  0.436226  \n",
       "3  0.341707  \n",
       "4  0.183048  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5\n",
       "1      8\n",
       "2      3\n",
       "3      7\n",
       "4      6\n",
       "      ..\n",
       "475    7\n",
       "476    1\n",
       "477    8\n",
       "478    8\n",
       "479    3\n",
       "Name: label, Length: 480, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,random_state=2,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 57)\n",
      "(96, 57)\n",
      "(384,)\n",
      "(96,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train=scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akansh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.fit(X_scaled_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=logistic.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy 70.83%\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Test Accuracy {:.2f}%\".format(logistic.score(X_scaled_test, Y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(criterion= 'entropy', n_estimators= 800, max_depth= 25, min_samples_split= 5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=25, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=800,\n",
       "                       n_jobs=None, oob_score=False, random_state=101,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_scaled_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pred = forest.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy 68.75%\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Test Accuracy {:.2f}%\".format(forest.score(X_scaled_test, Y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MLPClassifier(alpha=0.01, batch_size=16, epsilon=1e-08, hidden_layer_sizes=(600,), learning_rate='adaptive', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size=16, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(600,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_scaled_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=model.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_true=Y_test,y_pred=Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 1, 5, 4, 2, 0, 0, 1, 0, 4, 3, 5, 4, 5, 1, 0, 3, 2, 2, 2, 4,\n",
       "       0, 0, 0, 2, 6, 4, 0, 6, 3, 6, 5, 1, 6, 0, 1, 4, 1, 0, 6, 4, 4, 0,\n",
       "       0, 4, 6, 0, 3, 2, 1, 5, 0, 2, 1, 3, 6, 1, 0, 0, 4, 5, 0, 5, 3, 5,\n",
       "       2, 0, 6, 6, 3, 0, 2, 5, 0, 4, 6, 0, 5, 6, 1, 0, 4, 5, 0, 1, 1, 0,\n",
       "       0, 2, 4, 0, 0, 5, 0, 3, 2, 0, 3, 3, 3, 2, 1, 5, 4, 2, 3, 2, 3, 1,\n",
       "       5, 4, 3, 2, 6, 5, 0, 6, 6, 1, 3, 6, 1, 5, 4, 2, 0, 0, 1, 0, 4, 3,\n",
       "       5, 4, 5, 1, 0, 3, 2, 2, 2, 4, 0, 0, 0, 2, 6, 4, 0, 6, 3, 6, 5, 1,\n",
       "       6, 0, 1, 4, 1, 0, 6, 4, 4, 0, 0, 4, 6, 0, 3, 2, 1, 5, 0, 2, 1, 3,\n",
       "       6, 1, 0, 0, 4, 5, 0, 5, 3, 5, 2, 0, 6, 6, 3, 0, 2, 5, 0, 4, 6, 0,\n",
       "       5, 6, 1, 0, 4, 5, 0, 1, 1, 0, 0, 2, 4, 0, 0, 5, 0, 3, 2, 0, 3, 3,\n",
       "       3, 2, 1, 5, 4, 2, 3, 2, 3, 1, 5, 4, 3, 2, 6, 5, 0, 6, 6, 1, 3, 6,\n",
       "       1, 5, 4, 2, 0, 0, 1, 0, 4, 3, 5, 4, 5, 1, 0, 3, 2, 2, 2, 4, 0, 0,\n",
       "       0, 2, 6, 4, 0, 6, 3, 6, 5, 1, 6, 0, 1, 4, 1, 0, 6, 4, 4, 0, 0, 4,\n",
       "       6, 0, 3, 2, 1, 5, 0, 2, 1, 3, 6, 1, 0, 0, 4, 5, 0, 5, 3, 5, 2, 0,\n",
       "       6, 6, 3, 0, 2, 5, 0, 4, 6, 0, 5, 6, 1, 0, 4, 5, 0, 1, 1, 0, 0, 2,\n",
       "       4, 0, 0, 5, 0, 3, 2, 0, 3, 3, 3, 2, 1, 5, 4, 2, 3, 2, 3, 1, 5, 4,\n",
       "       3, 2, 6, 5, 0, 6, 6, 1, 3, 6, 1, 5, 4, 2, 0, 0, 1, 0, 4, 3, 5, 4,\n",
       "       5, 1, 0, 3, 2, 2, 2, 4, 0, 0, 0, 2, 6, 4, 0, 6, 3, 6, 5, 1, 6, 0,\n",
       "       1, 4, 1, 0, 6, 4, 4, 0, 0, 4, 6, 0, 3, 2, 1, 5, 0, 2, 1, 3, 6, 1,\n",
       "       0, 0, 4, 5, 0, 5, 3, 5, 2, 0, 6, 6, 3, 0, 2, 5, 0, 4, 6, 0, 5, 6,\n",
       "       1, 0, 4, 5, 0, 1, 1, 0, 0, 2, 4, 0, 0, 5, 0, 3, 2, 0, 3, 3, 3, 2,\n",
       "       1, 5, 4, 2, 3, 2, 3, 1, 5, 4, 3, 2, 6, 5, 0, 6, 6, 1])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tried the encoder of sklearn and compared with manual encoding. results had no huge difference.\n",
    "encoder = LabelEncoder()\n",
    "Y =  encoder.fit_transform(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cnn=data_copy.drop('name label emotion chroma_stft_mean rmse_mean spec_cent_mean spec_bw_mean rolloff_mean zcr_mean '.split(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 52)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480,)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn,X_test_cnn,Y_train_cnn,Y_test_cnn=train_test_split(X_cnn,Y,random_state=1,stratify=Y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train_cnn=scaler.fit_transform(X_train_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_test_cnn=scaler.transform(X_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_expanded_scaled_train_cnn = np.expand_dims(X_scaled_train_cnn, axis=2)\n",
    "X_expanded_scaled_test_cnn = np.expand_dims(X_scaled_test_cnn, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((384, 52, 1), (96, 52, 1))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_expanded_scaled_train_cnn.shape, X_expanded_scaled_test_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 8,padding='same',\n",
    "                 input_shape=(52,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(5)))\n",
    "model.add(Conv1D(256, 8,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(5)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr=0.00002, rho=0.9, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 384 samples, validate on 96 samples\n",
      "Epoch 1/700\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 2.0474 - accuracy: 0.2500 - val_loss: 2.0218 - val_accuracy: 0.2708\n",
      "Epoch 2/700\n",
      "384/384 [==============================] - 0s 940us/step - loss: 2.0136 - accuracy: 0.2760 - val_loss: 1.9957 - val_accuracy: 0.2708\n",
      "Epoch 3/700\n",
      "384/384 [==============================] - 0s 912us/step - loss: 1.9909 - accuracy: 0.2760 - val_loss: 1.9746 - val_accuracy: 0.2708\n",
      "Epoch 4/700\n",
      "384/384 [==============================] - 0s 897us/step - loss: 1.9677 - accuracy: 0.2760 - val_loss: 1.9543 - val_accuracy: 0.2708\n",
      "Epoch 5/700\n",
      "384/384 [==============================] - 0s 946us/step - loss: 1.9477 - accuracy: 0.2839 - val_loss: 1.9335 - val_accuracy: 0.2708\n",
      "Epoch 6/700\n",
      "384/384 [==============================] - 0s 916us/step - loss: 1.9317 - accuracy: 0.2891 - val_loss: 1.9133 - val_accuracy: 0.2917\n",
      "Epoch 7/700\n",
      "384/384 [==============================] - 0s 977us/step - loss: 1.9013 - accuracy: 0.2865 - val_loss: 1.8931 - val_accuracy: 0.3229\n",
      "Epoch 8/700\n",
      "384/384 [==============================] - 0s 925us/step - loss: 1.8819 - accuracy: 0.3333 - val_loss: 1.8735 - val_accuracy: 0.3229\n",
      "Epoch 9/700\n",
      "384/384 [==============================] - 0s 949us/step - loss: 1.8604 - accuracy: 0.3125 - val_loss: 1.8541 - val_accuracy: 0.3229\n",
      "Epoch 10/700\n",
      "384/384 [==============================] - 0s 952us/step - loss: 1.8569 - accuracy: 0.3177 - val_loss: 1.8359 - val_accuracy: 0.3229\n",
      "Epoch 11/700\n",
      "384/384 [==============================] - 0s 908us/step - loss: 1.8301 - accuracy: 0.3438 - val_loss: 1.8160 - val_accuracy: 0.3333\n",
      "Epoch 12/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1.8065 - accuracy: 0.3490 - val_loss: 1.7963 - val_accuracy: 0.3333\n",
      "Epoch 13/700\n",
      "384/384 [==============================] - 0s 920us/step - loss: 1.7868 - accuracy: 0.3568 - val_loss: 1.7775 - val_accuracy: 0.3542\n",
      "Epoch 14/700\n",
      "384/384 [==============================] - 0s 951us/step - loss: 1.7782 - accuracy: 0.3672 - val_loss: 1.7598 - val_accuracy: 0.3646\n",
      "Epoch 15/700\n",
      "384/384 [==============================] - 0s 960us/step - loss: 1.7525 - accuracy: 0.3776 - val_loss: 1.7414 - val_accuracy: 0.3542\n",
      "Epoch 16/700\n",
      "384/384 [==============================] - 0s 984us/step - loss: 1.7359 - accuracy: 0.4010 - val_loss: 1.7234 - val_accuracy: 0.3646\n",
      "Epoch 17/700\n",
      "384/384 [==============================] - 0s 903us/step - loss: 1.7176 - accuracy: 0.4062 - val_loss: 1.7068 - val_accuracy: 0.3646\n",
      "Epoch 18/700\n",
      "384/384 [==============================] - 0s 981us/step - loss: 1.7099 - accuracy: 0.3984 - val_loss: 1.6900 - val_accuracy: 0.3750\n",
      "Epoch 19/700\n",
      "384/384 [==============================] - 0s 950us/step - loss: 1.6898 - accuracy: 0.4115 - val_loss: 1.6731 - val_accuracy: 0.3542\n",
      "Epoch 20/700\n",
      "384/384 [==============================] - 0s 964us/step - loss: 1.6815 - accuracy: 0.4089 - val_loss: 1.6568 - val_accuracy: 0.3854\n",
      "Epoch 21/700\n",
      "384/384 [==============================] - 0s 925us/step - loss: 1.6642 - accuracy: 0.4219 - val_loss: 1.6408 - val_accuracy: 0.3854\n",
      "Epoch 22/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1.6359 - accuracy: 0.4349 - val_loss: 1.6248 - val_accuracy: 0.3854\n",
      "Epoch 23/700\n",
      "384/384 [==============================] - 0s 907us/step - loss: 1.6239 - accuracy: 0.4349 - val_loss: 1.6095 - val_accuracy: 0.3854\n",
      "Epoch 24/700\n",
      "384/384 [==============================] - 0s 960us/step - loss: 1.6062 - accuracy: 0.4193 - val_loss: 1.5947 - val_accuracy: 0.3854\n",
      "Epoch 25/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 1.6008 - accuracy: 0.4271 - val_loss: 1.5810 - val_accuracy: 0.3854\n",
      "Epoch 26/700\n",
      "384/384 [==============================] - 0s 919us/step - loss: 1.5795 - accuracy: 0.4505 - val_loss: 1.5656 - val_accuracy: 0.3854\n",
      "Epoch 27/700\n",
      "384/384 [==============================] - 0s 984us/step - loss: 1.5634 - accuracy: 0.4323 - val_loss: 1.5526 - val_accuracy: 0.3854\n",
      "Epoch 28/700\n",
      "384/384 [==============================] - 0s 935us/step - loss: 1.5561 - accuracy: 0.4479 - val_loss: 1.5386 - val_accuracy: 0.3958\n",
      "Epoch 29/700\n",
      "384/384 [==============================] - 0s 948us/step - loss: 1.5377 - accuracy: 0.4479 - val_loss: 1.5249 - val_accuracy: 0.3958\n",
      "Epoch 30/700\n",
      "384/384 [==============================] - 0s 924us/step - loss: 1.5157 - accuracy: 0.4766 - val_loss: 1.5114 - val_accuracy: 0.3854\n",
      "Epoch 31/700\n",
      "384/384 [==============================] - 0s 961us/step - loss: 1.5047 - accuracy: 0.4557 - val_loss: 1.5004 - val_accuracy: 0.3958\n",
      "Epoch 32/700\n",
      "384/384 [==============================] - 0s 905us/step - loss: 1.4917 - accuracy: 0.4505 - val_loss: 1.4883 - val_accuracy: 0.4062\n",
      "Epoch 33/700\n",
      "384/384 [==============================] - 0s 961us/step - loss: 1.4636 - accuracy: 0.4609 - val_loss: 1.4781 - val_accuracy: 0.3958\n",
      "Epoch 34/700\n",
      "384/384 [==============================] - 0s 925us/step - loss: 1.4964 - accuracy: 0.4583 - val_loss: 1.4686 - val_accuracy: 0.4062\n",
      "Epoch 35/700\n",
      "384/384 [==============================] - 0s 949us/step - loss: 1.4703 - accuracy: 0.4427 - val_loss: 1.4593 - val_accuracy: 0.3958\n",
      "Epoch 36/700\n",
      "384/384 [==============================] - 0s 941us/step - loss: 1.4476 - accuracy: 0.4896 - val_loss: 1.4485 - val_accuracy: 0.4062\n",
      "Epoch 37/700\n",
      "384/384 [==============================] - 0s 948us/step - loss: 1.4499 - accuracy: 0.4792 - val_loss: 1.4393 - val_accuracy: 0.4062\n",
      "Epoch 38/700\n",
      "384/384 [==============================] - 0s 923us/step - loss: 1.4304 - accuracy: 0.4896 - val_loss: 1.4298 - val_accuracy: 0.3958\n",
      "Epoch 39/700\n",
      "384/384 [==============================] - 0s 937us/step - loss: 1.4280 - accuracy: 0.4635 - val_loss: 1.4215 - val_accuracy: 0.4062\n",
      "Epoch 40/700\n",
      "384/384 [==============================] - 0s 921us/step - loss: 1.4027 - accuracy: 0.5000 - val_loss: 1.4142 - val_accuracy: 0.3958\n",
      "Epoch 41/700\n",
      "384/384 [==============================] - 0s 941us/step - loss: 1.4161 - accuracy: 0.4740 - val_loss: 1.4064 - val_accuracy: 0.4062\n",
      "Epoch 42/700\n",
      "384/384 [==============================] - 0s 928us/step - loss: 1.3877 - accuracy: 0.4896 - val_loss: 1.3989 - val_accuracy: 0.4167\n",
      "Epoch 43/700\n",
      "384/384 [==============================] - 0s 940us/step - loss: 1.3719 - accuracy: 0.5000 - val_loss: 1.3919 - val_accuracy: 0.3958\n",
      "Epoch 44/700\n",
      "384/384 [==============================] - 0s 941us/step - loss: 1.3680 - accuracy: 0.5000 - val_loss: 1.3840 - val_accuracy: 0.4271\n",
      "Epoch 45/700\n",
      "384/384 [==============================] - 0s 944us/step - loss: 1.3732 - accuracy: 0.4688 - val_loss: 1.3777 - val_accuracy: 0.4167\n",
      "Epoch 46/700\n",
      "384/384 [==============================] - 0s 927us/step - loss: 1.3799 - accuracy: 0.4818 - val_loss: 1.3704 - val_accuracy: 0.4167\n",
      "Epoch 47/700\n",
      "384/384 [==============================] - 0s 947us/step - loss: 1.3693 - accuracy: 0.4948 - val_loss: 1.3656 - val_accuracy: 0.4167\n",
      "Epoch 48/700\n",
      "384/384 [==============================] - 0s 929us/step - loss: 1.3259 - accuracy: 0.5312 - val_loss: 1.3603 - val_accuracy: 0.4167\n",
      "Epoch 49/700\n",
      "384/384 [==============================] - 0s 931us/step - loss: 1.3304 - accuracy: 0.4922 - val_loss: 1.3548 - val_accuracy: 0.4271\n",
      "Epoch 50/700\n",
      "384/384 [==============================] - 0s 914us/step - loss: 1.3387 - accuracy: 0.4922 - val_loss: 1.3502 - val_accuracy: 0.4167\n",
      "Epoch 51/700\n",
      "384/384 [==============================] - 0s 963us/step - loss: 1.3163 - accuracy: 0.5130 - val_loss: 1.3459 - val_accuracy: 0.4167\n",
      "Epoch 52/700\n",
      "384/384 [==============================] - 0s 930us/step - loss: 1.3063 - accuracy: 0.5469 - val_loss: 1.3374 - val_accuracy: 0.4375\n",
      "Epoch 53/700\n",
      "384/384 [==============================] - 0s 951us/step - loss: 1.3137 - accuracy: 0.5000 - val_loss: 1.3337 - val_accuracy: 0.4375\n",
      "Epoch 54/700\n",
      "384/384 [==============================] - 0s 919us/step - loss: 1.2781 - accuracy: 0.5469 - val_loss: 1.3280 - val_accuracy: 0.4479\n",
      "Epoch 55/700\n",
      "384/384 [==============================] - 0s 956us/step - loss: 1.2837 - accuracy: 0.5130 - val_loss: 1.3229 - val_accuracy: 0.4271\n",
      "Epoch 56/700\n",
      "384/384 [==============================] - 0s 944us/step - loss: 1.2840 - accuracy: 0.5312 - val_loss: 1.3156 - val_accuracy: 0.4271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 1.2600 - accuracy: 0.5260 - val_loss: 1.3139 - val_accuracy: 0.4375\n",
      "Epoch 58/700\n",
      "384/384 [==============================] - 0s 857us/step - loss: 1.2745 - accuracy: 0.5495 - val_loss: 1.3076 - val_accuracy: 0.4375\n",
      "Epoch 59/700\n",
      "384/384 [==============================] - 0s 840us/step - loss: 1.2643 - accuracy: 0.5312 - val_loss: 1.3058 - val_accuracy: 0.4479\n",
      "Epoch 60/700\n",
      "384/384 [==============================] - 0s 845us/step - loss: 1.2480 - accuracy: 0.5339 - val_loss: 1.2993 - val_accuracy: 0.4375\n",
      "Epoch 61/700\n",
      "384/384 [==============================] - 0s 897us/step - loss: 1.2691 - accuracy: 0.5182 - val_loss: 1.2970 - val_accuracy: 0.4271\n",
      "Epoch 62/700\n",
      "384/384 [==============================] - 0s 860us/step - loss: 1.2544 - accuracy: 0.5260 - val_loss: 1.2908 - val_accuracy: 0.4271\n",
      "Epoch 63/700\n",
      "384/384 [==============================] - 0s 875us/step - loss: 1.2567 - accuracy: 0.5078 - val_loss: 1.2852 - val_accuracy: 0.4479\n",
      "Epoch 64/700\n",
      "384/384 [==============================] - 0s 855us/step - loss: 1.2597 - accuracy: 0.5365 - val_loss: 1.2857 - val_accuracy: 0.4375\n",
      "Epoch 65/700\n",
      "384/384 [==============================] - 0s 850us/step - loss: 1.2276 - accuracy: 0.5365 - val_loss: 1.2834 - val_accuracy: 0.4479\n",
      "Epoch 66/700\n",
      "384/384 [==============================] - 0s 816us/step - loss: 1.2500 - accuracy: 0.5443 - val_loss: 1.2808 - val_accuracy: 0.4479\n",
      "Epoch 67/700\n",
      "384/384 [==============================] - 0s 891us/step - loss: 1.2158 - accuracy: 0.5547 - val_loss: 1.2768 - val_accuracy: 0.4479\n",
      "Epoch 68/700\n",
      "384/384 [==============================] - 0s 850us/step - loss: 1.2146 - accuracy: 0.5703 - val_loss: 1.2741 - val_accuracy: 0.4375\n",
      "Epoch 69/700\n",
      "384/384 [==============================] - 0s 892us/step - loss: 1.2146 - accuracy: 0.5469 - val_loss: 1.2708 - val_accuracy: 0.4479\n",
      "Epoch 70/700\n",
      "384/384 [==============================] - 0s 861us/step - loss: 1.2180 - accuracy: 0.5495 - val_loss: 1.2663 - val_accuracy: 0.4375\n",
      "Epoch 71/700\n",
      "384/384 [==============================] - 0s 888us/step - loss: 1.2014 - accuracy: 0.5469 - val_loss: 1.2640 - val_accuracy: 0.4271\n",
      "Epoch 72/700\n",
      "384/384 [==============================] - 0s 813us/step - loss: 1.2076 - accuracy: 0.5547 - val_loss: 1.2565 - val_accuracy: 0.4479\n",
      "Epoch 73/700\n",
      "384/384 [==============================] - 0s 868us/step - loss: 1.2094 - accuracy: 0.5391 - val_loss: 1.2571 - val_accuracy: 0.4271\n",
      "Epoch 74/700\n",
      "384/384 [==============================] - 0s 851us/step - loss: 1.2044 - accuracy: 0.5469 - val_loss: 1.2536 - val_accuracy: 0.4271\n",
      "Epoch 75/700\n",
      "384/384 [==============================] - 0s 843us/step - loss: 1.1775 - accuracy: 0.5443 - val_loss: 1.2479 - val_accuracy: 0.4688\n",
      "Epoch 76/700\n",
      "384/384 [==============================] - 0s 869us/step - loss: 1.1799 - accuracy: 0.5859 - val_loss: 1.2451 - val_accuracy: 0.4583\n",
      "Epoch 77/700\n",
      "384/384 [==============================] - 0s 865us/step - loss: 1.1568 - accuracy: 0.5417 - val_loss: 1.2429 - val_accuracy: 0.4583\n",
      "Epoch 78/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 1.1794 - accuracy: 0.5495 - val_loss: 1.2436 - val_accuracy: 0.4688\n",
      "Epoch 79/700\n",
      "384/384 [==============================] - 0s 881us/step - loss: 1.1415 - accuracy: 0.5729 - val_loss: 1.2422 - val_accuracy: 0.4583\n",
      "Epoch 80/700\n",
      "384/384 [==============================] - 0s 875us/step - loss: 1.1498 - accuracy: 0.5573 - val_loss: 1.2377 - val_accuracy: 0.4583\n",
      "Epoch 81/700\n",
      "384/384 [==============================] - 0s 863us/step - loss: 1.1313 - accuracy: 0.5911 - val_loss: 1.2308 - val_accuracy: 0.4792\n",
      "Epoch 82/700\n",
      "384/384 [==============================] - 0s 900us/step - loss: 1.1624 - accuracy: 0.5625 - val_loss: 1.2300 - val_accuracy: 0.4792\n",
      "Epoch 83/700\n",
      "384/384 [==============================] - 0s 861us/step - loss: 1.1401 - accuracy: 0.5807 - val_loss: 1.2251 - val_accuracy: 0.4688\n",
      "Epoch 84/700\n",
      "384/384 [==============================] - 0s 849us/step - loss: 1.1490 - accuracy: 0.5599 - val_loss: 1.2201 - val_accuracy: 0.4688\n",
      "Epoch 85/700\n",
      "384/384 [==============================] - 0s 852us/step - loss: 1.1136 - accuracy: 0.6042 - val_loss: 1.2207 - val_accuracy: 0.4375\n",
      "Epoch 86/700\n",
      "384/384 [==============================] - 0s 905us/step - loss: 1.1422 - accuracy: 0.5599 - val_loss: 1.2159 - val_accuracy: 0.4583\n",
      "Epoch 87/700\n",
      "384/384 [==============================] - 0s 858us/step - loss: 1.1125 - accuracy: 0.5911 - val_loss: 1.2155 - val_accuracy: 0.4792\n",
      "Epoch 88/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 1.1020 - accuracy: 0.5938 - val_loss: 1.2129 - val_accuracy: 0.4479\n",
      "Epoch 89/700\n",
      "384/384 [==============================] - 0s 843us/step - loss: 1.1013 - accuracy: 0.6068 - val_loss: 1.2110 - val_accuracy: 0.4896\n",
      "Epoch 90/700\n",
      "384/384 [==============================] - 0s 900us/step - loss: 1.1022 - accuracy: 0.5938 - val_loss: 1.2084 - val_accuracy: 0.4792\n",
      "Epoch 91/700\n",
      "384/384 [==============================] - 0s 896us/step - loss: 1.0945 - accuracy: 0.5859 - val_loss: 1.2053 - val_accuracy: 0.5000\n",
      "Epoch 92/700\n",
      "384/384 [==============================] - 0s 878us/step - loss: 1.0841 - accuracy: 0.6042 - val_loss: 1.2058 - val_accuracy: 0.4792\n",
      "Epoch 93/700\n",
      "384/384 [==============================] - 0s 827us/step - loss: 1.1178 - accuracy: 0.5703 - val_loss: 1.1972 - val_accuracy: 0.5000\n",
      "Epoch 94/700\n",
      "384/384 [==============================] - 0s 903us/step - loss: 1.0839 - accuracy: 0.5911 - val_loss: 1.1978 - val_accuracy: 0.4896\n",
      "Epoch 95/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 1.1064 - accuracy: 0.5755 - val_loss: 1.1944 - val_accuracy: 0.4896\n",
      "Epoch 96/700\n",
      "384/384 [==============================] - 0s 864us/step - loss: 1.0806 - accuracy: 0.5755 - val_loss: 1.1897 - val_accuracy: 0.5000\n",
      "Epoch 97/700\n",
      "384/384 [==============================] - 0s 849us/step - loss: 1.0834 - accuracy: 0.6068 - val_loss: 1.1851 - val_accuracy: 0.5000\n",
      "Epoch 98/700\n",
      "384/384 [==============================] - 0s 867us/step - loss: 1.0958 - accuracy: 0.5990 - val_loss: 1.1837 - val_accuracy: 0.4792\n",
      "Epoch 99/700\n",
      "384/384 [==============================] - 0s 867us/step - loss: 1.0982 - accuracy: 0.5755 - val_loss: 1.1858 - val_accuracy: 0.5000\n",
      "Epoch 100/700\n",
      "384/384 [==============================] - 0s 885us/step - loss: 1.0794 - accuracy: 0.5938 - val_loss: 1.1849 - val_accuracy: 0.4896\n",
      "Epoch 101/700\n",
      "384/384 [==============================] - 0s 875us/step - loss: 1.0653 - accuracy: 0.5885 - val_loss: 1.1842 - val_accuracy: 0.4792\n",
      "Epoch 102/700\n",
      "384/384 [==============================] - 0s 870us/step - loss: 1.0523 - accuracy: 0.6120 - val_loss: 1.1830 - val_accuracy: 0.4896\n",
      "Epoch 103/700\n",
      "384/384 [==============================] - 0s 878us/step - loss: 1.0231 - accuracy: 0.6094 - val_loss: 1.1786 - val_accuracy: 0.4896\n",
      "Epoch 104/700\n",
      "384/384 [==============================] - 0s 889us/step - loss: 1.0503 - accuracy: 0.6250 - val_loss: 1.1796 - val_accuracy: 0.4896\n",
      "Epoch 105/700\n",
      "384/384 [==============================] - 0s 902us/step - loss: 1.0469 - accuracy: 0.6328 - val_loss: 1.1668 - val_accuracy: 0.5000\n",
      "Epoch 106/700\n",
      "384/384 [==============================] - 0s 846us/step - loss: 1.0484 - accuracy: 0.6094 - val_loss: 1.1740 - val_accuracy: 0.5000\n",
      "Epoch 107/700\n",
      "384/384 [==============================] - 0s 886us/step - loss: 1.0289 - accuracy: 0.6276 - val_loss: 1.1657 - val_accuracy: 0.5000\n",
      "Epoch 108/700\n",
      "384/384 [==============================] - 0s 862us/step - loss: 1.0374 - accuracy: 0.6120 - val_loss: 1.1602 - val_accuracy: 0.4792\n",
      "Epoch 109/700\n",
      "384/384 [==============================] - 0s 900us/step - loss: 1.0328 - accuracy: 0.6276 - val_loss: 1.1649 - val_accuracy: 0.4896\n",
      "Epoch 110/700\n",
      "384/384 [==============================] - 0s 892us/step - loss: 1.0172 - accuracy: 0.6042 - val_loss: 1.1652 - val_accuracy: 0.4792\n",
      "Epoch 111/700\n",
      "384/384 [==============================] - 0s 919us/step - loss: 1.0113 - accuracy: 0.6120 - val_loss: 1.1557 - val_accuracy: 0.4792\n",
      "Epoch 112/700\n",
      "384/384 [==============================] - 0s 862us/step - loss: 1.0149 - accuracy: 0.6328 - val_loss: 1.1610 - val_accuracy: 0.4688\n",
      "Epoch 113/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 0s 857us/step - loss: 1.0063 - accuracy: 0.6432 - val_loss: 1.1559 - val_accuracy: 0.4792\n",
      "Epoch 114/700\n",
      "384/384 [==============================] - 0s 853us/step - loss: 1.0034 - accuracy: 0.6250 - val_loss: 1.1514 - val_accuracy: 0.4896\n",
      "Epoch 115/700\n",
      "384/384 [==============================] - 0s 907us/step - loss: 0.9993 - accuracy: 0.6354 - val_loss: 1.1472 - val_accuracy: 0.4896\n",
      "Epoch 116/700\n",
      "384/384 [==============================] - 0s 854us/step - loss: 1.0059 - accuracy: 0.6094 - val_loss: 1.1501 - val_accuracy: 0.4896\n",
      "Epoch 117/700\n",
      "384/384 [==============================] - 0s 894us/step - loss: 0.9960 - accuracy: 0.6328 - val_loss: 1.1494 - val_accuracy: 0.4896\n",
      "Epoch 118/700\n",
      "384/384 [==============================] - 0s 835us/step - loss: 0.9899 - accuracy: 0.6354 - val_loss: 1.1451 - val_accuracy: 0.4688\n",
      "Epoch 119/700\n",
      "384/384 [==============================] - 0s 881us/step - loss: 1.0088 - accuracy: 0.6120 - val_loss: 1.1440 - val_accuracy: 0.4792\n",
      "Epoch 120/700\n",
      "384/384 [==============================] - 0s 861us/step - loss: 1.0036 - accuracy: 0.6354 - val_loss: 1.1361 - val_accuracy: 0.4896\n",
      "Epoch 121/700\n",
      "384/384 [==============================] - 0s 881us/step - loss: 0.9859 - accuracy: 0.6302 - val_loss: 1.1354 - val_accuracy: 0.4896\n",
      "Epoch 122/700\n",
      "384/384 [==============================] - 0s 860us/step - loss: 0.9559 - accuracy: 0.6536 - val_loss: 1.1319 - val_accuracy: 0.4896\n",
      "Epoch 123/700\n",
      "384/384 [==============================] - 0s 890us/step - loss: 0.9548 - accuracy: 0.6589 - val_loss: 1.1300 - val_accuracy: 0.4896\n",
      "Epoch 124/700\n",
      "384/384 [==============================] - 0s 863us/step - loss: 0.9977 - accuracy: 0.6302 - val_loss: 1.1280 - val_accuracy: 0.5000\n",
      "Epoch 125/700\n",
      "384/384 [==============================] - 0s 898us/step - loss: 0.9689 - accuracy: 0.6484 - val_loss: 1.1262 - val_accuracy: 0.4896\n",
      "Epoch 126/700\n",
      "384/384 [==============================] - 0s 861us/step - loss: 0.9784 - accuracy: 0.6562 - val_loss: 1.1255 - val_accuracy: 0.5000\n",
      "Epoch 127/700\n",
      "384/384 [==============================] - 0s 883us/step - loss: 0.9675 - accuracy: 0.6406 - val_loss: 1.1219 - val_accuracy: 0.5000\n",
      "Epoch 128/700\n",
      "384/384 [==============================] - 0s 876us/step - loss: 0.9715 - accuracy: 0.6354 - val_loss: 1.1181 - val_accuracy: 0.5000\n",
      "Epoch 129/700\n",
      "384/384 [==============================] - 0s 876us/step - loss: 0.9772 - accuracy: 0.6432 - val_loss: 1.1195 - val_accuracy: 0.4896\n",
      "Epoch 130/700\n",
      "384/384 [==============================] - 0s 875us/step - loss: 0.9216 - accuracy: 0.6719 - val_loss: 1.1194 - val_accuracy: 0.5104\n",
      "Epoch 131/700\n",
      "384/384 [==============================] - 0s 835us/step - loss: 0.9240 - accuracy: 0.6849 - val_loss: 1.1196 - val_accuracy: 0.5104\n",
      "Epoch 132/700\n",
      "384/384 [==============================] - 0s 874us/step - loss: 0.9466 - accuracy: 0.6615 - val_loss: 1.1221 - val_accuracy: 0.5000\n",
      "Epoch 133/700\n",
      "384/384 [==============================] - 0s 877us/step - loss: 0.9297 - accuracy: 0.6510 - val_loss: 1.1118 - val_accuracy: 0.5104\n",
      "Epoch 134/700\n",
      "384/384 [==============================] - 0s 891us/step - loss: 0.9251 - accuracy: 0.6484 - val_loss: 1.1101 - val_accuracy: 0.5312\n",
      "Epoch 135/700\n",
      "384/384 [==============================] - 0s 837us/step - loss: 0.9316 - accuracy: 0.6667 - val_loss: 1.0997 - val_accuracy: 0.5104\n",
      "Epoch 136/700\n",
      "384/384 [==============================] - 0s 883us/step - loss: 0.9024 - accuracy: 0.6927 - val_loss: 1.1083 - val_accuracy: 0.5000\n",
      "Epoch 137/700\n",
      "384/384 [==============================] - 0s 838us/step - loss: 0.9216 - accuracy: 0.6068 - val_loss: 1.0980 - val_accuracy: 0.5208\n",
      "Epoch 138/700\n",
      "384/384 [==============================] - 0s 891us/step - loss: 0.9158 - accuracy: 0.6615 - val_loss: 1.1026 - val_accuracy: 0.5312\n",
      "Epoch 139/700\n",
      "384/384 [==============================] - 0s 877us/step - loss: 0.9127 - accuracy: 0.6953 - val_loss: 1.1052 - val_accuracy: 0.5312\n",
      "Epoch 140/700\n",
      "384/384 [==============================] - 0s 903us/step - loss: 0.9241 - accuracy: 0.6432 - val_loss: 1.0998 - val_accuracy: 0.5000\n",
      "Epoch 141/700\n",
      "384/384 [==============================] - 0s 860us/step - loss: 0.8741 - accuracy: 0.6875 - val_loss: 1.0910 - val_accuracy: 0.5312\n",
      "Epoch 142/700\n",
      "384/384 [==============================] - 0s 900us/step - loss: 0.9091 - accuracy: 0.6797 - val_loss: 1.1006 - val_accuracy: 0.5208\n",
      "Epoch 143/700\n",
      "384/384 [==============================] - 0s 865us/step - loss: 0.9040 - accuracy: 0.6589 - val_loss: 1.0915 - val_accuracy: 0.5208\n",
      "Epoch 144/700\n",
      "384/384 [==============================] - 0s 900us/step - loss: 0.8804 - accuracy: 0.6953 - val_loss: 1.0945 - val_accuracy: 0.5312\n",
      "Epoch 145/700\n",
      "384/384 [==============================] - 0s 897us/step - loss: 0.8945 - accuracy: 0.6693 - val_loss: 1.0888 - val_accuracy: 0.5417\n",
      "Epoch 146/700\n",
      "384/384 [==============================] - 0s 856us/step - loss: 0.8879 - accuracy: 0.6589 - val_loss: 1.0868 - val_accuracy: 0.5625\n",
      "Epoch 147/700\n",
      "384/384 [==============================] - 0s 874us/step - loss: 0.8698 - accuracy: 0.7031 - val_loss: 1.0900 - val_accuracy: 0.5417\n",
      "Epoch 148/700\n",
      "384/384 [==============================] - 0s 876us/step - loss: 0.8772 - accuracy: 0.6875 - val_loss: 1.0809 - val_accuracy: 0.5521\n",
      "Epoch 149/700\n",
      "384/384 [==============================] - 0s 866us/step - loss: 0.8455 - accuracy: 0.6953 - val_loss: 1.0819 - val_accuracy: 0.5312\n",
      "Epoch 150/700\n",
      "384/384 [==============================] - 0s 893us/step - loss: 0.8855 - accuracy: 0.6458 - val_loss: 1.0733 - val_accuracy: 0.5521\n",
      "Epoch 151/700\n",
      "384/384 [==============================] - 0s 867us/step - loss: 0.8544 - accuracy: 0.7240 - val_loss: 1.0813 - val_accuracy: 0.5208\n",
      "Epoch 152/700\n",
      "384/384 [==============================] - 0s 912us/step - loss: 0.8830 - accuracy: 0.6562 - val_loss: 1.0767 - val_accuracy: 0.5312\n",
      "Epoch 153/700\n",
      "384/384 [==============================] - 0s 851us/step - loss: 0.8466 - accuracy: 0.7057 - val_loss: 1.0753 - val_accuracy: 0.5104\n",
      "Epoch 154/700\n",
      "384/384 [==============================] - 0s 889us/step - loss: 0.8549 - accuracy: 0.7083 - val_loss: 1.0721 - val_accuracy: 0.5417\n",
      "Epoch 155/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 0.8594 - accuracy: 0.6927 - val_loss: 1.0739 - val_accuracy: 0.5625\n",
      "Epoch 156/700\n",
      "384/384 [==============================] - 0s 875us/step - loss: 0.8386 - accuracy: 0.7083 - val_loss: 1.0683 - val_accuracy: 0.5521\n",
      "Epoch 157/700\n",
      "384/384 [==============================] - 0s 856us/step - loss: 0.8539 - accuracy: 0.6797 - val_loss: 1.0655 - val_accuracy: 0.5417\n",
      "Epoch 158/700\n",
      "384/384 [==============================] - 0s 889us/step - loss: 0.8528 - accuracy: 0.7135 - val_loss: 1.0576 - val_accuracy: 0.5625\n",
      "Epoch 159/700\n",
      "384/384 [==============================] - 0s 899us/step - loss: 0.8401 - accuracy: 0.6953 - val_loss: 1.0718 - val_accuracy: 0.5312\n",
      "Epoch 160/700\n",
      "384/384 [==============================] - 0s 856us/step - loss: 0.8309 - accuracy: 0.7135 - val_loss: 1.0680 - val_accuracy: 0.5521\n",
      "Epoch 161/700\n",
      "384/384 [==============================] - 0s 906us/step - loss: 0.8587 - accuracy: 0.6823 - val_loss: 1.0671 - val_accuracy: 0.5521\n",
      "Epoch 162/700\n",
      "384/384 [==============================] - 0s 846us/step - loss: 0.8430 - accuracy: 0.6849 - val_loss: 1.0525 - val_accuracy: 0.5729\n",
      "Epoch 163/700\n",
      "384/384 [==============================] - 0s 889us/step - loss: 0.8397 - accuracy: 0.6849 - val_loss: 1.0498 - val_accuracy: 0.5521\n",
      "Epoch 164/700\n",
      "384/384 [==============================] - 0s 898us/step - loss: 0.8327 - accuracy: 0.7109 - val_loss: 1.0550 - val_accuracy: 0.5625\n",
      "Epoch 165/700\n",
      "384/384 [==============================] - 0s 896us/step - loss: 0.8069 - accuracy: 0.7214 - val_loss: 1.0452 - val_accuracy: 0.5729\n",
      "Epoch 166/700\n",
      "384/384 [==============================] - 0s 870us/step - loss: 0.8168 - accuracy: 0.7188 - val_loss: 1.0476 - val_accuracy: 0.5521\n",
      "Epoch 167/700\n",
      "384/384 [==============================] - 0s 875us/step - loss: 0.8086 - accuracy: 0.7161 - val_loss: 1.0554 - val_accuracy: 0.5625\n",
      "Epoch 168/700\n",
      "384/384 [==============================] - 0s 895us/step - loss: 0.7957 - accuracy: 0.7292 - val_loss: 1.0557 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.8014 - accuracy: 0.7240 - val_loss: 1.0528 - val_accuracy: 0.5312\n",
      "Epoch 170/700\n",
      "384/384 [==============================] - 0s 863us/step - loss: 0.7942 - accuracy: 0.7448 - val_loss: 1.0474 - val_accuracy: 0.5625\n",
      "Epoch 171/700\n",
      "384/384 [==============================] - 0s 847us/step - loss: 0.8020 - accuracy: 0.7214 - val_loss: 1.0519 - val_accuracy: 0.5417\n",
      "Epoch 172/700\n",
      "384/384 [==============================] - 0s 870us/step - loss: 0.7862 - accuracy: 0.7266 - val_loss: 1.0466 - val_accuracy: 0.5625\n",
      "Epoch 173/700\n",
      "384/384 [==============================] - 0s 866us/step - loss: 0.7725 - accuracy: 0.7526 - val_loss: 1.0379 - val_accuracy: 0.5729\n",
      "Epoch 174/700\n",
      "384/384 [==============================] - 0s 862us/step - loss: 0.7887 - accuracy: 0.7500 - val_loss: 1.0559 - val_accuracy: 0.5729\n",
      "Epoch 175/700\n",
      "384/384 [==============================] - 0s 876us/step - loss: 0.7660 - accuracy: 0.7214 - val_loss: 1.0324 - val_accuracy: 0.5625\n",
      "Epoch 176/700\n",
      "384/384 [==============================] - 0s 855us/step - loss: 0.7958 - accuracy: 0.7240 - val_loss: 1.0294 - val_accuracy: 0.5625\n",
      "Epoch 177/700\n",
      "384/384 [==============================] - 0s 894us/step - loss: 0.7887 - accuracy: 0.7396 - val_loss: 1.0317 - val_accuracy: 0.5729\n",
      "Epoch 178/700\n",
      "384/384 [==============================] - 0s 848us/step - loss: 0.7901 - accuracy: 0.7083 - val_loss: 1.0341 - val_accuracy: 0.5521\n",
      "Epoch 179/700\n",
      "384/384 [==============================] - 0s 865us/step - loss: 0.7773 - accuracy: 0.7370 - val_loss: 1.0247 - val_accuracy: 0.6042\n",
      "Epoch 180/700\n",
      "384/384 [==============================] - 0s 820us/step - loss: 0.7669 - accuracy: 0.7630 - val_loss: 1.0156 - val_accuracy: 0.5938\n",
      "Epoch 181/700\n",
      "384/384 [==============================] - 0s 867us/step - loss: 0.7729 - accuracy: 0.7240 - val_loss: 1.0266 - val_accuracy: 0.5938\n",
      "Epoch 182/700\n",
      "384/384 [==============================] - 0s 862us/step - loss: 0.7657 - accuracy: 0.7344 - val_loss: 1.0175 - val_accuracy: 0.5833\n",
      "Epoch 183/700\n",
      "384/384 [==============================] - 0s 886us/step - loss: 0.7418 - accuracy: 0.7500 - val_loss: 1.0288 - val_accuracy: 0.5938\n",
      "Epoch 184/700\n",
      "384/384 [==============================] - 0s 842us/step - loss: 0.7364 - accuracy: 0.7630 - val_loss: 1.0185 - val_accuracy: 0.5833\n",
      "Epoch 185/700\n",
      "384/384 [==============================] - 0s 847us/step - loss: 0.7307 - accuracy: 0.7708 - val_loss: 1.0327 - val_accuracy: 0.5521\n",
      "Epoch 186/700\n",
      "384/384 [==============================] - 0s 904us/step - loss: 0.7277 - accuracy: 0.7578 - val_loss: 1.0217 - val_accuracy: 0.5833\n",
      "Epoch 187/700\n",
      "384/384 [==============================] - 0s 841us/step - loss: 0.7057 - accuracy: 0.7891 - val_loss: 1.0200 - val_accuracy: 0.5729\n",
      "Epoch 188/700\n",
      "384/384 [==============================] - 0s 871us/step - loss: 0.7413 - accuracy: 0.7318 - val_loss: 1.0195 - val_accuracy: 0.5625\n",
      "Epoch 189/700\n",
      "384/384 [==============================] - 0s 869us/step - loss: 0.7213 - accuracy: 0.7630 - val_loss: 1.0319 - val_accuracy: 0.5729\n",
      "Epoch 190/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 0.7168 - accuracy: 0.7760 - val_loss: 1.0162 - val_accuracy: 0.5625\n",
      "Epoch 191/700\n",
      "384/384 [==============================] - 0s 877us/step - loss: 0.7253 - accuracy: 0.7630 - val_loss: 1.0121 - val_accuracy: 0.5729\n",
      "Epoch 192/700\n",
      "384/384 [==============================] - 0s 865us/step - loss: 0.6863 - accuracy: 0.7865 - val_loss: 1.0045 - val_accuracy: 0.5833\n",
      "Epoch 193/700\n",
      "384/384 [==============================] - 0s 830us/step - loss: 0.7203 - accuracy: 0.7500 - val_loss: 1.0176 - val_accuracy: 0.5729\n",
      "Epoch 194/700\n",
      "384/384 [==============================] - 0s 869us/step - loss: 0.7228 - accuracy: 0.7526 - val_loss: 1.0075 - val_accuracy: 0.5938\n",
      "Epoch 195/700\n",
      "384/384 [==============================] - 0s 877us/step - loss: 0.7249 - accuracy: 0.7604 - val_loss: 0.9990 - val_accuracy: 0.5938\n",
      "Epoch 196/700\n",
      "384/384 [==============================] - 0s 890us/step - loss: 0.6809 - accuracy: 0.7865 - val_loss: 1.0025 - val_accuracy: 0.5729\n",
      "Epoch 197/700\n",
      "384/384 [==============================] - 0s 873us/step - loss: 0.7088 - accuracy: 0.7656 - val_loss: 1.0163 - val_accuracy: 0.5938\n",
      "Epoch 198/700\n",
      "384/384 [==============================] - 0s 888us/step - loss: 0.7047 - accuracy: 0.7682 - val_loss: 1.0016 - val_accuracy: 0.5729\n",
      "Epoch 199/700\n",
      "384/384 [==============================] - 0s 828us/step - loss: 0.7050 - accuracy: 0.7500 - val_loss: 0.9958 - val_accuracy: 0.6042\n",
      "Epoch 200/700\n",
      "384/384 [==============================] - 0s 890us/step - loss: 0.6893 - accuracy: 0.7760 - val_loss: 1.0060 - val_accuracy: 0.5833\n",
      "Epoch 201/700\n",
      "384/384 [==============================] - 0s 893us/step - loss: 0.6735 - accuracy: 0.7734 - val_loss: 1.0098 - val_accuracy: 0.5833\n",
      "Epoch 202/700\n",
      "384/384 [==============================] - 0s 903us/step - loss: 0.6904 - accuracy: 0.7734 - val_loss: 0.9957 - val_accuracy: 0.5729\n",
      "Epoch 203/700\n",
      "384/384 [==============================] - 0s 829us/step - loss: 0.6610 - accuracy: 0.8021 - val_loss: 1.0028 - val_accuracy: 0.5938\n",
      "Epoch 204/700\n",
      "384/384 [==============================] - 0s 880us/step - loss: 0.6816 - accuracy: 0.7865 - val_loss: 0.9919 - val_accuracy: 0.5833\n",
      "Epoch 205/700\n",
      "384/384 [==============================] - 0s 871us/step - loss: 0.6751 - accuracy: 0.8021 - val_loss: 0.9970 - val_accuracy: 0.5938\n",
      "Epoch 206/700\n",
      "384/384 [==============================] - 0s 869us/step - loss: 0.6747 - accuracy: 0.7812 - val_loss: 0.9798 - val_accuracy: 0.6042\n",
      "Epoch 207/700\n",
      "384/384 [==============================] - 0s 855us/step - loss: 0.6844 - accuracy: 0.7917 - val_loss: 0.9872 - val_accuracy: 0.5729\n",
      "Epoch 208/700\n",
      "384/384 [==============================] - 0s 898us/step - loss: 0.6772 - accuracy: 0.7760 - val_loss: 0.9908 - val_accuracy: 0.5729\n",
      "Epoch 209/700\n",
      "384/384 [==============================] - 0s 881us/step - loss: 0.6663 - accuracy: 0.7786 - val_loss: 0.9789 - val_accuracy: 0.5938\n",
      "Epoch 210/700\n",
      "384/384 [==============================] - 0s 864us/step - loss: 0.6713 - accuracy: 0.7865 - val_loss: 0.9866 - val_accuracy: 0.5833\n",
      "Epoch 211/700\n",
      "384/384 [==============================] - 0s 870us/step - loss: 0.6437 - accuracy: 0.8021 - val_loss: 0.9913 - val_accuracy: 0.5729\n",
      "Epoch 212/700\n",
      "384/384 [==============================] - 0s 898us/step - loss: 0.6508 - accuracy: 0.7917 - val_loss: 0.9827 - val_accuracy: 0.5938\n",
      "Epoch 213/700\n",
      "384/384 [==============================] - 0s 875us/step - loss: 0.6487 - accuracy: 0.7891 - val_loss: 0.9950 - val_accuracy: 0.5833\n",
      "Epoch 214/700\n",
      "384/384 [==============================] - 0s 902us/step - loss: 0.6468 - accuracy: 0.7969 - val_loss: 0.9848 - val_accuracy: 0.5833\n",
      "Epoch 215/700\n",
      "384/384 [==============================] - 0s 909us/step - loss: 0.6386 - accuracy: 0.7917 - val_loss: 0.9798 - val_accuracy: 0.5833\n",
      "Epoch 216/700\n",
      "384/384 [==============================] - 0s 888us/step - loss: 0.6349 - accuracy: 0.8021 - val_loss: 0.9872 - val_accuracy: 0.5833\n",
      "Epoch 217/700\n",
      "384/384 [==============================] - 0s 872us/step - loss: 0.6330 - accuracy: 0.7891 - val_loss: 0.9916 - val_accuracy: 0.5938\n",
      "Epoch 218/700\n",
      "384/384 [==============================] - 0s 899us/step - loss: 0.6342 - accuracy: 0.7969 - val_loss: 0.9777 - val_accuracy: 0.5833\n",
      "Epoch 219/700\n",
      "384/384 [==============================] - 0s 909us/step - loss: 0.6228 - accuracy: 0.8021 - val_loss: 0.9872 - val_accuracy: 0.5729\n",
      "Epoch 220/700\n",
      "384/384 [==============================] - 0s 857us/step - loss: 0.6158 - accuracy: 0.8125 - val_loss: 0.9661 - val_accuracy: 0.5833\n",
      "Epoch 221/700\n",
      "384/384 [==============================] - 0s 899us/step - loss: 0.6322 - accuracy: 0.7865 - val_loss: 0.9695 - val_accuracy: 0.5729\n",
      "Epoch 222/700\n",
      "384/384 [==============================] - 0s 867us/step - loss: 0.6156 - accuracy: 0.8177 - val_loss: 0.9701 - val_accuracy: 0.5833\n",
      "Epoch 223/700\n",
      "384/384 [==============================] - 0s 894us/step - loss: 0.6158 - accuracy: 0.8203 - val_loss: 0.9661 - val_accuracy: 0.5625\n",
      "Epoch 224/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 0.6038 - accuracy: 0.8151 - val_loss: 0.9675 - val_accuracy: 0.5729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/700\n",
      "384/384 [==============================] - 0s 904us/step - loss: 0.5854 - accuracy: 0.8203 - val_loss: 0.9618 - val_accuracy: 0.5833\n",
      "Epoch 226/700\n",
      "384/384 [==============================] - 0s 869us/step - loss: 0.6262 - accuracy: 0.8021 - val_loss: 0.9758 - val_accuracy: 0.5625\n",
      "Epoch 227/700\n",
      "384/384 [==============================] - 0s 878us/step - loss: 0.6111 - accuracy: 0.8203 - val_loss: 0.9724 - val_accuracy: 0.5729\n",
      "Epoch 228/700\n",
      "384/384 [==============================] - 0s 851us/step - loss: 0.5971 - accuracy: 0.8177 - val_loss: 0.9720 - val_accuracy: 0.5729\n",
      "Epoch 229/700\n",
      "384/384 [==============================] - 0s 869us/step - loss: 0.6026 - accuracy: 0.8099 - val_loss: 0.9708 - val_accuracy: 0.5729\n",
      "Epoch 230/700\n",
      "384/384 [==============================] - 0s 854us/step - loss: 0.5944 - accuracy: 0.8281 - val_loss: 0.9738 - val_accuracy: 0.5729\n",
      "Epoch 231/700\n",
      "384/384 [==============================] - 0s 904us/step - loss: 0.5843 - accuracy: 0.8359 - val_loss: 0.9586 - val_accuracy: 0.5625\n",
      "Epoch 232/700\n",
      "384/384 [==============================] - 0s 852us/step - loss: 0.5709 - accuracy: 0.8307 - val_loss: 0.9620 - val_accuracy: 0.5625\n",
      "Epoch 233/700\n",
      "384/384 [==============================] - 0s 908us/step - loss: 0.5662 - accuracy: 0.8359 - val_loss: 0.9715 - val_accuracy: 0.5729\n",
      "Epoch 234/700\n",
      "384/384 [==============================] - 0s 854us/step - loss: 0.5908 - accuracy: 0.8229 - val_loss: 0.9548 - val_accuracy: 0.5729\n",
      "Epoch 235/700\n",
      "384/384 [==============================] - 0s 886us/step - loss: 0.5720 - accuracy: 0.8333 - val_loss: 0.9685 - val_accuracy: 0.5729\n",
      "Epoch 236/700\n",
      "384/384 [==============================] - 0s 859us/step - loss: 0.5580 - accuracy: 0.8281 - val_loss: 0.9743 - val_accuracy: 0.5729\n",
      "Epoch 237/700\n",
      "384/384 [==============================] - 0s 889us/step - loss: 0.5726 - accuracy: 0.8229 - val_loss: 0.9623 - val_accuracy: 0.5729\n",
      "Epoch 238/700\n",
      "384/384 [==============================] - 0s 850us/step - loss: 0.5707 - accuracy: 0.8255 - val_loss: 0.9505 - val_accuracy: 0.5729\n",
      "Epoch 239/700\n",
      "384/384 [==============================] - 0s 881us/step - loss: 0.5543 - accuracy: 0.8255 - val_loss: 0.9556 - val_accuracy: 0.5729\n",
      "Epoch 240/700\n",
      "384/384 [==============================] - 0s 961us/step - loss: 0.5663 - accuracy: 0.8490 - val_loss: 0.9575 - val_accuracy: 0.5833\n",
      "Epoch 241/700\n",
      "384/384 [==============================] - 0s 867us/step - loss: 0.5787 - accuracy: 0.8177 - val_loss: 0.9515 - val_accuracy: 0.5729\n",
      "Epoch 242/700\n",
      "384/384 [==============================] - 0s 912us/step - loss: 0.5652 - accuracy: 0.8177 - val_loss: 0.9576 - val_accuracy: 0.6042\n",
      "Epoch 243/700\n",
      "384/384 [==============================] - 0s 875us/step - loss: 0.5538 - accuracy: 0.8333 - val_loss: 0.9476 - val_accuracy: 0.5833\n",
      "Epoch 244/700\n",
      "384/384 [==============================] - 0s 886us/step - loss: 0.5507 - accuracy: 0.8281 - val_loss: 0.9409 - val_accuracy: 0.5833\n",
      "Epoch 245/700\n",
      "384/384 [==============================] - 0s 855us/step - loss: 0.5382 - accuracy: 0.8464 - val_loss: 0.9546 - val_accuracy: 0.5729\n",
      "Epoch 246/700\n",
      "384/384 [==============================] - 0s 948us/step - loss: 0.5371 - accuracy: 0.8490 - val_loss: 0.9525 - val_accuracy: 0.6042\n",
      "Epoch 247/700\n",
      "384/384 [==============================] - 0s 841us/step - loss: 0.5301 - accuracy: 0.8516 - val_loss: 0.9354 - val_accuracy: 0.5729\n",
      "Epoch 248/700\n",
      "384/384 [==============================] - 0s 868us/step - loss: 0.5417 - accuracy: 0.8203 - val_loss: 0.9540 - val_accuracy: 0.5729\n",
      "Epoch 249/700\n",
      "384/384 [==============================] - 0s 838us/step - loss: 0.5395 - accuracy: 0.8281 - val_loss: 0.9388 - val_accuracy: 0.5833\n",
      "Epoch 250/700\n",
      "384/384 [==============================] - 0s 895us/step - loss: 0.5166 - accuracy: 0.8516 - val_loss: 0.9486 - val_accuracy: 0.5938\n",
      "Epoch 251/700\n",
      "384/384 [==============================] - 0s 842us/step - loss: 0.5361 - accuracy: 0.8411 - val_loss: 0.9576 - val_accuracy: 0.5729\n",
      "Epoch 252/700\n",
      "384/384 [==============================] - 0s 896us/step - loss: 0.5403 - accuracy: 0.8385 - val_loss: 0.9607 - val_accuracy: 0.5625\n",
      "Epoch 253/700\n",
      "384/384 [==============================] - 0s 862us/step - loss: 0.5299 - accuracy: 0.8385 - val_loss: 0.9357 - val_accuracy: 0.5833\n",
      "Epoch 254/700\n",
      "384/384 [==============================] - 0s 906us/step - loss: 0.5160 - accuracy: 0.8411 - val_loss: 0.9397 - val_accuracy: 0.5625\n",
      "Epoch 255/700\n",
      "384/384 [==============================] - 0s 872us/step - loss: 0.5103 - accuracy: 0.8594 - val_loss: 0.9585 - val_accuracy: 0.5833\n",
      "Epoch 256/700\n",
      "384/384 [==============================] - 0s 909us/step - loss: 0.5131 - accuracy: 0.8438 - val_loss: 0.9473 - val_accuracy: 0.5625\n",
      "Epoch 257/700\n",
      "384/384 [==============================] - 0s 858us/step - loss: 0.4982 - accuracy: 0.8620 - val_loss: 0.9342 - val_accuracy: 0.5729\n",
      "Epoch 258/700\n",
      "384/384 [==============================] - 0s 890us/step - loss: 0.5314 - accuracy: 0.8359 - val_loss: 0.9511 - val_accuracy: 0.5729\n",
      "Epoch 259/700\n",
      "384/384 [==============================] - 0s 834us/step - loss: 0.4933 - accuracy: 0.8802 - val_loss: 0.9570 - val_accuracy: 0.5625\n",
      "Epoch 260/700\n",
      "384/384 [==============================] - 0s 925us/step - loss: 0.5054 - accuracy: 0.8359 - val_loss: 0.9476 - val_accuracy: 0.5625\n",
      "Epoch 261/700\n",
      "384/384 [==============================] - 0s 862us/step - loss: 0.4769 - accuracy: 0.8568 - val_loss: 0.9598 - val_accuracy: 0.5521\n",
      "Epoch 262/700\n",
      "384/384 [==============================] - 0s 858us/step - loss: 0.5047 - accuracy: 0.8542 - val_loss: 0.9371 - val_accuracy: 0.5833\n",
      "Epoch 263/700\n",
      "384/384 [==============================] - 0s 846us/step - loss: 0.4916 - accuracy: 0.8646 - val_loss: 0.9365 - val_accuracy: 0.5729\n",
      "Epoch 264/700\n",
      "384/384 [==============================] - 0s 870us/step - loss: 0.4897 - accuracy: 0.8646 - val_loss: 0.9344 - val_accuracy: 0.5729\n",
      "Epoch 265/700\n",
      "384/384 [==============================] - 0s 854us/step - loss: 0.4920 - accuracy: 0.8672 - val_loss: 0.9544 - val_accuracy: 0.5833\n",
      "Epoch 266/700\n",
      "384/384 [==============================] - 0s 904us/step - loss: 0.4810 - accuracy: 0.8724 - val_loss: 0.9312 - val_accuracy: 0.5833\n",
      "Epoch 267/700\n",
      "384/384 [==============================] - 0s 864us/step - loss: 0.4880 - accuracy: 0.8672 - val_loss: 0.9456 - val_accuracy: 0.5729\n",
      "Epoch 268/700\n",
      "384/384 [==============================] - 0s 902us/step - loss: 0.4739 - accuracy: 0.8620 - val_loss: 0.9459 - val_accuracy: 0.5729\n",
      "Epoch 269/700\n",
      "384/384 [==============================] - 0s 874us/step - loss: 0.4646 - accuracy: 0.8672 - val_loss: 0.9283 - val_accuracy: 0.5729\n",
      "Epoch 270/700\n",
      "384/384 [==============================] - 0s 859us/step - loss: 0.4584 - accuracy: 0.8880 - val_loss: 0.9477 - val_accuracy: 0.5729\n",
      "Epoch 271/700\n",
      "384/384 [==============================] - 0s 899us/step - loss: 0.4979 - accuracy: 0.8359 - val_loss: 0.9351 - val_accuracy: 0.5729\n",
      "Epoch 272/700\n",
      "384/384 [==============================] - 0s 873us/step - loss: 0.4950 - accuracy: 0.8359 - val_loss: 0.9443 - val_accuracy: 0.5729\n",
      "Epoch 273/700\n",
      "384/384 [==============================] - 0s 903us/step - loss: 0.4666 - accuracy: 0.8516 - val_loss: 0.9377 - val_accuracy: 0.5729\n",
      "Epoch 274/700\n",
      "384/384 [==============================] - 0s 869us/step - loss: 0.4657 - accuracy: 0.8698 - val_loss: 0.9381 - val_accuracy: 0.5729\n",
      "Epoch 275/700\n",
      "384/384 [==============================] - 0s 901us/step - loss: 0.4629 - accuracy: 0.8698 - val_loss: 0.9206 - val_accuracy: 0.5729\n",
      "Epoch 276/700\n",
      "384/384 [==============================] - 0s 868us/step - loss: 0.4587 - accuracy: 0.8672 - val_loss: 0.9391 - val_accuracy: 0.5625\n",
      "Epoch 277/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 0.4656 - accuracy: 0.8854 - val_loss: 0.9496 - val_accuracy: 0.5625\n",
      "Epoch 278/700\n",
      "384/384 [==============================] - 0s 920us/step - loss: 0.4644 - accuracy: 0.8724 - val_loss: 0.9526 - val_accuracy: 0.5521\n",
      "Epoch 279/700\n",
      "384/384 [==============================] - 0s 901us/step - loss: 0.4378 - accuracy: 0.8880 - val_loss: 0.9278 - val_accuracy: 0.5625\n",
      "Epoch 280/700\n",
      "384/384 [==============================] - 0s 876us/step - loss: 0.4402 - accuracy: 0.8594 - val_loss: 0.9428 - val_accuracy: 0.5729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/700\n",
      "384/384 [==============================] - 0s 889us/step - loss: 0.4309 - accuracy: 0.8984 - val_loss: 0.9376 - val_accuracy: 0.5625\n",
      "Epoch 282/700\n",
      "384/384 [==============================] - 0s 858us/step - loss: 0.4475 - accuracy: 0.8698 - val_loss: 0.9404 - val_accuracy: 0.5729\n",
      "Epoch 283/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 0.4403 - accuracy: 0.8854 - val_loss: 0.9254 - val_accuracy: 0.5833\n",
      "Epoch 284/700\n",
      "384/384 [==============================] - 0s 880us/step - loss: 0.4427 - accuracy: 0.8828 - val_loss: 0.9418 - val_accuracy: 0.5729\n",
      "Epoch 285/700\n",
      "384/384 [==============================] - 0s 902us/step - loss: 0.4389 - accuracy: 0.8776 - val_loss: 0.9355 - val_accuracy: 0.5729\n",
      "Epoch 286/700\n",
      "384/384 [==============================] - 0s 861us/step - loss: 0.4124 - accuracy: 0.9141 - val_loss: 0.9418 - val_accuracy: 0.5833\n",
      "Epoch 287/700\n",
      "384/384 [==============================] - 0s 913us/step - loss: 0.4373 - accuracy: 0.8932 - val_loss: 0.9378 - val_accuracy: 0.5833\n",
      "Epoch 288/700\n",
      "384/384 [==============================] - 0s 841us/step - loss: 0.4262 - accuracy: 0.8880 - val_loss: 0.9358 - val_accuracy: 0.5625\n",
      "Epoch 289/700\n",
      "384/384 [==============================] - 0s 900us/step - loss: 0.4196 - accuracy: 0.8880 - val_loss: 0.9269 - val_accuracy: 0.5833\n",
      "Epoch 290/700\n",
      "384/384 [==============================] - 0s 851us/step - loss: 0.4178 - accuracy: 0.8854 - val_loss: 0.9384 - val_accuracy: 0.5729\n",
      "Epoch 291/700\n",
      "384/384 [==============================] - 0s 911us/step - loss: 0.4243 - accuracy: 0.8802 - val_loss: 0.9401 - val_accuracy: 0.5833\n",
      "Epoch 292/700\n",
      "384/384 [==============================] - 0s 865us/step - loss: 0.4099 - accuracy: 0.8958 - val_loss: 0.9349 - val_accuracy: 0.5625\n",
      "Epoch 293/700\n",
      "384/384 [==============================] - 0s 885us/step - loss: 0.4036 - accuracy: 0.9036 - val_loss: 0.9303 - val_accuracy: 0.5625\n",
      "Epoch 294/700\n",
      "384/384 [==============================] - 0s 823us/step - loss: 0.3868 - accuracy: 0.9010 - val_loss: 0.9168 - val_accuracy: 0.5729\n",
      "Epoch 295/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 0.4209 - accuracy: 0.8880 - val_loss: 0.9224 - val_accuracy: 0.5729\n",
      "Epoch 296/700\n",
      "384/384 [==============================] - 0s 855us/step - loss: 0.4281 - accuracy: 0.8750 - val_loss: 0.9230 - val_accuracy: 0.5625\n",
      "Epoch 297/700\n",
      "384/384 [==============================] - 0s 885us/step - loss: 0.3965 - accuracy: 0.9115 - val_loss: 0.9438 - val_accuracy: 0.5625\n",
      "Epoch 298/700\n",
      "384/384 [==============================] - 0s 871us/step - loss: 0.3931 - accuracy: 0.9193 - val_loss: 0.9416 - val_accuracy: 0.5729\n",
      "Epoch 299/700\n",
      "384/384 [==============================] - 0s 869us/step - loss: 0.3820 - accuracy: 0.9062 - val_loss: 0.9387 - val_accuracy: 0.5625\n",
      "Epoch 300/700\n",
      "384/384 [==============================] - 0s 885us/step - loss: 0.3759 - accuracy: 0.8932 - val_loss: 0.9326 - val_accuracy: 0.5625\n",
      "Epoch 301/700\n",
      "384/384 [==============================] - 0s 876us/step - loss: 0.3749 - accuracy: 0.9089 - val_loss: 0.9272 - val_accuracy: 0.5625\n",
      "Epoch 302/700\n",
      "384/384 [==============================] - 0s 880us/step - loss: 0.3794 - accuracy: 0.8932 - val_loss: 0.9315 - val_accuracy: 0.5625\n",
      "Epoch 303/700\n",
      "384/384 [==============================] - 0s 832us/step - loss: 0.3848 - accuracy: 0.9036 - val_loss: 0.9304 - val_accuracy: 0.5521\n",
      "Epoch 304/700\n",
      "384/384 [==============================] - 0s 898us/step - loss: 0.3763 - accuracy: 0.8828 - val_loss: 0.9312 - val_accuracy: 0.5625\n",
      "Epoch 305/700\n",
      "384/384 [==============================] - 0s 879us/step - loss: 0.3850 - accuracy: 0.9036 - val_loss: 0.9199 - val_accuracy: 0.5729\n",
      "Epoch 306/700\n",
      "384/384 [==============================] - 0s 871us/step - loss: 0.3841 - accuracy: 0.8958 - val_loss: 0.9334 - val_accuracy: 0.5729\n",
      "Epoch 307/700\n",
      "384/384 [==============================] - 0s 861us/step - loss: 0.3691 - accuracy: 0.9375 - val_loss: 0.9215 - val_accuracy: 0.5729\n",
      "Epoch 308/700\n",
      "384/384 [==============================] - 0s 873us/step - loss: 0.3857 - accuracy: 0.9115 - val_loss: 0.9362 - val_accuracy: 0.5521\n",
      "Epoch 309/700\n",
      "384/384 [==============================] - 0s 877us/step - loss: 0.3697 - accuracy: 0.9167 - val_loss: 0.9244 - val_accuracy: 0.5729\n",
      "Epoch 310/700\n",
      "384/384 [==============================] - 0s 907us/step - loss: 0.3513 - accuracy: 0.9141 - val_loss: 0.9411 - val_accuracy: 0.5625\n",
      "Epoch 311/700\n",
      "384/384 [==============================] - 0s 887us/step - loss: 0.3751 - accuracy: 0.8958 - val_loss: 0.9257 - val_accuracy: 0.5625\n",
      "Epoch 312/700\n",
      "384/384 [==============================] - 0s 861us/step - loss: 0.3600 - accuracy: 0.9167 - val_loss: 0.9356 - val_accuracy: 0.5729\n",
      "Epoch 313/700\n",
      "384/384 [==============================] - 0s 843us/step - loss: 0.3396 - accuracy: 0.9219 - val_loss: 0.9351 - val_accuracy: 0.5625\n",
      "Epoch 314/700\n",
      "384/384 [==============================] - 0s 877us/step - loss: 0.3769 - accuracy: 0.8984 - val_loss: 0.9434 - val_accuracy: 0.5833\n",
      "Epoch 315/700\n",
      "384/384 [==============================] - 0s 874us/step - loss: 0.3572 - accuracy: 0.9245 - val_loss: 0.9295 - val_accuracy: 0.5521\n",
      "Epoch 316/700\n",
      "384/384 [==============================] - 0s 909us/step - loss: 0.3533 - accuracy: 0.9089 - val_loss: 0.9510 - val_accuracy: 0.5729\n",
      "Epoch 317/700\n",
      "384/384 [==============================] - 0s 857us/step - loss: 0.3510 - accuracy: 0.9245 - val_loss: 0.9393 - val_accuracy: 0.5833\n",
      "Epoch 318/700\n",
      "384/384 [==============================] - 0s 903us/step - loss: 0.3503 - accuracy: 0.9115 - val_loss: 0.9271 - val_accuracy: 0.5833\n",
      "Epoch 319/700\n",
      "384/384 [==============================] - 0s 868us/step - loss: 0.3489 - accuracy: 0.9245 - val_loss: 0.9409 - val_accuracy: 0.5833\n",
      "Epoch 320/700\n",
      "384/384 [==============================] - 0s 908us/step - loss: 0.3418 - accuracy: 0.9036 - val_loss: 0.9390 - val_accuracy: 0.5833\n",
      "Epoch 321/700\n",
      "384/384 [==============================] - 0s 832us/step - loss: 0.3361 - accuracy: 0.9036 - val_loss: 0.9546 - val_accuracy: 0.5625\n",
      "Epoch 322/700\n",
      "384/384 [==============================] - 0s 941us/step - loss: 0.3272 - accuracy: 0.9323 - val_loss: 0.9368 - val_accuracy: 0.5521\n",
      "Epoch 323/700\n",
      "384/384 [==============================] - 0s 872us/step - loss: 0.3498 - accuracy: 0.9141 - val_loss: 0.9424 - val_accuracy: 0.5521\n",
      "Epoch 324/700\n",
      "384/384 [==============================] - 0s 898us/step - loss: 0.3266 - accuracy: 0.9323 - val_loss: 0.9199 - val_accuracy: 0.5729\n",
      "Epoch 325/700\n",
      "384/384 [==============================] - 0s 887us/step - loss: 0.3140 - accuracy: 0.9401 - val_loss: 0.9541 - val_accuracy: 0.5833\n",
      "Epoch 326/700\n",
      "384/384 [==============================] - 0s 903us/step - loss: 0.3252 - accuracy: 0.9375 - val_loss: 0.9455 - val_accuracy: 0.5729\n",
      "Epoch 327/700\n",
      "384/384 [==============================] - 0s 843us/step - loss: 0.3353 - accuracy: 0.9193 - val_loss: 0.9175 - val_accuracy: 0.5729\n",
      "Epoch 328/700\n",
      "384/384 [==============================] - 0s 923us/step - loss: 0.3105 - accuracy: 0.9349 - val_loss: 0.9591 - val_accuracy: 0.5521\n",
      "Epoch 329/700\n",
      "384/384 [==============================] - 0s 872us/step - loss: 0.3239 - accuracy: 0.9219 - val_loss: 0.9253 - val_accuracy: 0.5833\n",
      "Epoch 330/700\n",
      "384/384 [==============================] - 0s 906us/step - loss: 0.3161 - accuracy: 0.9089 - val_loss: 0.9425 - val_accuracy: 0.5625\n",
      "Epoch 331/700\n",
      "384/384 [==============================] - 0s 857us/step - loss: 0.3286 - accuracy: 0.9245 - val_loss: 0.9331 - val_accuracy: 0.5625\n",
      "Epoch 332/700\n",
      "384/384 [==============================] - 0s 914us/step - loss: 0.3286 - accuracy: 0.9245 - val_loss: 0.9434 - val_accuracy: 0.5625\n",
      "Epoch 333/700\n",
      "384/384 [==============================] - 0s 878us/step - loss: 0.3048 - accuracy: 0.9323 - val_loss: 0.9339 - val_accuracy: 0.5729\n",
      "Epoch 334/700\n",
      "384/384 [==============================] - 0s 860us/step - loss: 0.3131 - accuracy: 0.9375 - val_loss: 0.9397 - val_accuracy: 0.5729\n",
      "Epoch 335/700\n",
      "384/384 [==============================] - 0s 888us/step - loss: 0.3113 - accuracy: 0.9271 - val_loss: 0.9329 - val_accuracy: 0.5729\n",
      "Epoch 336/700\n",
      "384/384 [==============================] - 0s 895us/step - loss: 0.3111 - accuracy: 0.9219 - val_loss: 0.9616 - val_accuracy: 0.5521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/700\n",
      "384/384 [==============================] - 0s 893us/step - loss: 0.3034 - accuracy: 0.9271 - val_loss: 0.9478 - val_accuracy: 0.5625\n",
      "Epoch 338/700\n",
      "384/384 [==============================] - 0s 852us/step - loss: 0.2987 - accuracy: 0.9349 - val_loss: 0.9360 - val_accuracy: 0.5729\n",
      "Epoch 339/700\n",
      "384/384 [==============================] - 0s 879us/step - loss: 0.2876 - accuracy: 0.9401 - val_loss: 0.9373 - val_accuracy: 0.5729\n",
      "Epoch 340/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.3083 - accuracy: 0.9245 - val_loss: 0.9295 - val_accuracy: 0.5833\n",
      "Epoch 341/700\n",
      "384/384 [==============================] - 0s 939us/step - loss: 0.2921 - accuracy: 0.9479 - val_loss: 0.9566 - val_accuracy: 0.5625\n",
      "Epoch 342/700\n",
      "384/384 [==============================] - 0s 824us/step - loss: 0.3025 - accuracy: 0.9401 - val_loss: 0.9169 - val_accuracy: 0.5625\n",
      "Epoch 343/700\n",
      "384/384 [==============================] - 0s 882us/step - loss: 0.2770 - accuracy: 0.9375 - val_loss: 0.9213 - val_accuracy: 0.5729\n",
      "Epoch 344/700\n",
      "384/384 [==============================] - 0s 870us/step - loss: 0.2785 - accuracy: 0.9453 - val_loss: 0.9263 - val_accuracy: 0.5625\n",
      "Epoch 345/700\n",
      "384/384 [==============================] - 0s 878us/step - loss: 0.3002 - accuracy: 0.9245 - val_loss: 0.9600 - val_accuracy: 0.5729\n",
      "Epoch 346/700\n",
      "384/384 [==============================] - 0s 894us/step - loss: 0.2804 - accuracy: 0.9401 - val_loss: 0.9372 - val_accuracy: 0.5729\n",
      "Epoch 347/700\n",
      "384/384 [==============================] - 0s 888us/step - loss: 0.2896 - accuracy: 0.9401 - val_loss: 0.9586 - val_accuracy: 0.5625\n",
      "Epoch 348/700\n",
      "384/384 [==============================] - 0s 878us/step - loss: 0.2963 - accuracy: 0.9193 - val_loss: 0.9427 - val_accuracy: 0.5833\n",
      "Epoch 349/700\n",
      "384/384 [==============================] - 0s 870us/step - loss: 0.2834 - accuracy: 0.9349 - val_loss: 0.9388 - val_accuracy: 0.5833\n",
      "Epoch 350/700\n",
      "384/384 [==============================] - 0s 855us/step - loss: 0.2770 - accuracy: 0.9453 - val_loss: 0.9626 - val_accuracy: 0.5833\n",
      "Epoch 351/700\n",
      "384/384 [==============================] - 0s 875us/step - loss: 0.2662 - accuracy: 0.9531 - val_loss: 0.9442 - val_accuracy: 0.5729\n",
      "Epoch 352/700\n",
      "384/384 [==============================] - 0s 863us/step - loss: 0.2679 - accuracy: 0.9453 - val_loss: 0.9353 - val_accuracy: 0.5729\n",
      "Epoch 353/700\n",
      "384/384 [==============================] - 0s 900us/step - loss: 0.2647 - accuracy: 0.9531 - val_loss: 0.9445 - val_accuracy: 0.5833\n",
      "Epoch 354/700\n",
      "384/384 [==============================] - 0s 879us/step - loss: 0.2820 - accuracy: 0.9349 - val_loss: 0.9526 - val_accuracy: 0.5625\n",
      "Epoch 355/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 0.2650 - accuracy: 0.9583 - val_loss: 0.9337 - val_accuracy: 0.5833\n",
      "Epoch 356/700\n",
      "384/384 [==============================] - 0s 828us/step - loss: 0.2502 - accuracy: 0.9583 - val_loss: 0.9404 - val_accuracy: 0.5625\n",
      "Epoch 357/700\n",
      "384/384 [==============================] - 0s 890us/step - loss: 0.2652 - accuracy: 0.9531 - val_loss: 0.9478 - val_accuracy: 0.5729\n",
      "Epoch 358/700\n",
      "384/384 [==============================] - 0s 833us/step - loss: 0.2381 - accuracy: 0.9688 - val_loss: 0.9818 - val_accuracy: 0.5833\n",
      "Epoch 359/700\n",
      "384/384 [==============================] - 0s 878us/step - loss: 0.2564 - accuracy: 0.9531 - val_loss: 0.9318 - val_accuracy: 0.5938\n",
      "Epoch 360/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 0.2559 - accuracy: 0.9609 - val_loss: 0.9742 - val_accuracy: 0.5625\n",
      "Epoch 361/700\n",
      "384/384 [==============================] - 0s 898us/step - loss: 0.2366 - accuracy: 0.9531 - val_loss: 0.9543 - val_accuracy: 0.5833\n",
      "Epoch 362/700\n",
      "384/384 [==============================] - 0s 832us/step - loss: 0.2566 - accuracy: 0.9479 - val_loss: 0.9621 - val_accuracy: 0.5833\n",
      "Epoch 363/700\n",
      "384/384 [==============================] - 0s 864us/step - loss: 0.2508 - accuracy: 0.9453 - val_loss: 0.9488 - val_accuracy: 0.5625\n",
      "Epoch 364/700\n",
      "384/384 [==============================] - 0s 881us/step - loss: 0.2448 - accuracy: 0.9453 - val_loss: 0.9724 - val_accuracy: 0.5938\n",
      "Epoch 365/700\n",
      "384/384 [==============================] - 0s 865us/step - loss: 0.2449 - accuracy: 0.9453 - val_loss: 0.9368 - val_accuracy: 0.5833\n",
      "Epoch 366/700\n",
      "384/384 [==============================] - 0s 869us/step - loss: 0.2344 - accuracy: 0.9635 - val_loss: 0.9238 - val_accuracy: 0.5833\n",
      "Epoch 367/700\n",
      "384/384 [==============================] - 0s 834us/step - loss: 0.2526 - accuracy: 0.9609 - val_loss: 0.9342 - val_accuracy: 0.5833\n",
      "Epoch 368/700\n",
      "384/384 [==============================] - 0s 883us/step - loss: 0.2295 - accuracy: 0.9609 - val_loss: 0.9453 - val_accuracy: 0.5625\n",
      "Epoch 369/700\n",
      "384/384 [==============================] - 0s 868us/step - loss: 0.2401 - accuracy: 0.9531 - val_loss: 0.9515 - val_accuracy: 0.5833\n",
      "Epoch 370/700\n",
      "384/384 [==============================] - 0s 886us/step - loss: 0.2285 - accuracy: 0.9635 - val_loss: 0.9740 - val_accuracy: 0.5625\n",
      "Epoch 371/700\n",
      "384/384 [==============================] - 0s 865us/step - loss: 0.2138 - accuracy: 0.9714 - val_loss: 0.9681 - val_accuracy: 0.5521\n",
      "Epoch 372/700\n",
      "384/384 [==============================] - 0s 893us/step - loss: 0.2359 - accuracy: 0.9583 - val_loss: 0.9324 - val_accuracy: 0.5833\n",
      "Epoch 373/700\n",
      "384/384 [==============================] - 0s 880us/step - loss: 0.2182 - accuracy: 0.9766 - val_loss: 0.9437 - val_accuracy: 0.5729\n",
      "Epoch 374/700\n",
      "384/384 [==============================] - 0s 861us/step - loss: 0.2147 - accuracy: 0.9688 - val_loss: 0.9835 - val_accuracy: 0.5833\n",
      "Epoch 375/700\n",
      "384/384 [==============================] - 0s 875us/step - loss: 0.2360 - accuracy: 0.9479 - val_loss: 0.9408 - val_accuracy: 0.5729\n",
      "Epoch 376/700\n",
      "384/384 [==============================] - 0s 868us/step - loss: 0.2161 - accuracy: 0.9661 - val_loss: 0.9839 - val_accuracy: 0.5833\n",
      "Epoch 377/700\n",
      "384/384 [==============================] - 0s 867us/step - loss: 0.2126 - accuracy: 0.9583 - val_loss: 0.9746 - val_accuracy: 0.5833\n",
      "Epoch 378/700\n",
      "384/384 [==============================] - 0s 927us/step - loss: 0.2241 - accuracy: 0.9583 - val_loss: 0.9594 - val_accuracy: 0.5729\n",
      "Epoch 379/700\n",
      "384/384 [==============================] - 0s 876us/step - loss: 0.2308 - accuracy: 0.9505 - val_loss: 0.9535 - val_accuracy: 0.5833\n",
      "Epoch 380/700\n",
      "384/384 [==============================] - 0s 892us/step - loss: 0.2057 - accuracy: 0.9688 - val_loss: 0.9913 - val_accuracy: 0.5938\n",
      "Epoch 381/700\n",
      "384/384 [==============================] - 0s 843us/step - loss: 0.2151 - accuracy: 0.9688 - val_loss: 0.9714 - val_accuracy: 0.5521\n",
      "Epoch 382/700\n",
      "384/384 [==============================] - 0s 896us/step - loss: 0.2026 - accuracy: 0.9714 - val_loss: 0.9619 - val_accuracy: 0.5729\n",
      "Epoch 383/700\n",
      "384/384 [==============================] - 0s 866us/step - loss: 0.1965 - accuracy: 0.9766 - val_loss: 0.9691 - val_accuracy: 0.5833\n",
      "Epoch 384/700\n",
      "384/384 [==============================] - 0s 920us/step - loss: 0.1924 - accuracy: 0.9792 - val_loss: 0.9585 - val_accuracy: 0.5833\n",
      "Epoch 385/700\n",
      "384/384 [==============================] - 0s 872us/step - loss: 0.2123 - accuracy: 0.9635 - val_loss: 0.9798 - val_accuracy: 0.5833\n",
      "Epoch 386/700\n",
      "384/384 [==============================] - 0s 875us/step - loss: 0.1914 - accuracy: 0.9766 - val_loss: 0.9757 - val_accuracy: 0.5938\n",
      "Epoch 387/700\n",
      "384/384 [==============================] - 0s 871us/step - loss: 0.2031 - accuracy: 0.9609 - val_loss: 0.9805 - val_accuracy: 0.5938\n",
      "Epoch 388/700\n",
      "384/384 [==============================] - 0s 875us/step - loss: 0.2000 - accuracy: 0.9792 - val_loss: 0.9564 - val_accuracy: 0.5938\n",
      "Epoch 389/700\n",
      "384/384 [==============================] - 0s 885us/step - loss: 0.2131 - accuracy: 0.9688 - val_loss: 0.9683 - val_accuracy: 0.5833\n",
      "Epoch 390/700\n",
      "384/384 [==============================] - 0s 895us/step - loss: 0.1887 - accuracy: 0.9688 - val_loss: 0.9619 - val_accuracy: 0.5625\n",
      "Epoch 391/700\n",
      "384/384 [==============================] - 0s 858us/step - loss: 0.1869 - accuracy: 0.9792 - val_loss: 0.9699 - val_accuracy: 0.5833\n",
      "Epoch 392/700\n",
      "384/384 [==============================] - 0s 902us/step - loss: 0.1862 - accuracy: 0.9766 - val_loss: 0.9778 - val_accuracy: 0.5938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/700\n",
      "384/384 [==============================] - 0s 864us/step - loss: 0.1890 - accuracy: 0.9740 - val_loss: 0.9871 - val_accuracy: 0.5729\n",
      "Epoch 394/700\n",
      "384/384 [==============================] - 0s 830us/step - loss: 0.2018 - accuracy: 0.9583 - val_loss: 0.9920 - val_accuracy: 0.5729\n",
      "Epoch 395/700\n",
      "384/384 [==============================] - 0s 890us/step - loss: 0.1829 - accuracy: 0.9740 - val_loss: 0.9797 - val_accuracy: 0.6042\n",
      "Epoch 396/700\n",
      "384/384 [==============================] - 0s 830us/step - loss: 0.1732 - accuracy: 0.9740 - val_loss: 0.9689 - val_accuracy: 0.5833\n",
      "Epoch 397/700\n",
      "384/384 [==============================] - 0s 870us/step - loss: 0.1711 - accuracy: 0.9896 - val_loss: 0.9615 - val_accuracy: 0.5833\n",
      "Epoch 398/700\n",
      "384/384 [==============================] - 0s 869us/step - loss: 0.1840 - accuracy: 0.9661 - val_loss: 0.9970 - val_accuracy: 0.5729\n",
      "Epoch 399/700\n",
      "384/384 [==============================] - 0s 871us/step - loss: 0.1709 - accuracy: 0.9844 - val_loss: 0.9874 - val_accuracy: 0.5833\n",
      "Epoch 400/700\n",
      "384/384 [==============================] - 0s 854us/step - loss: 0.1717 - accuracy: 0.9818 - val_loss: 1.0118 - val_accuracy: 0.5833\n",
      "Epoch 401/700\n",
      "384/384 [==============================] - 0s 853us/step - loss: 0.1814 - accuracy: 0.9766 - val_loss: 0.9800 - val_accuracy: 0.5729\n",
      "Epoch 402/700\n",
      "384/384 [==============================] - 0s 824us/step - loss: 0.1756 - accuracy: 0.9792 - val_loss: 1.0025 - val_accuracy: 0.5729\n",
      "Epoch 403/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 0.1611 - accuracy: 0.9844 - val_loss: 1.0072 - val_accuracy: 0.5729\n",
      "Epoch 404/700\n",
      "384/384 [==============================] - 0s 828us/step - loss: 0.1699 - accuracy: 0.9818 - val_loss: 0.9850 - val_accuracy: 0.5938\n",
      "Epoch 405/700\n",
      "384/384 [==============================] - 0s 879us/step - loss: 0.1563 - accuracy: 0.9844 - val_loss: 0.9816 - val_accuracy: 0.5729\n",
      "Epoch 406/700\n",
      "384/384 [==============================] - 0s 864us/step - loss: 0.1611 - accuracy: 0.9818 - val_loss: 0.9977 - val_accuracy: 0.5833\n",
      "Epoch 407/700\n",
      "384/384 [==============================] - 0s 916us/step - loss: 0.1621 - accuracy: 0.9844 - val_loss: 1.0047 - val_accuracy: 0.5729\n",
      "Epoch 408/700\n",
      "384/384 [==============================] - 0s 865us/step - loss: 0.1531 - accuracy: 0.9766 - val_loss: 1.0142 - val_accuracy: 0.5938\n",
      "Epoch 409/700\n",
      "384/384 [==============================] - 0s 886us/step - loss: 0.1579 - accuracy: 0.9818 - val_loss: 1.0048 - val_accuracy: 0.5729\n",
      "Epoch 410/700\n",
      "384/384 [==============================] - 0s 868us/step - loss: 0.1611 - accuracy: 0.9792 - val_loss: 0.9809 - val_accuracy: 0.5938\n",
      "Epoch 411/700\n",
      "384/384 [==============================] - 0s 906us/step - loss: 0.1641 - accuracy: 0.9792 - val_loss: 0.9951 - val_accuracy: 0.5729\n",
      "Epoch 412/700\n",
      "384/384 [==============================] - 0s 864us/step - loss: 0.1470 - accuracy: 0.9896 - val_loss: 1.0059 - val_accuracy: 0.5729\n",
      "Epoch 413/700\n",
      "384/384 [==============================] - 0s 892us/step - loss: 0.1494 - accuracy: 0.9792 - val_loss: 1.0043 - val_accuracy: 0.5833\n",
      "Epoch 414/700\n",
      "384/384 [==============================] - 0s 862us/step - loss: 0.1471 - accuracy: 0.9792 - val_loss: 1.0304 - val_accuracy: 0.5729\n",
      "Epoch 415/700\n",
      "384/384 [==============================] - 0s 896us/step - loss: 0.1508 - accuracy: 0.9844 - val_loss: 0.9889 - val_accuracy: 0.5729\n",
      "Epoch 416/700\n",
      "384/384 [==============================] - 0s 850us/step - loss: 0.1381 - accuracy: 0.9922 - val_loss: 0.9900 - val_accuracy: 0.5938\n",
      "Epoch 417/700\n",
      "384/384 [==============================] - 0s 873us/step - loss: 0.1478 - accuracy: 0.9870 - val_loss: 1.0112 - val_accuracy: 0.5833\n",
      "Epoch 418/700\n",
      "384/384 [==============================] - 0s 887us/step - loss: 0.1476 - accuracy: 0.9870 - val_loss: 1.0234 - val_accuracy: 0.5938\n",
      "Epoch 419/700\n",
      "384/384 [==============================] - 0s 875us/step - loss: 0.1413 - accuracy: 0.9844 - val_loss: 0.9794 - val_accuracy: 0.5729\n",
      "Epoch 420/700\n",
      "384/384 [==============================] - 0s 913us/step - loss: 0.1485 - accuracy: 0.9818 - val_loss: 0.9953 - val_accuracy: 0.5729\n",
      "Epoch 421/700\n",
      "384/384 [==============================] - 0s 869us/step - loss: 0.1359 - accuracy: 0.9922 - val_loss: 1.0020 - val_accuracy: 0.5938\n",
      "Epoch 422/700\n",
      "384/384 [==============================] - 0s 915us/step - loss: 0.1478 - accuracy: 0.9766 - val_loss: 1.0039 - val_accuracy: 0.5833\n",
      "Epoch 423/700\n",
      "384/384 [==============================] - 0s 858us/step - loss: 0.1449 - accuracy: 0.9870 - val_loss: 0.9975 - val_accuracy: 0.5729\n",
      "Epoch 424/700\n",
      "384/384 [==============================] - 0s 907us/step - loss: 0.1526 - accuracy: 0.9792 - val_loss: 1.0035 - val_accuracy: 0.5833\n",
      "Epoch 425/700\n",
      "384/384 [==============================] - 0s 853us/step - loss: 0.1367 - accuracy: 0.9948 - val_loss: 1.0245 - val_accuracy: 0.5833\n",
      "Epoch 426/700\n",
      "384/384 [==============================] - 0s 877us/step - loss: 0.1327 - accuracy: 0.9870 - val_loss: 1.0275 - val_accuracy: 0.5833\n",
      "Epoch 427/700\n",
      "384/384 [==============================] - 0s 862us/step - loss: 0.1332 - accuracy: 0.9896 - val_loss: 1.0084 - val_accuracy: 0.5938\n",
      "Epoch 428/700\n",
      "384/384 [==============================] - 0s 864us/step - loss: 0.1355 - accuracy: 0.9844 - val_loss: 1.0305 - val_accuracy: 0.5729\n",
      "Epoch 429/700\n",
      "384/384 [==============================] - 0s 845us/step - loss: 0.1322 - accuracy: 0.9818 - val_loss: 1.0275 - val_accuracy: 0.5833\n",
      "Epoch 430/700\n",
      "384/384 [==============================] - 0s 882us/step - loss: 0.1411 - accuracy: 0.9844 - val_loss: 1.0336 - val_accuracy: 0.5938\n",
      "Epoch 431/700\n",
      "384/384 [==============================] - 0s 848us/step - loss: 0.1242 - accuracy: 0.9896 - val_loss: 0.9967 - val_accuracy: 0.5833\n",
      "Epoch 432/700\n",
      "384/384 [==============================] - 0s 890us/step - loss: 0.1286 - accuracy: 0.9922 - val_loss: 1.0139 - val_accuracy: 0.5729\n",
      "Epoch 433/700\n",
      "384/384 [==============================] - 0s 844us/step - loss: 0.1172 - accuracy: 0.9922 - val_loss: 0.9990 - val_accuracy: 0.6042\n",
      "Epoch 434/700\n",
      "384/384 [==============================] - 0s 893us/step - loss: 0.1317 - accuracy: 0.9844 - val_loss: 0.9926 - val_accuracy: 0.5833\n",
      "Epoch 435/700\n",
      "384/384 [==============================] - 0s 833us/step - loss: 0.1257 - accuracy: 0.9870 - val_loss: 1.0279 - val_accuracy: 0.5833\n",
      "Epoch 436/700\n",
      "384/384 [==============================] - 0s 900us/step - loss: 0.1205 - accuracy: 0.9870 - val_loss: 1.0296 - val_accuracy: 0.6042\n",
      "Epoch 437/700\n",
      "384/384 [==============================] - 0s 849us/step - loss: 0.1178 - accuracy: 0.9896 - val_loss: 0.9894 - val_accuracy: 0.5938\n",
      "Epoch 438/700\n",
      "384/384 [==============================] - 0s 873us/step - loss: 0.1195 - accuracy: 0.9922 - val_loss: 1.0001 - val_accuracy: 0.5729\n",
      "Epoch 439/700\n",
      "384/384 [==============================] - 0s 880us/step - loss: 0.1197 - accuracy: 0.9948 - val_loss: 1.0218 - val_accuracy: 0.5833\n",
      "Epoch 440/700\n",
      "384/384 [==============================] - 0s 868us/step - loss: 0.1232 - accuracy: 0.9818 - val_loss: 1.0346 - val_accuracy: 0.5938\n",
      "Epoch 441/700\n",
      "384/384 [==============================] - 0s 893us/step - loss: 0.1145 - accuracy: 0.9922 - val_loss: 1.0318 - val_accuracy: 0.5833\n",
      "Epoch 442/700\n",
      "384/384 [==============================] - 0s 881us/step - loss: 0.1247 - accuracy: 0.9896 - val_loss: 1.0250 - val_accuracy: 0.6042\n",
      "Epoch 443/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 0.1105 - accuracy: 0.9896 - val_loss: 1.0503 - val_accuracy: 0.5938\n",
      "Epoch 444/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 0.1108 - accuracy: 1.0000 - val_loss: 1.0280 - val_accuracy: 0.6042\n",
      "Epoch 445/700\n",
      "384/384 [==============================] - 0s 896us/step - loss: 0.1106 - accuracy: 0.9922 - val_loss: 1.0375 - val_accuracy: 0.5729\n",
      "Epoch 446/700\n",
      "384/384 [==============================] - 0s 899us/step - loss: 0.0997 - accuracy: 0.9974 - val_loss: 1.0626 - val_accuracy: 0.5833\n",
      "Epoch 447/700\n",
      "384/384 [==============================] - 0s 871us/step - loss: 0.1061 - accuracy: 0.9922 - val_loss: 1.0419 - val_accuracy: 0.6042\n",
      "Epoch 448/700\n",
      "384/384 [==============================] - 0s 868us/step - loss: 0.1069 - accuracy: 0.9922 - val_loss: 1.0588 - val_accuracy: 0.5833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/700\n",
      "384/384 [==============================] - 0s 879us/step - loss: 0.1067 - accuracy: 0.9896 - val_loss: 1.0424 - val_accuracy: 0.5938\n",
      "Epoch 450/700\n",
      "384/384 [==============================] - 0s 847us/step - loss: 0.1094 - accuracy: 0.9870 - val_loss: 1.0378 - val_accuracy: 0.5938\n",
      "Epoch 451/700\n",
      "384/384 [==============================] - 0s 871us/step - loss: 0.0907 - accuracy: 0.9948 - val_loss: 1.0180 - val_accuracy: 0.5938\n",
      "Epoch 452/700\n",
      "384/384 [==============================] - 0s 855us/step - loss: 0.1055 - accuracy: 0.9922 - val_loss: 1.0654 - val_accuracy: 0.5833\n",
      "Epoch 453/700\n",
      "384/384 [==============================] - 0s 885us/step - loss: 0.0953 - accuracy: 0.9922 - val_loss: 1.0467 - val_accuracy: 0.5938\n",
      "Epoch 454/700\n",
      "384/384 [==============================] - 0s 818us/step - loss: 0.1057 - accuracy: 0.9870 - val_loss: 1.0787 - val_accuracy: 0.5833\n",
      "Epoch 455/700\n",
      "384/384 [==============================] - 0s 898us/step - loss: 0.0974 - accuracy: 0.9948 - val_loss: 1.0837 - val_accuracy: 0.5833\n",
      "Epoch 456/700\n",
      "384/384 [==============================] - 0s 912us/step - loss: 0.1053 - accuracy: 0.9896 - val_loss: 1.0238 - val_accuracy: 0.5833\n",
      "Epoch 457/700\n",
      "384/384 [==============================] - 0s 850us/step - loss: 0.1099 - accuracy: 0.9896 - val_loss: 1.0329 - val_accuracy: 0.5938\n",
      "Epoch 458/700\n",
      "384/384 [==============================] - 0s 834us/step - loss: 0.1061 - accuracy: 0.9922 - val_loss: 1.0392 - val_accuracy: 0.5938\n",
      "Epoch 459/700\n",
      "384/384 [==============================] - 0s 897us/step - loss: 0.0867 - accuracy: 0.9974 - val_loss: 1.0832 - val_accuracy: 0.5833\n",
      "Epoch 460/700\n",
      "384/384 [==============================] - 0s 845us/step - loss: 0.0978 - accuracy: 0.9974 - val_loss: 1.0424 - val_accuracy: 0.5833\n",
      "Epoch 461/700\n",
      "384/384 [==============================] - 0s 859us/step - loss: 0.1061 - accuracy: 0.9870 - val_loss: 1.0573 - val_accuracy: 0.5833\n",
      "Epoch 462/700\n",
      "384/384 [==============================] - 0s 860us/step - loss: 0.0903 - accuracy: 0.9974 - val_loss: 1.0499 - val_accuracy: 0.5833\n",
      "Epoch 463/700\n",
      "384/384 [==============================] - 0s 851us/step - loss: 0.0885 - accuracy: 0.9948 - val_loss: 1.0420 - val_accuracy: 0.5833\n",
      "Epoch 464/700\n",
      "384/384 [==============================] - 0s 856us/step - loss: 0.0896 - accuracy: 0.9922 - val_loss: 1.0739 - val_accuracy: 0.5833\n",
      "Epoch 465/700\n",
      "384/384 [==============================] - 0s 895us/step - loss: 0.0914 - accuracy: 0.9922 - val_loss: 1.0641 - val_accuracy: 0.5833\n",
      "Epoch 466/700\n",
      "384/384 [==============================] - 0s 872us/step - loss: 0.0840 - accuracy: 0.9974 - val_loss: 1.0311 - val_accuracy: 0.5938\n",
      "Epoch 467/700\n",
      "384/384 [==============================] - 0s 881us/step - loss: 0.0872 - accuracy: 0.9948 - val_loss: 1.0645 - val_accuracy: 0.5938\n",
      "Epoch 468/700\n",
      "384/384 [==============================] - 0s 861us/step - loss: 0.0732 - accuracy: 1.0000 - val_loss: 1.0606 - val_accuracy: 0.5938\n",
      "Epoch 469/700\n",
      "384/384 [==============================] - 0s 863us/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 1.0957 - val_accuracy: 0.5938\n",
      "Epoch 470/700\n",
      "384/384 [==============================] - 0s 877us/step - loss: 0.0807 - accuracy: 0.9922 - val_loss: 1.0529 - val_accuracy: 0.5938\n",
      "Epoch 471/700\n",
      "384/384 [==============================] - 0s 874us/step - loss: 0.0812 - accuracy: 0.9948 - val_loss: 1.0499 - val_accuracy: 0.5938\n",
      "Epoch 472/700\n",
      "384/384 [==============================] - 0s 863us/step - loss: 0.0873 - accuracy: 0.9922 - val_loss: 1.0896 - val_accuracy: 0.6042\n",
      "Epoch 473/700\n",
      "384/384 [==============================] - 0s 893us/step - loss: 0.0805 - accuracy: 0.9974 - val_loss: 1.0650 - val_accuracy: 0.5938\n",
      "Epoch 474/700\n",
      "384/384 [==============================] - 0s 865us/step - loss: 0.0811 - accuracy: 0.9974 - val_loss: 1.0575 - val_accuracy: 0.6042\n",
      "Epoch 475/700\n",
      "384/384 [==============================] - 0s 827us/step - loss: 0.0789 - accuracy: 0.9974 - val_loss: 1.0669 - val_accuracy: 0.5938\n",
      "Epoch 476/700\n",
      "384/384 [==============================] - 0s 892us/step - loss: 0.0757 - accuracy: 0.9948 - val_loss: 1.0925 - val_accuracy: 0.6042\n",
      "Epoch 477/700\n",
      "384/384 [==============================] - 0s 858us/step - loss: 0.0804 - accuracy: 0.9948 - val_loss: 1.0895 - val_accuracy: 0.5938\n",
      "Epoch 478/700\n",
      "384/384 [==============================] - 0s 876us/step - loss: 0.0731 - accuracy: 0.9974 - val_loss: 1.0654 - val_accuracy: 0.5833\n",
      "Epoch 479/700\n",
      "384/384 [==============================] - 0s 867us/step - loss: 0.0774 - accuracy: 0.9974 - val_loss: 1.0989 - val_accuracy: 0.5938\n",
      "Epoch 480/700\n",
      "384/384 [==============================] - 0s 893us/step - loss: 0.0709 - accuracy: 0.9974 - val_loss: 1.0878 - val_accuracy: 0.5938\n",
      "Epoch 481/700\n",
      "384/384 [==============================] - 0s 844us/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 1.1023 - val_accuracy: 0.6042\n",
      "Epoch 482/700\n",
      "384/384 [==============================] - 0s 890us/step - loss: 0.0739 - accuracy: 0.9948 - val_loss: 1.0739 - val_accuracy: 0.5833\n",
      "Epoch 483/700\n",
      "384/384 [==============================] - 0s 860us/step - loss: 0.0838 - accuracy: 0.9922 - val_loss: 1.0653 - val_accuracy: 0.5938\n",
      "Epoch 484/700\n",
      "384/384 [==============================] - 0s 890us/step - loss: 0.0696 - accuracy: 1.0000 - val_loss: 1.0752 - val_accuracy: 0.5833\n",
      "Epoch 485/700\n",
      "384/384 [==============================] - 0s 852us/step - loss: 0.0676 - accuracy: 0.9974 - val_loss: 1.1099 - val_accuracy: 0.6042\n",
      "Epoch 486/700\n",
      "384/384 [==============================] - 0s 897us/step - loss: 0.0615 - accuracy: 0.9974 - val_loss: 1.0950 - val_accuracy: 0.5938\n",
      "Epoch 487/700\n",
      "384/384 [==============================] - 0s 832us/step - loss: 0.0627 - accuracy: 0.9974 - val_loss: 1.1235 - val_accuracy: 0.5833\n",
      "Epoch 488/700\n",
      "384/384 [==============================] - 0s 859us/step - loss: 0.0585 - accuracy: 0.9974 - val_loss: 1.0770 - val_accuracy: 0.5938\n",
      "Epoch 489/700\n",
      "384/384 [==============================] - 0s 853us/step - loss: 0.0620 - accuracy: 0.9974 - val_loss: 1.0959 - val_accuracy: 0.6042\n",
      "Epoch 490/700\n",
      "384/384 [==============================] - 0s 829us/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 1.1209 - val_accuracy: 0.6042\n",
      "Epoch 491/700\n",
      "384/384 [==============================] - 0s 895us/step - loss: 0.0605 - accuracy: 0.9974 - val_loss: 1.0435 - val_accuracy: 0.6042\n",
      "Epoch 492/700\n",
      "384/384 [==============================] - 0s 832us/step - loss: 0.0632 - accuracy: 0.9948 - val_loss: 1.0859 - val_accuracy: 0.5938\n",
      "Epoch 493/700\n",
      "384/384 [==============================] - 0s 869us/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 1.0812 - val_accuracy: 0.5938\n",
      "Epoch 494/700\n",
      "384/384 [==============================] - 0s 893us/step - loss: 0.0736 - accuracy: 0.9948 - val_loss: 1.0971 - val_accuracy: 0.5833\n",
      "Epoch 495/700\n",
      "384/384 [==============================] - 0s 865us/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 1.0653 - val_accuracy: 0.5938\n",
      "Epoch 496/700\n",
      "384/384 [==============================] - 0s 860us/step - loss: 0.0628 - accuracy: 0.9974 - val_loss: 1.1308 - val_accuracy: 0.6042\n",
      "Epoch 497/700\n",
      "384/384 [==============================] - 0s 897us/step - loss: 0.0581 - accuracy: 0.9974 - val_loss: 1.1162 - val_accuracy: 0.5938\n",
      "Epoch 498/700\n",
      "384/384 [==============================] - 0s 847us/step - loss: 0.0611 - accuracy: 0.9948 - val_loss: 1.1146 - val_accuracy: 0.6042\n",
      "Epoch 499/700\n",
      "384/384 [==============================] - 0s 883us/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 1.1192 - val_accuracy: 0.5833\n",
      "Epoch 500/700\n",
      "384/384 [==============================] - 0s 874us/step - loss: 0.0575 - accuracy: 0.9974 - val_loss: 1.1146 - val_accuracy: 0.6042\n",
      "Epoch 501/700\n",
      "384/384 [==============================] - 0s 906us/step - loss: 0.0596 - accuracy: 0.9974 - val_loss: 1.1169 - val_accuracy: 0.5833\n",
      "Epoch 502/700\n",
      "384/384 [==============================] - 0s 833us/step - loss: 0.0656 - accuracy: 0.9922 - val_loss: 1.1022 - val_accuracy: 0.5833\n",
      "Epoch 503/700\n",
      "384/384 [==============================] - 0s 885us/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 1.1484 - val_accuracy: 0.5938\n",
      "Epoch 504/700\n",
      "384/384 [==============================] - 0s 837us/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 1.1269 - val_accuracy: 0.5938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/700\n",
      "384/384 [==============================] - 0s 877us/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 1.1238 - val_accuracy: 0.5833\n",
      "Epoch 506/700\n",
      "384/384 [==============================] - 0s 822us/step - loss: 0.0553 - accuracy: 0.9974 - val_loss: 1.1316 - val_accuracy: 0.5833\n",
      "Epoch 507/700\n",
      "384/384 [==============================] - 0s 849us/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 1.0991 - val_accuracy: 0.6042\n",
      "Epoch 508/700\n",
      "384/384 [==============================] - 0s 869us/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 1.1142 - val_accuracy: 0.5833\n",
      "Epoch 509/700\n",
      "384/384 [==============================] - 0s 879us/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 1.0977 - val_accuracy: 0.5938\n",
      "Epoch 510/700\n",
      "384/384 [==============================] - 0s 863us/step - loss: 0.0537 - accuracy: 0.9922 - val_loss: 1.0749 - val_accuracy: 0.5833\n",
      "Epoch 511/700\n",
      "384/384 [==============================] - 0s 870us/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 1.1514 - val_accuracy: 0.6042\n",
      "Epoch 512/700\n",
      "384/384 [==============================] - 0s 889us/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 1.1096 - val_accuracy: 0.6042\n",
      "Epoch 513/700\n",
      "384/384 [==============================] - 0s 879us/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 1.1531 - val_accuracy: 0.5938\n",
      "Epoch 514/700\n",
      "384/384 [==============================] - 0s 851us/step - loss: 0.0479 - accuracy: 1.0000 - val_loss: 1.1197 - val_accuracy: 0.5938\n",
      "Epoch 515/700\n",
      "384/384 [==============================] - 0s 892us/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 1.1361 - val_accuracy: 0.6042\n",
      "Epoch 516/700\n",
      "384/384 [==============================] - 0s 876us/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 1.1050 - val_accuracy: 0.6146\n",
      "Epoch 517/700\n",
      "384/384 [==============================] - 0s 822us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 1.1570 - val_accuracy: 0.5833\n",
      "Epoch 518/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0566 - accuracy: 0.9896 - val_loss: 1.1443 - val_accuracy: 0.5938\n",
      "Epoch 519/700\n",
      "384/384 [==============================] - 0s 821us/step - loss: 0.0474 - accuracy: 0.9922 - val_loss: 1.1425 - val_accuracy: 0.5833\n",
      "Epoch 520/700\n",
      "384/384 [==============================] - 0s 879us/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 1.1683 - val_accuracy: 0.5833\n",
      "Epoch 521/700\n",
      "384/384 [==============================] - 0s 874us/step - loss: 0.0502 - accuracy: 0.9948 - val_loss: 1.2093 - val_accuracy: 0.6042\n",
      "Epoch 522/700\n",
      "384/384 [==============================] - 0s 846us/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 1.1577 - val_accuracy: 0.6042\n",
      "Epoch 523/700\n",
      "384/384 [==============================] - 0s 826us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 1.1819 - val_accuracy: 0.5938\n",
      "Epoch 524/700\n",
      "384/384 [==============================] - 0s 842us/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 1.1112 - val_accuracy: 0.6042\n",
      "Epoch 525/700\n",
      "384/384 [==============================] - 0s 860us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 1.2032 - val_accuracy: 0.5938\n",
      "Epoch 526/700\n",
      "384/384 [==============================] - 0s 873us/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 1.1518 - val_accuracy: 0.5833\n",
      "Epoch 527/700\n",
      "384/384 [==============================] - 0s 866us/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 1.1078 - val_accuracy: 0.5833\n",
      "Epoch 528/700\n",
      "384/384 [==============================] - 0s 882us/step - loss: 0.0433 - accuracy: 0.9974 - val_loss: 1.1534 - val_accuracy: 0.5729\n",
      "Epoch 529/700\n",
      "384/384 [==============================] - 0s 844us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 1.1158 - val_accuracy: 0.5938\n",
      "Epoch 530/700\n",
      "384/384 [==============================] - 0s 838us/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 1.1460 - val_accuracy: 0.6042\n",
      "Epoch 531/700\n",
      "384/384 [==============================] - 0s 876us/step - loss: 0.0379 - accuracy: 0.9974 - val_loss: 1.1765 - val_accuracy: 0.5938\n",
      "Epoch 532/700\n",
      "384/384 [==============================] - 0s 823us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 1.1677 - val_accuracy: 0.6042\n",
      "Epoch 533/700\n",
      "384/384 [==============================] - 0s 866us/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 1.1183 - val_accuracy: 0.6042\n",
      "Epoch 534/700\n",
      "384/384 [==============================] - 0s 872us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 1.1366 - val_accuracy: 0.6042\n",
      "Epoch 535/700\n",
      "384/384 [==============================] - 0s 872us/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 1.1782 - val_accuracy: 0.5938\n",
      "Epoch 536/700\n",
      "384/384 [==============================] - 0s 885us/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 1.1824 - val_accuracy: 0.5833\n",
      "Epoch 537/700\n",
      "384/384 [==============================] - 0s 894us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 1.1635 - val_accuracy: 0.5833\n",
      "Epoch 538/700\n",
      "384/384 [==============================] - 0s 869us/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 1.2051 - val_accuracy: 0.5938\n",
      "Epoch 539/700\n",
      "384/384 [==============================] - 0s 858us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 1.2060 - val_accuracy: 0.5833\n",
      "Epoch 540/700\n",
      "384/384 [==============================] - 0s 860us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 1.1606 - val_accuracy: 0.5729\n",
      "Epoch 541/700\n",
      "384/384 [==============================] - 0s 876us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 1.1611 - val_accuracy: 0.5729\n",
      "Epoch 542/700\n",
      "384/384 [==============================] - 0s 860us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 1.1953 - val_accuracy: 0.6042\n",
      "Epoch 543/700\n",
      "384/384 [==============================] - 0s 902us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 1.1874 - val_accuracy: 0.6146\n",
      "Epoch 544/700\n",
      "384/384 [==============================] - 0s 841us/step - loss: 0.0352 - accuracy: 0.9974 - val_loss: 1.1853 - val_accuracy: 0.5938\n",
      "Epoch 545/700\n",
      "384/384 [==============================] - 0s 861us/step - loss: 0.0349 - accuracy: 0.9974 - val_loss: 1.1974 - val_accuracy: 0.5833\n",
      "Epoch 546/700\n",
      "384/384 [==============================] - 0s 892us/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 1.1769 - val_accuracy: 0.5938\n",
      "Epoch 547/700\n",
      "384/384 [==============================] - 0s 859us/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 1.1823 - val_accuracy: 0.5833\n",
      "Epoch 548/700\n",
      "384/384 [==============================] - 0s 838us/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 1.1599 - val_accuracy: 0.6042\n",
      "Epoch 549/700\n",
      "384/384 [==============================] - 0s 887us/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 1.1947 - val_accuracy: 0.5938\n",
      "Epoch 550/700\n",
      "384/384 [==============================] - 0s 851us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 1.2360 - val_accuracy: 0.6042\n",
      "Epoch 551/700\n",
      "384/384 [==============================] - 0s 906us/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 1.1942 - val_accuracy: 0.5729\n",
      "Epoch 552/700\n",
      "384/384 [==============================] - 0s 864us/step - loss: 0.0331 - accuracy: 0.9974 - val_loss: 1.1357 - val_accuracy: 0.5938\n",
      "Epoch 553/700\n",
      "384/384 [==============================] - 0s 834us/step - loss: 0.0330 - accuracy: 0.9974 - val_loss: 1.1608 - val_accuracy: 0.6042\n",
      "Epoch 554/700\n",
      "384/384 [==============================] - 0s 888us/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 1.2194 - val_accuracy: 0.5833\n",
      "Epoch 555/700\n",
      "384/384 [==============================] - 0s 844us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 1.2260 - val_accuracy: 0.6042\n",
      "Epoch 556/700\n",
      "384/384 [==============================] - 0s 889us/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 1.2186 - val_accuracy: 0.6250\n",
      "Epoch 557/700\n",
      "384/384 [==============================] - 0s 886us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 1.2235 - val_accuracy: 0.5833\n",
      "Epoch 558/700\n",
      "384/384 [==============================] - 0s 886us/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.5833\n",
      "Epoch 559/700\n",
      "384/384 [==============================] - 0s 891us/step - loss: 0.0263 - accuracy: 0.9974 - val_loss: 1.2180 - val_accuracy: 0.5938\n",
      "Epoch 560/700\n",
      "384/384 [==============================] - 0s 906us/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 1.2688 - val_accuracy: 0.6042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/700\n",
      "384/384 [==============================] - 0s 850us/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 1.2077 - val_accuracy: 0.5938\n",
      "Epoch 562/700\n",
      "384/384 [==============================] - 0s 856us/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 1.2455 - val_accuracy: 0.5833\n",
      "Epoch 563/700\n",
      "384/384 [==============================] - 0s 893us/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.2373 - val_accuracy: 0.6042\n",
      "Epoch 564/700\n",
      "384/384 [==============================] - 0s 831us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.2356 - val_accuracy: 0.5833\n",
      "Epoch 565/700\n",
      "384/384 [==============================] - 0s 871us/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 1.2062 - val_accuracy: 0.6042\n",
      "Epoch 566/700\n",
      "384/384 [==============================] - 0s 848us/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 1.2324 - val_accuracy: 0.5833\n",
      "Epoch 567/700\n",
      "384/384 [==============================] - 0s 818us/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 1.2818 - val_accuracy: 0.5938\n",
      "Epoch 568/700\n",
      "384/384 [==============================] - 0s 847us/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.2911 - val_accuracy: 0.5938\n",
      "Epoch 569/700\n",
      "384/384 [==============================] - 0s 823us/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.1981 - val_accuracy: 0.5833\n",
      "Epoch 570/700\n",
      "384/384 [==============================] - 0s 855us/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 1.2113 - val_accuracy: 0.6042\n",
      "Epoch 571/700\n",
      "384/384 [==============================] - 0s 826us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.2734 - val_accuracy: 0.5833\n",
      "Epoch 572/700\n",
      "384/384 [==============================] - 0s 882us/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.6042\n",
      "Epoch 573/700\n",
      "384/384 [==============================] - 0s 839us/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.2693 - val_accuracy: 0.5938\n",
      "Epoch 574/700\n",
      "384/384 [==============================] - 0s 819us/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 1.2776 - val_accuracy: 0.6042\n",
      "Epoch 575/700\n",
      "384/384 [==============================] - 0s 878us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.2569 - val_accuracy: 0.5833\n",
      "Epoch 576/700\n",
      "384/384 [==============================] - 0s 840us/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.2218 - val_accuracy: 0.5729\n",
      "Epoch 577/700\n",
      "384/384 [==============================] - 0s 864us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.2971 - val_accuracy: 0.6042\n",
      "Epoch 578/700\n",
      "384/384 [==============================] - 0s 876us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.2489 - val_accuracy: 0.5938\n",
      "Epoch 579/700\n",
      "384/384 [==============================] - 0s 899us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.2491 - val_accuracy: 0.5938\n",
      "Epoch 580/700\n",
      "384/384 [==============================] - 0s 865us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.2464 - val_accuracy: 0.6042\n",
      "Epoch 581/700\n",
      "384/384 [==============================] - 0s 908us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.2023 - val_accuracy: 0.5833\n",
      "Epoch 582/700\n",
      "384/384 [==============================] - 0s 844us/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.2593 - val_accuracy: 0.6042\n",
      "Epoch 583/700\n",
      "384/384 [==============================] - 0s 885us/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.2824 - val_accuracy: 0.6042\n",
      "Epoch 584/700\n",
      "384/384 [==============================] - 0s 836us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.3099 - val_accuracy: 0.6042\n",
      "Epoch 585/700\n",
      "384/384 [==============================] - 0s 851us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.2375 - val_accuracy: 0.5938\n",
      "Epoch 586/700\n",
      "384/384 [==============================] - 0s 871us/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.2375 - val_accuracy: 0.6042\n",
      "Epoch 587/700\n",
      "384/384 [==============================] - 0s 897us/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.2868 - val_accuracy: 0.6042\n",
      "Epoch 588/700\n",
      "384/384 [==============================] - 0s 866us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.2584 - val_accuracy: 0.5938\n",
      "Epoch 589/700\n",
      "384/384 [==============================] - 0s 898us/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.2584 - val_accuracy: 0.5938\n",
      "Epoch 590/700\n",
      "384/384 [==============================] - 0s 840us/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.2816 - val_accuracy: 0.5833\n",
      "Epoch 591/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.3007 - val_accuracy: 0.5729\n",
      "Epoch 592/700\n",
      "384/384 [==============================] - 0s 863us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.2952 - val_accuracy: 0.5833\n",
      "Epoch 593/700\n",
      "384/384 [==============================] - 0s 903us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.2917 - val_accuracy: 0.6042\n",
      "Epoch 594/700\n",
      "384/384 [==============================] - 0s 831us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.2702 - val_accuracy: 0.5938\n",
      "Epoch 595/700\n",
      "384/384 [==============================] - 0s 866us/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.3033 - val_accuracy: 0.5938\n",
      "Epoch 596/700\n",
      "384/384 [==============================] - 0s 947us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.2755 - val_accuracy: 0.5938\n",
      "Epoch 597/700\n",
      "384/384 [==============================] - 0s 933us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.2994 - val_accuracy: 0.6042\n",
      "Epoch 598/700\n",
      "384/384 [==============================] - 0s 912us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 1.3259 - val_accuracy: 0.5833\n",
      "Epoch 599/700\n",
      "384/384 [==============================] - 0s 887us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.2909 - val_accuracy: 0.5833\n",
      "Epoch 600/700\n",
      "384/384 [==============================] - 0s 852us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.2973 - val_accuracy: 0.5833\n",
      "Epoch 601/700\n",
      "384/384 [==============================] - 0s 843us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.3260 - val_accuracy: 0.5938\n",
      "Epoch 602/700\n",
      "384/384 [==============================] - 0s 944us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.3287 - val_accuracy: 0.5729\n",
      "Epoch 603/700\n",
      "384/384 [==============================] - 0s 862us/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.3023 - val_accuracy: 0.5833\n",
      "Epoch 604/700\n",
      "384/384 [==============================] - 0s 854us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.3500 - val_accuracy: 0.5729\n",
      "Epoch 605/700\n",
      "384/384 [==============================] - 0s 870us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.3280 - val_accuracy: 0.5833\n",
      "Epoch 606/700\n",
      "384/384 [==============================] - 0s 903us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.3094 - val_accuracy: 0.5938\n",
      "Epoch 607/700\n",
      "384/384 [==============================] - 0s 888us/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.3639 - val_accuracy: 0.5938\n",
      "Epoch 608/700\n",
      "384/384 [==============================] - 0s 881us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.3629 - val_accuracy: 0.6042\n",
      "Epoch 609/700\n",
      "384/384 [==============================] - 0s 885us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.2869 - val_accuracy: 0.5938\n",
      "Epoch 610/700\n",
      "384/384 [==============================] - 0s 891us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3297 - val_accuracy: 0.5833\n",
      "Epoch 611/700\n",
      "384/384 [==============================] - 0s 862us/step - loss: 0.0157 - accuracy: 0.9974 - val_loss: 1.2768 - val_accuracy: 0.5938\n",
      "Epoch 612/700\n",
      "384/384 [==============================] - 0s 856us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.3166 - val_accuracy: 0.5833\n",
      "Epoch 613/700\n",
      "384/384 [==============================] - 0s 878us/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.3285 - val_accuracy: 0.6042\n",
      "Epoch 614/700\n",
      "384/384 [==============================] - 0s 904us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.2984 - val_accuracy: 0.5729\n",
      "Epoch 615/700\n",
      "384/384 [==============================] - 0s 909us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.3459 - val_accuracy: 0.5833\n",
      "Epoch 616/700\n",
      "384/384 [==============================] - 0s 980us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.3380 - val_accuracy: 0.6042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/700\n",
      "384/384 [==============================] - 0s 904us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.3164 - val_accuracy: 0.5833\n",
      "Epoch 618/700\n",
      "384/384 [==============================] - 0s 902us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.3510 - val_accuracy: 0.5833\n",
      "Epoch 619/700\n",
      "384/384 [==============================] - 1s 1ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.3848 - val_accuracy: 0.6042\n",
      "Epoch 620/700\n",
      "384/384 [==============================] - 0s 909us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.3781 - val_accuracy: 0.5729\n",
      "Epoch 621/700\n",
      "384/384 [==============================] - 0s 950us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3843 - val_accuracy: 0.5729\n",
      "Epoch 622/700\n",
      "384/384 [==============================] - 0s 890us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.3248 - val_accuracy: 0.5833\n",
      "Epoch 623/700\n",
      "384/384 [==============================] - 0s 910us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.3416 - val_accuracy: 0.5938\n",
      "Epoch 624/700\n",
      "384/384 [==============================] - 0s 963us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.3304 - val_accuracy: 0.6042\n",
      "Epoch 625/700\n",
      "384/384 [==============================] - 0s 938us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.3025 - val_accuracy: 0.5938\n",
      "Epoch 626/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.3141 - val_accuracy: 0.6146\n",
      "Epoch 627/700\n",
      "384/384 [==============================] - 0s 969us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.3019 - val_accuracy: 0.5833\n",
      "Epoch 628/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.2925 - val_accuracy: 0.6146\n",
      "Epoch 629/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.3389 - val_accuracy: 0.5938\n",
      "Epoch 630/700\n",
      "384/384 [==============================] - 0s 956us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.3892 - val_accuracy: 0.5625\n",
      "Epoch 631/700\n",
      "384/384 [==============================] - 0s 992us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.3300 - val_accuracy: 0.5729\n",
      "Epoch 632/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.3914 - val_accuracy: 0.5938\n",
      "Epoch 633/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.4171 - val_accuracy: 0.5938\n",
      "Epoch 634/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.3504 - val_accuracy: 0.6042\n",
      "Epoch 635/700\n",
      "384/384 [==============================] - 0s 850us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.3861 - val_accuracy: 0.5938\n",
      "Epoch 636/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 0.9974 - val_loss: 1.4741 - val_accuracy: 0.6042\n",
      "Epoch 637/700\n",
      "384/384 [==============================] - 0s 898us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.4062 - val_accuracy: 0.5729\n",
      "Epoch 638/700\n",
      "384/384 [==============================] - 0s 917us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.3689 - val_accuracy: 0.5833\n",
      "Epoch 639/700\n",
      "384/384 [==============================] - 0s 880us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.4442 - val_accuracy: 0.5833\n",
      "Epoch 640/700\n",
      "384/384 [==============================] - 0s 944us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.3709 - val_accuracy: 0.5833\n",
      "Epoch 641/700\n",
      "384/384 [==============================] - 0s 862us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.3640 - val_accuracy: 0.5938\n",
      "Epoch 642/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4506 - val_accuracy: 0.5938\n",
      "Epoch 643/700\n",
      "384/384 [==============================] - 0s 949us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.3905 - val_accuracy: 0.6250\n",
      "Epoch 644/700\n",
      "384/384 [==============================] - 0s 973us/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 1.4264 - val_accuracy: 0.5729\n",
      "Epoch 645/700\n",
      "384/384 [==============================] - 0s 949us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.4027 - val_accuracy: 0.5938\n",
      "Epoch 646/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.4337 - val_accuracy: 0.5833\n",
      "Epoch 647/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.4224 - val_accuracy: 0.6146\n",
      "Epoch 648/700\n",
      "384/384 [==============================] - 0s 976us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.3566 - val_accuracy: 0.5938\n",
      "Epoch 649/700\n",
      "384/384 [==============================] - 0s 963us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.4259 - val_accuracy: 0.6042\n",
      "Epoch 650/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.3876 - val_accuracy: 0.6042\n",
      "Epoch 651/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.4642 - val_accuracy: 0.5938\n",
      "Epoch 652/700\n",
      "384/384 [==============================] - 0s 910us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.4074 - val_accuracy: 0.5729\n",
      "Epoch 653/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.4822 - val_accuracy: 0.5938\n",
      "Epoch 654/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.4372 - val_accuracy: 0.6146\n",
      "Epoch 655/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.4137 - val_accuracy: 0.5833\n",
      "Epoch 656/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.4427 - val_accuracy: 0.6146\n",
      "Epoch 657/700\n",
      "384/384 [==============================] - 0s 960us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.4034 - val_accuracy: 0.5833\n",
      "Epoch 658/700\n",
      "384/384 [==============================] - 0s 969us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.4124 - val_accuracy: 0.5938\n",
      "Epoch 659/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.4667 - val_accuracy: 0.6042\n",
      "Epoch 660/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.4012 - val_accuracy: 0.5833\n",
      "Epoch 661/700\n",
      "384/384 [==============================] - 0s 967us/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 1.3993 - val_accuracy: 0.6042\n",
      "Epoch 662/700\n",
      "384/384 [==============================] - 0s 958us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.4559 - val_accuracy: 0.5625\n",
      "Epoch 663/700\n",
      "384/384 [==============================] - 0s 975us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5126 - val_accuracy: 0.5625\n",
      "Epoch 664/700\n",
      "384/384 [==============================] - 0s 943us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.4154 - val_accuracy: 0.5833\n",
      "Epoch 665/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.5007 - val_accuracy: 0.6146\n",
      "Epoch 666/700\n",
      "384/384 [==============================] - 0s 955us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.4660 - val_accuracy: 0.5833\n",
      "Epoch 667/700\n",
      "384/384 [==============================] - 0s 963us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.4450 - val_accuracy: 0.5938\n",
      "Epoch 668/700\n",
      "384/384 [==============================] - 0s 934us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.5016 - val_accuracy: 0.5833\n",
      "Epoch 669/700\n",
      "384/384 [==============================] - 0s 951us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.4074 - val_accuracy: 0.5938\n",
      "Epoch 670/700\n",
      "384/384 [==============================] - 0s 965us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.4270 - val_accuracy: 0.5938\n",
      "Epoch 671/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.3841 - val_accuracy: 0.6042\n",
      "Epoch 672/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.4571 - val_accuracy: 0.6146\n",
      "Epoch 673/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 0s 935us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.4225 - val_accuracy: 0.5729\n",
      "Epoch 674/700\n",
      "384/384 [==============================] - 0s 893us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.3697 - val_accuracy: 0.5729\n",
      "Epoch 675/700\n",
      "384/384 [==============================] - 0s 898us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.4110 - val_accuracy: 0.5938\n",
      "Epoch 676/700\n",
      "384/384 [==============================] - 0s 882us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.4425 - val_accuracy: 0.6042\n",
      "Epoch 677/700\n",
      "384/384 [==============================] - 0s 864us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.4614 - val_accuracy: 0.5833\n",
      "Epoch 678/700\n",
      "384/384 [==============================] - 0s 856us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.4557 - val_accuracy: 0.5938\n",
      "Epoch 679/700\n",
      "384/384 [==============================] - 0s 843us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.4543 - val_accuracy: 0.5938\n",
      "Epoch 680/700\n",
      "384/384 [==============================] - 0s 828us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.5039 - val_accuracy: 0.5833\n",
      "Epoch 681/700\n",
      "384/384 [==============================] - 0s 878us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.4673 - val_accuracy: 0.5938\n",
      "Epoch 682/700\n",
      "384/384 [==============================] - 0s 844us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.4710 - val_accuracy: 0.6042\n",
      "Epoch 683/700\n",
      "384/384 [==============================] - 0s 881us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.4813 - val_accuracy: 0.5938\n",
      "Epoch 684/700\n",
      "384/384 [==============================] - 0s 854us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.4623 - val_accuracy: 0.6042\n",
      "Epoch 685/700\n",
      "384/384 [==============================] - 0s 856us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.4652 - val_accuracy: 0.5833\n",
      "Epoch 686/700\n",
      "384/384 [==============================] - 0s 870us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.4541 - val_accuracy: 0.6042\n",
      "Epoch 687/700\n",
      "384/384 [==============================] - 0s 875us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.4671 - val_accuracy: 0.6146\n",
      "Epoch 688/700\n",
      "384/384 [==============================] - 0s 861us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.4998 - val_accuracy: 0.6042\n",
      "Epoch 689/700\n",
      "384/384 [==============================] - 0s 854us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.4901 - val_accuracy: 0.5833\n",
      "Epoch 690/700\n",
      "384/384 [==============================] - 0s 885us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.4422 - val_accuracy: 0.5938\n",
      "Epoch 691/700\n",
      "384/384 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.4297 - val_accuracy: 0.6146\n",
      "Epoch 692/700\n",
      "384/384 [==============================] - 0s 888us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.4641 - val_accuracy: 0.6042\n",
      "Epoch 693/700\n",
      "384/384 [==============================] - 0s 886us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.4827 - val_accuracy: 0.5938\n",
      "Epoch 694/700\n",
      "384/384 [==============================] - 0s 889us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.4680 - val_accuracy: 0.6042\n",
      "Epoch 695/700\n",
      "384/384 [==============================] - 0s 939us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4527 - val_accuracy: 0.5729\n",
      "Epoch 696/700\n",
      "384/384 [==============================] - 0s 884us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.5097 - val_accuracy: 0.5833\n",
      "Epoch 697/700\n",
      "384/384 [==============================] - 0s 903us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.4500 - val_accuracy: 0.5938\n",
      "Epoch 698/700\n",
      "384/384 [==============================] - 0s 877us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5054 - val_accuracy: 0.5833\n",
      "Epoch 699/700\n",
      "384/384 [==============================] - 0s 923us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.5143 - val_accuracy: 0.6146\n",
      "Epoch 700/700\n",
      "384/384 [==============================] - 0s 888us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.4911 - val_accuracy: 0.5938\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(X_expanded_scaled_train_cnn, Y_train_cnn, batch_size=32, epochs=700, validation_data=(X_expanded_scaled_test_cnn, Y_test_cnn))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model=SVC(kernel='rbf',C=8).fit(X_scaled_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=svm_model.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=svm_model.score(X_scaled_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7083333333333334"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=4,weights='distance',p=1).fit(X_scaled_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=knn.score(X_scaled_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6354166666666666"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb=GaussianNB().fit(X_scaled_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=gnb.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=gnb.score(X_scaled_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4895833333333333"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracies obtained by all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAVDESS DATASET\n",
      "Logistic Regression : 52.78 %\n",
      "Random Forest       : 61.81 % \n",
      "MLP Classifier      : 68.75 %\n",
      "CNN                 : 70.83 %\n",
      "SVM                 : 70.13 %\n",
      "KNN                 : 61.11 %\n",
      "Naive-Bayes         : 36.45 %\n"
     ]
    }
   ],
   "source": [
    "print('RAVDESS DATASET')\n",
    "print('Logistic Regression : 52.78 %')\n",
    "print('Random Forest       : 61.81 % ')\n",
    "print('MLP Classifier      : 68.75 %')\n",
    "print('CNN                 : 70.83 %')\n",
    "print('SVM                 : 70.13 %')\n",
    "print('KNN                 : 61.11 %')\n",
    "print('Naive-Bayes         : 36.45 %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVVEE DATASET\n",
      "Logistic Regression : 70.83 %\n",
      "Random Forest       : 68.75 % \n",
      "MLP Classifier      : 75.00 %\n",
      "CNN                 : 61.46 %\n",
      "SVM                 : 70.83 %\n",
      "KNN                 : 63.54 %\n",
      "Naive-Bayes         : 48.95 %\n"
     ]
    }
   ],
   "source": [
    "print('SAVVEE DATASET')\n",
    "print('Logistic Regression : 70.83 %')\n",
    "print('Random Forest       : 68.75 % ')\n",
    "print('MLP Classifier      : 75.00 %')\n",
    "print('CNN                 : 61.46 %')\n",
    "print('SVM                 : 70.83 %')\n",
    "print('KNN                 : 63.54 %')\n",
    "print('Naive-Bayes         : 48.95 %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
