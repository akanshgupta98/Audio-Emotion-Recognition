{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir=r\"/home/akansh/Downloads/AudioData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a07.wav', 'su11.wav', 'h04.wav', 'd15.wav', 'f15.wav', 'sa15.wav', 'n25.wav', 'n07.wav', 'h07.wav', 'n22.wav', 'f05.wav', 'a15.wav', 'd08.wav', 'f03.wav', 'd14.wav', 'h11.wav', 'n21.wav', 'a12.wav', 'sa05.wav', 'sa04.wav', 'sa13.wav', 'f08.wav', 'n13.wav', 'n02.wav', 'n03.wav', 'sa08.wav', 'su07.wav', 'f10.wav', 'n08.wav', 'su13.wav', 'a04.wav', 'su01.wav', 'd05.wav', 'h14.wav', 'su06.wav', 'n20.wav', 'h13.wav', 'f11.wav', 'h05.wav', 'n06.wav', 'su03.wav', 'f13.wav', 'f09.wav', 'n10.wav', 'n09.wav', 'f01.wav', 'su02.wav', 'n27.wav', 'a10.wav', 'sa14.wav', 'h15.wav', 'd03.wav', 'n11.wav', 'sa11.wav', 'h01.wav', 'a11.wav', 'su04.wav', 'h02.wav', 'n12.wav', 'n29.wav', 'f02.wav', 'd10.wav', 'n05.wav', 'd12.wav', 'a09.wav', 'd02.wav', 'sa02.wav', 'n28.wav', 'su14.wav', 'su10.wav', 'a08.wav', 'n14.wav', 'sa01.wav', 'd11.wav', 'n15.wav', 'f12.wav', 'su05.wav', 'n16.wav', 'd09.wav', 'su15.wav', 'h08.wav', 'n30.wav', 'f06.wav', 'd07.wav', 'n26.wav', 'h03.wav', 'h10.wav', 'n18.wav', 'n01.wav', 'sa12.wav', 'f04.wav', 'n23.wav', 'n19.wav', 'd04.wav', 'n04.wav', 'a14.wav', 'sa03.wav', 'n24.wav', 'a06.wav', 'a13.wav', 'a01.wav', 'sa10.wav', 'h09.wav', 'd13.wav', 'f14.wav', 'sa06.wav', 'a03.wav', 'sa07.wav', 'a05.wav', 'h06.wav', 'd06.wav', 'f07.wav', 'a02.wav', 'sa09.wav', 'su12.wav', 'd01.wav', 'n17.wav', 'su09.wav', 'su08.wav', 'h12.wav']\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(root_dir):\n",
    "    actor_name=os.path.join(root_dir,file)\n",
    "    print(os.listdir(actor_name))\n",
    "    break;\n",
    "print(len(my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_file=open('saavvee.csv','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion='nuetral neutral happy sad angry fearful disgust surprised'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "for file in os.listdir(root_dir):\n",
    "    actor_name=os.path.join(root_dir,file)\n",
    "    my=os.listdir(actor_name)\n",
    "    for file_name in my:\n",
    "        if(file_name[0:2]=='sa'):\n",
    "            labels.append(4)\n",
    "        elif(file_name[0:2]=='su'):\n",
    "            labels.append(8)\n",
    "        elif(file_name[0]=='a'):\n",
    "            labels.append(5)\n",
    "        elif(file_name[0]=='d'):\n",
    "            labels.append(7)\n",
    "        elif(file_name[0]=='f'):\n",
    "            labels.append(6)\n",
    "        elif(file_name[0]=='h'):\n",
    "            labels.append(3)\n",
    "        elif(file_name[0]=='n'):\n",
    "            labels.append(1)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in zip(labels,range(0,480)):\n",
    "    if(x=='a'):\n",
    "        labels[y]=5\n",
    "    elif(x=='d'):\n",
    "        labels[y]=7\n",
    "    elif(x=='f'):\n",
    "        labels[y]=6\n",
    "    elif(x=='d'):\n",
    "        labels[y]=7\n",
    "    elif(x=='h'):\n",
    "        labels[y]=7\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "header='name label emotion chroma_stft_mean rmse_mean spec_cent_mean spec_bw_mean rolloff_mean zcr_mean'\n",
    "for i in range(1, 41):\n",
    "    header += f' mfcc{i}'\n",
    "for i in range(1, 41):\n",
    "    header += f' chroma{i}'\n",
    "header = header.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name',\n",
       " 'label',\n",
       " 'emotion',\n",
       " 'chroma_stft_mean',\n",
       " 'rmse_mean',\n",
       " 'spec_cent_mean',\n",
       " 'spec_bw_mean',\n",
       " 'rolloff_mean',\n",
       " 'zcr_mean',\n",
       " 'mfcc1',\n",
       " 'mfcc2',\n",
       " 'mfcc3',\n",
       " 'mfcc4',\n",
       " 'mfcc5',\n",
       " 'mfcc6',\n",
       " 'mfcc7',\n",
       " 'mfcc8',\n",
       " 'mfcc9',\n",
       " 'mfcc10',\n",
       " 'mfcc11',\n",
       " 'mfcc12',\n",
       " 'mfcc13',\n",
       " 'mfcc14',\n",
       " 'mfcc15',\n",
       " 'mfcc16',\n",
       " 'mfcc17',\n",
       " 'mfcc18',\n",
       " 'mfcc19',\n",
       " 'mfcc20',\n",
       " 'mfcc21',\n",
       " 'mfcc22',\n",
       " 'mfcc23',\n",
       " 'mfcc24',\n",
       " 'mfcc25',\n",
       " 'mfcc26',\n",
       " 'mfcc27',\n",
       " 'mfcc28',\n",
       " 'mfcc29',\n",
       " 'mfcc30',\n",
       " 'mfcc31',\n",
       " 'mfcc32',\n",
       " 'mfcc33',\n",
       " 'mfcc34',\n",
       " 'mfcc35',\n",
       " 'mfcc36',\n",
       " 'mfcc37',\n",
       " 'mfcc38',\n",
       " 'mfcc39',\n",
       " 'mfcc40',\n",
       " 'chroma1',\n",
       " 'chroma2',\n",
       " 'chroma3',\n",
       " 'chroma4',\n",
       " 'chroma5',\n",
       " 'chroma6',\n",
       " 'chroma7',\n",
       " 'chroma8',\n",
       " 'chroma9',\n",
       " 'chroma10',\n",
       " 'chroma11',\n",
       " 'chroma12',\n",
       " 'chroma13',\n",
       " 'chroma14',\n",
       " 'chroma15',\n",
       " 'chroma16',\n",
       " 'chroma17',\n",
       " 'chroma18',\n",
       " 'chroma19',\n",
       " 'chroma20',\n",
       " 'chroma21',\n",
       " 'chroma22',\n",
       " 'chroma23',\n",
       " 'chroma24',\n",
       " 'chroma25',\n",
       " 'chroma26',\n",
       " 'chroma27',\n",
       " 'chroma28',\n",
       " 'chroma29',\n",
       " 'chroma30',\n",
       " 'chroma31',\n",
       " 'chroma32',\n",
       " 'chroma33',\n",
       " 'chroma34',\n",
       " 'chroma35',\n",
       " 'chroma36',\n",
       " 'chroma37',\n",
       " 'chroma38',\n",
       " 'chroma39',\n",
       " 'chroma40']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import librosa\n",
    "import csv\n",
    "import librosa\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_mean=[]\n",
    "with emotion_file:\n",
    "    writer=csv.writer(emotion_file)\n",
    "    writer.writerow(header)\n",
    "    for actor_dir in os.listdir(root_dir):\n",
    "        actor_name=os.path.join(root_dir,actor_dir)\n",
    "        my=os.listdir(actor_name) \n",
    "        for i in range(len(my)): \n",
    "            songname = os.path.join(actor_name,my[i])\n",
    "            y, sr = librosa.load(songname)\n",
    "            sr=np.array(sr)\n",
    "            chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr,n_chroma=40)\n",
    "            chroma_stft_mean=np.mean(chroma_stft)\n",
    "            rmse = librosa.feature.rms(y=y)\n",
    "            rmse_mean=np.mean(rmse)\n",
    "            spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "            spec_cent_mean=np.mean(spec_cent)\n",
    "            spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "            spec_bw_mean=np.mean(spec_bw)\n",
    "            rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "            rolloff_mean=np.mean(rolloff)\n",
    "            zcr = librosa.feature.zero_crossing_rate(y)\n",
    "            zcr_mean=np.mean(zcr)\n",
    "            final_list=[my[i],labels[i],emotion[int(labels[i])-1],chroma_stft_mean,rmse_mean,spec_cent_mean,spec_bw_mean,rolloff_mean,zcr_mean]\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr,n_mfcc=40)\n",
    "            mfcc_mean=[]\n",
    "            for e in mfcc[0:40]:\n",
    "                final_list.append(np.mean(e))\n",
    "            for f in chroma_stft[0:40]:\n",
    "                final_list.append(np.mean(f))\n",
    "            #writer.writerow(my[0:3])\n",
    "            \n",
    "            writer.writerow(final_list)\n",
    "            #writer.writerow(my[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 3]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "8\n",
      "3\n",
      "7\n",
      "6\n",
      "4\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,8):\n",
    "    print(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry\n",
      "surprised\n",
      "happy\n",
      "disgust\n",
      "fearful\n",
      "sad\n",
      "nuetral\n",
      "nuetral\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,8):\n",
    "    print(emotion[labels[i]-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('saavvee.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma31</th>\n",
       "      <th>chroma32</th>\n",
       "      <th>chroma33</th>\n",
       "      <th>chroma34</th>\n",
       "      <th>chroma35</th>\n",
       "      <th>chroma36</th>\n",
       "      <th>chroma37</th>\n",
       "      <th>chroma38</th>\n",
       "      <th>chroma39</th>\n",
       "      <th>chroma40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a07.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.453620</td>\n",
       "      <td>0.188765</td>\n",
       "      <td>708.461942</td>\n",
       "      <td>1075.186781</td>\n",
       "      <td>1242.243063</td>\n",
       "      <td>0.023012</td>\n",
       "      <td>-311.66483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493046</td>\n",
       "      <td>0.469258</td>\n",
       "      <td>0.463017</td>\n",
       "      <td>0.463213</td>\n",
       "      <td>0.488015</td>\n",
       "      <td>0.462780</td>\n",
       "      <td>0.426917</td>\n",
       "      <td>0.405259</td>\n",
       "      <td>0.402458</td>\n",
       "      <td>0.387063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>su11.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.529019</td>\n",
       "      <td>0.115584</td>\n",
       "      <td>786.819046</td>\n",
       "      <td>1154.246808</td>\n",
       "      <td>1362.531991</td>\n",
       "      <td>0.020697</td>\n",
       "      <td>-367.18490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564666</td>\n",
       "      <td>0.557354</td>\n",
       "      <td>0.562710</td>\n",
       "      <td>0.570263</td>\n",
       "      <td>0.566272</td>\n",
       "      <td>0.550136</td>\n",
       "      <td>0.538275</td>\n",
       "      <td>0.520465</td>\n",
       "      <td>0.501501</td>\n",
       "      <td>0.483808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>h04.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.382981</td>\n",
       "      <td>0.170454</td>\n",
       "      <td>824.990781</td>\n",
       "      <td>1115.254560</td>\n",
       "      <td>1483.176270</td>\n",
       "      <td>0.029987</td>\n",
       "      <td>-283.54694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.391823</td>\n",
       "      <td>0.395524</td>\n",
       "      <td>0.416979</td>\n",
       "      <td>0.429550</td>\n",
       "      <td>0.438576</td>\n",
       "      <td>0.428286</td>\n",
       "      <td>0.416861</td>\n",
       "      <td>0.427764</td>\n",
       "      <td>0.458571</td>\n",
       "      <td>0.464348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>d15.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.331768</td>\n",
       "      <td>0.094535</td>\n",
       "      <td>736.095487</td>\n",
       "      <td>1008.300308</td>\n",
       "      <td>1344.876414</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>-356.75275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269815</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>0.253670</td>\n",
       "      <td>0.264804</td>\n",
       "      <td>0.278391</td>\n",
       "      <td>0.287833</td>\n",
       "      <td>0.293499</td>\n",
       "      <td>0.300780</td>\n",
       "      <td>0.305024</td>\n",
       "      <td>0.302512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>f15.wav</td>\n",
       "      <td>6</td>\n",
       "      <td>fearful</td>\n",
       "      <td>0.345309</td>\n",
       "      <td>0.176559</td>\n",
       "      <td>812.241450</td>\n",
       "      <td>1083.898577</td>\n",
       "      <td>1528.372440</td>\n",
       "      <td>0.023224</td>\n",
       "      <td>-305.33292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450625</td>\n",
       "      <td>0.419348</td>\n",
       "      <td>0.393573</td>\n",
       "      <td>0.369591</td>\n",
       "      <td>0.334339</td>\n",
       "      <td>0.303741</td>\n",
       "      <td>0.273194</td>\n",
       "      <td>0.251841</td>\n",
       "      <td>0.238980</td>\n",
       "      <td>0.235346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  label    emotion  chroma_stft_mean  rmse_mean  spec_cent_mean  \\\n",
       "0   a07.wav      5      angry          0.453620   0.188765      708.461942   \n",
       "1  su11.wav      8  surprised          0.529019   0.115584      786.819046   \n",
       "2   h04.wav      3      happy          0.382981   0.170454      824.990781   \n",
       "3   d15.wav      7    disgust          0.331768   0.094535      736.095487   \n",
       "4   f15.wav      6    fearful          0.345309   0.176559      812.241450   \n",
       "\n",
       "   spec_bw_mean  rolloff_mean  zcr_mean      mfcc1  ...  chroma31  chroma32  \\\n",
       "0   1075.186781   1242.243063  0.023012 -311.66483  ...  0.493046  0.469258   \n",
       "1   1154.246808   1362.531991  0.020697 -367.18490  ...  0.564666  0.557354   \n",
       "2   1115.254560   1483.176270  0.029987 -283.54694  ...  0.391823  0.395524   \n",
       "3   1008.300308   1344.876414  0.020126 -356.75275  ...  0.269815  0.257576   \n",
       "4   1083.898577   1528.372440  0.023224 -305.33292  ...  0.450625  0.419348   \n",
       "\n",
       "   chroma33  chroma34  chroma35  chroma36  chroma37  chroma38  chroma39  \\\n",
       "0  0.463017  0.463213  0.488015  0.462780  0.426917  0.405259  0.402458   \n",
       "1  0.562710  0.570263  0.566272  0.550136  0.538275  0.520465  0.501501   \n",
       "2  0.416979  0.429550  0.438576  0.428286  0.416861  0.427764  0.458571   \n",
       "3  0.253670  0.264804  0.278391  0.287833  0.293499  0.300780  0.305024   \n",
       "4  0.393573  0.369591  0.334339  0.303741  0.273194  0.251841  0.238980   \n",
       "\n",
       "   chroma40  \n",
       "0  0.387063  \n",
       "1  0.483808  \n",
       "2  0.464348  \n",
       "3  0.302512  \n",
       "4  0.235346  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 61)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 4, saw 61\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-edb6677db8d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 4, saw 61\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('my.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_csv('audio.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=pd.read_csv('save.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma3</th>\n",
       "      <th>chroma4</th>\n",
       "      <th>chroma5</th>\n",
       "      <th>chroma6</th>\n",
       "      <th>chroma7</th>\n",
       "      <th>chroma8</th>\n",
       "      <th>chroma9</th>\n",
       "      <th>chroma10</th>\n",
       "      <th>chroma11</th>\n",
       "      <th>chroma12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a07.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.502734</td>\n",
       "      <td>0.188765</td>\n",
       "      <td>708.461942</td>\n",
       "      <td>1075.186781</td>\n",
       "      <td>1242.243063</td>\n",
       "      <td>0.023012</td>\n",
       "      <td>-311.66483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441126</td>\n",
       "      <td>0.530508</td>\n",
       "      <td>0.586412</td>\n",
       "      <td>0.649876</td>\n",
       "      <td>0.589163</td>\n",
       "      <td>0.546012</td>\n",
       "      <td>0.527696</td>\n",
       "      <td>0.485116</td>\n",
       "      <td>0.411493</td>\n",
       "      <td>0.385100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>su11.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.566749</td>\n",
       "      <td>0.115584</td>\n",
       "      <td>786.819046</td>\n",
       "      <td>1154.246808</td>\n",
       "      <td>1362.531991</td>\n",
       "      <td>0.020697</td>\n",
       "      <td>-367.18490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566975</td>\n",
       "      <td>0.636410</td>\n",
       "      <td>0.591235</td>\n",
       "      <td>0.578802</td>\n",
       "      <td>0.589855</td>\n",
       "      <td>0.591339</td>\n",
       "      <td>0.599358</td>\n",
       "      <td>0.576127</td>\n",
       "      <td>0.513877</td>\n",
       "      <td>0.479570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>h04.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.433026</td>\n",
       "      <td>0.170454</td>\n",
       "      <td>824.990781</td>\n",
       "      <td>1115.254560</td>\n",
       "      <td>1483.176270</td>\n",
       "      <td>0.029987</td>\n",
       "      <td>-283.54694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327907</td>\n",
       "      <td>0.371451</td>\n",
       "      <td>0.421986</td>\n",
       "      <td>0.460247</td>\n",
       "      <td>0.491815</td>\n",
       "      <td>0.455797</td>\n",
       "      <td>0.452028</td>\n",
       "      <td>0.477943</td>\n",
       "      <td>0.514452</td>\n",
       "      <td>0.480846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>d15.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.378664</td>\n",
       "      <td>0.094535</td>\n",
       "      <td>736.095487</td>\n",
       "      <td>1008.300308</td>\n",
       "      <td>1344.876414</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>-356.75275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443246</td>\n",
       "      <td>0.477263</td>\n",
       "      <td>0.400068</td>\n",
       "      <td>0.370872</td>\n",
       "      <td>0.342654</td>\n",
       "      <td>0.301004</td>\n",
       "      <td>0.308168</td>\n",
       "      <td>0.344775</td>\n",
       "      <td>0.343149</td>\n",
       "      <td>0.341142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>f15.wav</td>\n",
       "      <td>6</td>\n",
       "      <td>fearful</td>\n",
       "      <td>0.393653</td>\n",
       "      <td>0.176559</td>\n",
       "      <td>812.241450</td>\n",
       "      <td>1083.898577</td>\n",
       "      <td>1528.372440</td>\n",
       "      <td>0.023224</td>\n",
       "      <td>-305.33292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314041</td>\n",
       "      <td>0.330823</td>\n",
       "      <td>0.405824</td>\n",
       "      <td>0.599642</td>\n",
       "      <td>0.657282</td>\n",
       "      <td>0.542771</td>\n",
       "      <td>0.421477</td>\n",
       "      <td>0.300966</td>\n",
       "      <td>0.247257</td>\n",
       "      <td>0.250691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  label    emotion  chroma_stft_mean  rmse_mean  spec_cent_mean  \\\n",
       "0   a07.wav      5      angry          0.502734   0.188765      708.461942   \n",
       "1  su11.wav      8  surprised          0.566749   0.115584      786.819046   \n",
       "2   h04.wav      3      happy          0.433026   0.170454      824.990781   \n",
       "3   d15.wav      7    disgust          0.378664   0.094535      736.095487   \n",
       "4   f15.wav      6    fearful          0.393653   0.176559      812.241450   \n",
       "\n",
       "   spec_bw_mean  rolloff_mean  zcr_mean      mfcc1  ...   chroma3   chroma4  \\\n",
       "0   1075.186781   1242.243063  0.023012 -311.66483  ...  0.441126  0.530508   \n",
       "1   1154.246808   1362.531991  0.020697 -367.18490  ...  0.566975  0.636410   \n",
       "2   1115.254560   1483.176270  0.029987 -283.54694  ...  0.327907  0.371451   \n",
       "3   1008.300308   1344.876414  0.020126 -356.75275  ...  0.443246  0.477263   \n",
       "4   1083.898577   1528.372440  0.023224 -305.33292  ...  0.314041  0.330823   \n",
       "\n",
       "    chroma5   chroma6   chroma7   chroma8   chroma9  chroma10  chroma11  \\\n",
       "0  0.586412  0.649876  0.589163  0.546012  0.527696  0.485116  0.411493   \n",
       "1  0.591235  0.578802  0.589855  0.591339  0.599358  0.576127  0.513877   \n",
       "2  0.421986  0.460247  0.491815  0.455797  0.452028  0.477943  0.514452   \n",
       "3  0.400068  0.370872  0.342654  0.301004  0.308168  0.344775  0.343149   \n",
       "4  0.405824  0.599642  0.657282  0.542771  0.421477  0.300966  0.247257   \n",
       "\n",
       "   chroma12  \n",
       "0  0.385100  \n",
       "1  0.479570  \n",
       "2  0.480846  \n",
       "3  0.341142  \n",
       "4  0.250691  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma3</th>\n",
       "      <th>chroma4</th>\n",
       "      <th>chroma5</th>\n",
       "      <th>chroma6</th>\n",
       "      <th>chroma7</th>\n",
       "      <th>chroma8</th>\n",
       "      <th>chroma9</th>\n",
       "      <th>chroma10</th>\n",
       "      <th>chroma11</th>\n",
       "      <th>chroma12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>03-01-01-01-01-01-01.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.598800</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>3435.943088</td>\n",
       "      <td>2600.929791</td>\n",
       "      <td>6264.656291</td>\n",
       "      <td>0.326237</td>\n",
       "      <td>-697.984245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570387</td>\n",
       "      <td>0.562410</td>\n",
       "      <td>0.551299</td>\n",
       "      <td>0.531241</td>\n",
       "      <td>0.589565</td>\n",
       "      <td>0.640624</td>\n",
       "      <td>0.644353</td>\n",
       "      <td>0.608717</td>\n",
       "      <td>0.611980</td>\n",
       "      <td>0.606167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>03-01-01-01-01-02-01.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.578452</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>3231.037280</td>\n",
       "      <td>2646.981271</td>\n",
       "      <td>6162.832642</td>\n",
       "      <td>0.340786</td>\n",
       "      <td>-693.069755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586752</td>\n",
       "      <td>0.530952</td>\n",
       "      <td>0.529118</td>\n",
       "      <td>0.552281</td>\n",
       "      <td>0.497320</td>\n",
       "      <td>0.549519</td>\n",
       "      <td>0.584854</td>\n",
       "      <td>0.633122</td>\n",
       "      <td>0.632074</td>\n",
       "      <td>0.617527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>03-01-01-01-02-01-01.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.587585</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>3203.154528</td>\n",
       "      <td>2605.181241</td>\n",
       "      <td>6117.338659</td>\n",
       "      <td>0.356861</td>\n",
       "      <td>-691.770194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579290</td>\n",
       "      <td>0.590824</td>\n",
       "      <td>0.573292</td>\n",
       "      <td>0.528130</td>\n",
       "      <td>0.516716</td>\n",
       "      <td>0.578961</td>\n",
       "      <td>0.639646</td>\n",
       "      <td>0.640274</td>\n",
       "      <td>0.563098</td>\n",
       "      <td>0.562465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>03-01-01-01-02-02-01.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.573247</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>3080.483081</td>\n",
       "      <td>2644.191743</td>\n",
       "      <td>6094.210838</td>\n",
       "      <td>0.366200</td>\n",
       "      <td>-685.237871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518804</td>\n",
       "      <td>0.521994</td>\n",
       "      <td>0.584694</td>\n",
       "      <td>0.590593</td>\n",
       "      <td>0.537656</td>\n",
       "      <td>0.589734</td>\n",
       "      <td>0.611182</td>\n",
       "      <td>0.560056</td>\n",
       "      <td>0.568192</td>\n",
       "      <td>0.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>03-01-02-01-01-01-01.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.561084</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>3192.620354</td>\n",
       "      <td>2601.322629</td>\n",
       "      <td>6003.471105</td>\n",
       "      <td>0.313122</td>\n",
       "      <td>-727.317945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.586327</td>\n",
       "      <td>0.547133</td>\n",
       "      <td>0.522434</td>\n",
       "      <td>0.539025</td>\n",
       "      <td>0.501785</td>\n",
       "      <td>0.554183</td>\n",
       "      <td>0.575118</td>\n",
       "      <td>0.618561</td>\n",
       "      <td>0.654716</td>\n",
       "      <td>0.552219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  label  emotion  chroma_stft_mean  rmse_mean  \\\n",
       "0  03-01-01-01-01-01-01.wav      1  neutral          0.598800   0.002257   \n",
       "1  03-01-01-01-01-02-01.wav      1  neutral          0.578452   0.002420   \n",
       "2  03-01-01-01-02-01-01.wav      1  neutral          0.587585   0.002810   \n",
       "3  03-01-01-01-02-02-01.wav      1  neutral          0.573247   0.002618   \n",
       "4  03-01-02-01-01-01-01.wav      2     calm          0.561084   0.001654   \n",
       "\n",
       "   spec_cent_mean  spec_bw_mean  rolloff_mean  zcr_mean       mfcc1  ...  \\\n",
       "0     3435.943088   2600.929791   6264.656291  0.326237 -697.984245  ...   \n",
       "1     3231.037280   2646.981271   6162.832642  0.340786 -693.069755  ...   \n",
       "2     3203.154528   2605.181241   6117.338659  0.356861 -691.770194  ...   \n",
       "3     3080.483081   2644.191743   6094.210838  0.366200 -685.237871  ...   \n",
       "4     3192.620354   2601.322629   6003.471105  0.313122 -727.317945  ...   \n",
       "\n",
       "    chroma3   chroma4   chroma5   chroma6   chroma7   chroma8   chroma9  \\\n",
       "0  0.570387  0.562410  0.551299  0.531241  0.589565  0.640624  0.644353   \n",
       "1  0.586752  0.530952  0.529118  0.552281  0.497320  0.549519  0.584854   \n",
       "2  0.579290  0.590824  0.573292  0.528130  0.516716  0.578961  0.639646   \n",
       "3  0.518804  0.521994  0.584694  0.590593  0.537656  0.589734  0.611182   \n",
       "4  0.586327  0.547133  0.522434  0.539025  0.501785  0.554183  0.575118   \n",
       "\n",
       "   chroma10  chroma11  chroma12  \n",
       "0  0.608717  0.611980  0.606167  \n",
       "1  0.633122  0.632074  0.617527  \n",
       "2  0.640274  0.563098  0.562465  \n",
       "3  0.560056  0.568192  0.592452  \n",
       "4  0.618561  0.654716  0.552219  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-3818101820db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   7332\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7333\u001b[0m             \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7334\u001b[0;31m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7335\u001b[0m         )\n\u001b[1;32m   7336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     )\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1772\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1773\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1774\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "merged = a.merge(b, on='title')\n",
    "merged.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.reader(open(\"audio.csv\"))\n",
    "reader1 = csv.reader(open(\"save.csv\"))\n",
    "f = open(\"combined.csv\", \"w\")\n",
    "writer = csv.writer(f)\n",
    "\n",
    "for row in reader:\n",
    "    writer.writerow(row)\n",
    "for row in reader1:\n",
    "    writer.writerow(row)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-55fbddeaafb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('myexpfinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma31</th>\n",
       "      <th>chroma32</th>\n",
       "      <th>chroma33</th>\n",
       "      <th>chroma34</th>\n",
       "      <th>chroma35</th>\n",
       "      <th>chroma36</th>\n",
       "      <th>chroma37</th>\n",
       "      <th>chroma38</th>\n",
       "      <th>chroma39</th>\n",
       "      <th>chroma40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1915</td>\n",
       "      <td>d01.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.393920</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>813.782244</td>\n",
       "      <td>1196.672323</td>\n",
       "      <td>1306.106940</td>\n",
       "      <td>0.014997</td>\n",
       "      <td>-608.06670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364996</td>\n",
       "      <td>0.379896</td>\n",
       "      <td>0.415330</td>\n",
       "      <td>0.416510</td>\n",
       "      <td>0.380505</td>\n",
       "      <td>0.372216</td>\n",
       "      <td>0.363030</td>\n",
       "      <td>0.354653</td>\n",
       "      <td>0.358105</td>\n",
       "      <td>0.340235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1916</td>\n",
       "      <td>n17.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>nuetral</td>\n",
       "      <td>0.354278</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>830.164313</td>\n",
       "      <td>1296.456247</td>\n",
       "      <td>1384.222898</td>\n",
       "      <td>0.023844</td>\n",
       "      <td>-604.96920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337089</td>\n",
       "      <td>0.324475</td>\n",
       "      <td>0.316751</td>\n",
       "      <td>0.331846</td>\n",
       "      <td>0.352019</td>\n",
       "      <td>0.397303</td>\n",
       "      <td>0.458941</td>\n",
       "      <td>0.467767</td>\n",
       "      <td>0.474734</td>\n",
       "      <td>0.461751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1917</td>\n",
       "      <td>su09.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.406514</td>\n",
       "      <td>0.009833</td>\n",
       "      <td>1026.556384</td>\n",
       "      <td>1473.063327</td>\n",
       "      <td>1875.413161</td>\n",
       "      <td>0.022524</td>\n",
       "      <td>-573.56490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417060</td>\n",
       "      <td>0.403727</td>\n",
       "      <td>0.394791</td>\n",
       "      <td>0.401452</td>\n",
       "      <td>0.390464</td>\n",
       "      <td>0.391067</td>\n",
       "      <td>0.406367</td>\n",
       "      <td>0.415129</td>\n",
       "      <td>0.426788</td>\n",
       "      <td>0.430615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1918</td>\n",
       "      <td>su08.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.394880</td>\n",
       "      <td>0.007730</td>\n",
       "      <td>1157.352920</td>\n",
       "      <td>1486.602507</td>\n",
       "      <td>1941.054267</td>\n",
       "      <td>0.039211</td>\n",
       "      <td>-576.51794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412002</td>\n",
       "      <td>0.422335</td>\n",
       "      <td>0.436887</td>\n",
       "      <td>0.444563</td>\n",
       "      <td>0.451129</td>\n",
       "      <td>0.434277</td>\n",
       "      <td>0.423281</td>\n",
       "      <td>0.431441</td>\n",
       "      <td>0.443131</td>\n",
       "      <td>0.435172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1919</td>\n",
       "      <td>h12.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.336927</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>1058.038644</td>\n",
       "      <td>1403.211297</td>\n",
       "      <td>1984.094063</td>\n",
       "      <td>0.035824</td>\n",
       "      <td>-571.95404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348946</td>\n",
       "      <td>0.337333</td>\n",
       "      <td>0.337022</td>\n",
       "      <td>0.350069</td>\n",
       "      <td>0.348373</td>\n",
       "      <td>0.355150</td>\n",
       "      <td>0.366430</td>\n",
       "      <td>0.377430</td>\n",
       "      <td>0.391307</td>\n",
       "      <td>0.388412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  label    emotion  chroma_stft_mean  rmse_mean  spec_cent_mean  \\\n",
       "1915   d01.wav      7    disgust          0.393920   0.008647      813.782244   \n",
       "1916   n17.wav      1    nuetral          0.354278   0.005757      830.164313   \n",
       "1917  su09.wav      8  surprised          0.406514   0.009833     1026.556384   \n",
       "1918  su08.wav      8  surprised          0.394880   0.007730     1157.352920   \n",
       "1919   h12.wav      3      happy          0.336927   0.008214     1058.038644   \n",
       "\n",
       "      spec_bw_mean  rolloff_mean  zcr_mean      mfcc1  ...  chroma31  \\\n",
       "1915   1196.672323   1306.106940  0.014997 -608.06670  ...  0.364996   \n",
       "1916   1296.456247   1384.222898  0.023844 -604.96920  ...  0.337089   \n",
       "1917   1473.063327   1875.413161  0.022524 -573.56490  ...  0.417060   \n",
       "1918   1486.602507   1941.054267  0.039211 -576.51794  ...  0.412002   \n",
       "1919   1403.211297   1984.094063  0.035824 -571.95404  ...  0.348946   \n",
       "\n",
       "      chroma32  chroma33  chroma34  chroma35  chroma36  chroma37  chroma38  \\\n",
       "1915  0.379896  0.415330  0.416510  0.380505  0.372216  0.363030  0.354653   \n",
       "1916  0.324475  0.316751  0.331846  0.352019  0.397303  0.458941  0.467767   \n",
       "1917  0.403727  0.394791  0.401452  0.390464  0.391067  0.406367  0.415129   \n",
       "1918  0.422335  0.436887  0.444563  0.451129  0.434277  0.423281  0.431441   \n",
       "1919  0.337333  0.337022  0.350069  0.348373  0.355150  0.366430  0.377430   \n",
       "\n",
       "      chroma39  chroma40  \n",
       "1915  0.358105  0.340235  \n",
       "1916  0.474734  0.461751  \n",
       "1917  0.426788  0.430615  \n",
       "1918  0.443131  0.435172  \n",
       "1919  0.391307  0.388412  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 89)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma31</th>\n",
       "      <th>chroma32</th>\n",
       "      <th>chroma33</th>\n",
       "      <th>chroma34</th>\n",
       "      <th>chroma35</th>\n",
       "      <th>chroma36</th>\n",
       "      <th>chroma37</th>\n",
       "      <th>chroma38</th>\n",
       "      <th>chroma39</th>\n",
       "      <th>chroma40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>03-01-03-02-01-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.385386</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>2592.308325</td>\n",
       "      <td>2360.097245</td>\n",
       "      <td>4995.771702</td>\n",
       "      <td>0.246548</td>\n",
       "      <td>-560.09265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464910</td>\n",
       "      <td>0.475772</td>\n",
       "      <td>0.437146</td>\n",
       "      <td>0.477294</td>\n",
       "      <td>0.468137</td>\n",
       "      <td>0.397129</td>\n",
       "      <td>0.374605</td>\n",
       "      <td>0.363818</td>\n",
       "      <td>0.353714</td>\n",
       "      <td>0.350808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>03-01-03-02-02-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.399802</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>3158.102896</td>\n",
       "      <td>2509.477352</td>\n",
       "      <td>5908.204274</td>\n",
       "      <td>0.304351</td>\n",
       "      <td>-539.44464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>0.443214</td>\n",
       "      <td>0.441170</td>\n",
       "      <td>0.453948</td>\n",
       "      <td>0.446627</td>\n",
       "      <td>0.423123</td>\n",
       "      <td>0.409154</td>\n",
       "      <td>0.380438</td>\n",
       "      <td>0.364385</td>\n",
       "      <td>0.329913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>03-01-03-01-02-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.432610</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>3155.010040</td>\n",
       "      <td>2500.076212</td>\n",
       "      <td>5856.358337</td>\n",
       "      <td>0.369135</td>\n",
       "      <td>-652.92870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398528</td>\n",
       "      <td>0.452733</td>\n",
       "      <td>0.453803</td>\n",
       "      <td>0.451015</td>\n",
       "      <td>0.450011</td>\n",
       "      <td>0.447997</td>\n",
       "      <td>0.456473</td>\n",
       "      <td>0.446582</td>\n",
       "      <td>0.428503</td>\n",
       "      <td>0.459803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>03-01-05-01-01-02-01.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.389468</td>\n",
       "      <td>0.009704</td>\n",
       "      <td>3435.518747</td>\n",
       "      <td>2619.287507</td>\n",
       "      <td>6348.558278</td>\n",
       "      <td>0.303829</td>\n",
       "      <td>-526.54034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422416</td>\n",
       "      <td>0.412361</td>\n",
       "      <td>0.386799</td>\n",
       "      <td>0.383563</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>0.372256</td>\n",
       "      <td>0.367946</td>\n",
       "      <td>0.360153</td>\n",
       "      <td>0.373736</td>\n",
       "      <td>0.369871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>03-01-08-01-02-02-01.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.491953</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>3524.545799</td>\n",
       "      <td>2647.952102</td>\n",
       "      <td>6432.624460</td>\n",
       "      <td>0.284329</td>\n",
       "      <td>-666.63245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530399</td>\n",
       "      <td>0.520594</td>\n",
       "      <td>0.468319</td>\n",
       "      <td>0.440439</td>\n",
       "      <td>0.431363</td>\n",
       "      <td>0.439305</td>\n",
       "      <td>0.463814</td>\n",
       "      <td>0.481968</td>\n",
       "      <td>0.456423</td>\n",
       "      <td>0.451458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  label    emotion  chroma_stft_mean  rmse_mean  \\\n",
       "0  03-01-03-02-01-02-01.wav      3      happy          0.385386   0.008209   \n",
       "1  03-01-03-02-02-02-01.wav      3      happy          0.399802   0.010222   \n",
       "2  03-01-03-01-02-02-01.wav      3      happy          0.432610   0.003754   \n",
       "3  03-01-05-01-01-02-01.wav      5      angry          0.389468   0.009704   \n",
       "4  03-01-08-01-02-02-01.wav      8  surprised          0.491953   0.003929   \n",
       "\n",
       "   spec_cent_mean  spec_bw_mean  rolloff_mean  zcr_mean      mfcc1  ...  \\\n",
       "0     2592.308325   2360.097245   4995.771702  0.246548 -560.09265  ...   \n",
       "1     3158.102896   2509.477352   5908.204274  0.304351 -539.44464  ...   \n",
       "2     3155.010040   2500.076212   5856.358337  0.369135 -652.92870  ...   \n",
       "3     3435.518747   2619.287507   6348.558278  0.303829 -526.54034  ...   \n",
       "4     3524.545799   2647.952102   6432.624460  0.284329 -666.63245  ...   \n",
       "\n",
       "   chroma31  chroma32  chroma33  chroma34  chroma35  chroma36  chroma37  \\\n",
       "0  0.464910  0.475772  0.437146  0.477294  0.468137  0.397129  0.374605   \n",
       "1  0.421389  0.443214  0.441170  0.453948  0.446627  0.423123  0.409154   \n",
       "2  0.398528  0.452733  0.453803  0.451015  0.450011  0.447997  0.456473   \n",
       "3  0.422416  0.412361  0.386799  0.383563  0.390801  0.372256  0.367946   \n",
       "4  0.530399  0.520594  0.468319  0.440439  0.431363  0.439305  0.463814   \n",
       "\n",
       "   chroma38  chroma39  chroma40  \n",
       "0  0.363818  0.353714  0.350808  \n",
       "1  0.380438  0.364385  0.329913  \n",
       "2  0.446582  0.428503  0.459803  \n",
       "3  0.360153  0.373736  0.369871  \n",
       "4  0.481968  0.456423  0.451458  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.drop(columns=['name','emotion','label'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x= scaler.fit_transform(np.array(data_copy.iloc[:, :], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.050767</td>\n",
       "      <td>-0.451380</td>\n",
       "      <td>0.235196</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>0.246012</td>\n",
       "      <td>0.553425</td>\n",
       "      <td>-0.123271</td>\n",
       "      <td>-0.288072</td>\n",
       "      <td>-0.747081</td>\n",
       "      <td>-0.627370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733906</td>\n",
       "      <td>0.859391</td>\n",
       "      <td>0.422104</td>\n",
       "      <td>0.883082</td>\n",
       "      <td>0.813325</td>\n",
       "      <td>-0.026577</td>\n",
       "      <td>-0.290855</td>\n",
       "      <td>-0.358060</td>\n",
       "      <td>-0.486113</td>\n",
       "      <td>-0.500753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.144805</td>\n",
       "      <td>-0.410528</td>\n",
       "      <td>0.849566</td>\n",
       "      <td>0.582633</td>\n",
       "      <td>0.754155</td>\n",
       "      <td>1.084621</td>\n",
       "      <td>0.032491</td>\n",
       "      <td>-0.449098</td>\n",
       "      <td>-0.598399</td>\n",
       "      <td>-0.517907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249795</td>\n",
       "      <td>0.484933</td>\n",
       "      <td>0.469621</td>\n",
       "      <td>0.608471</td>\n",
       "      <td>0.558546</td>\n",
       "      <td>0.285196</td>\n",
       "      <td>0.135579</td>\n",
       "      <td>-0.152802</td>\n",
       "      <td>-0.354809</td>\n",
       "      <td>-0.760362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.589915</td>\n",
       "      <td>-0.541763</td>\n",
       "      <td>0.846208</td>\n",
       "      <td>0.566740</td>\n",
       "      <td>0.725282</td>\n",
       "      <td>1.679957</td>\n",
       "      <td>-0.823599</td>\n",
       "      <td>-0.216466</td>\n",
       "      <td>-0.016831</td>\n",
       "      <td>0.296825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004511</td>\n",
       "      <td>0.594416</td>\n",
       "      <td>0.618808</td>\n",
       "      <td>0.573971</td>\n",
       "      <td>0.598626</td>\n",
       "      <td>0.583537</td>\n",
       "      <td>0.719621</td>\n",
       "      <td>0.664028</td>\n",
       "      <td>0.434182</td>\n",
       "      <td>0.853439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>-0.421048</td>\n",
       "      <td>1.150799</td>\n",
       "      <td>0.768277</td>\n",
       "      <td>0.999392</td>\n",
       "      <td>1.079817</td>\n",
       "      <td>0.129838</td>\n",
       "      <td>-0.750749</td>\n",
       "      <td>-0.378736</td>\n",
       "      <td>-0.432065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261210</td>\n",
       "      <td>0.130091</td>\n",
       "      <td>-0.172490</td>\n",
       "      <td>-0.219450</td>\n",
       "      <td>-0.102715</td>\n",
       "      <td>-0.324912</td>\n",
       "      <td>-0.373046</td>\n",
       "      <td>-0.403320</td>\n",
       "      <td>-0.239736</td>\n",
       "      <td>-0.263910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.395018</td>\n",
       "      <td>-0.538216</td>\n",
       "      <td>1.247470</td>\n",
       "      <td>0.816737</td>\n",
       "      <td>1.046210</td>\n",
       "      <td>0.900618</td>\n",
       "      <td>-0.926977</td>\n",
       "      <td>-0.462237</td>\n",
       "      <td>-0.154147</td>\n",
       "      <td>-0.427835</td>\n",
       "      <td>...</td>\n",
       "      <td>1.462393</td>\n",
       "      <td>1.374910</td>\n",
       "      <td>0.790236</td>\n",
       "      <td>0.449564</td>\n",
       "      <td>0.377744</td>\n",
       "      <td>0.479285</td>\n",
       "      <td>0.810225</td>\n",
       "      <td>1.101032</td>\n",
       "      <td>0.777751</td>\n",
       "      <td>0.749764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1915</td>\n",
       "      <td>0.065017</td>\n",
       "      <td>-0.442485</td>\n",
       "      <td>-1.696024</td>\n",
       "      <td>-1.636782</td>\n",
       "      <td>-1.808798</td>\n",
       "      <td>-1.574454</td>\n",
       "      <td>-0.485173</td>\n",
       "      <td>1.408264</td>\n",
       "      <td>1.916686</td>\n",
       "      <td>2.374902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.377518</td>\n",
       "      <td>-0.243309</td>\n",
       "      <td>0.164454</td>\n",
       "      <td>0.168096</td>\n",
       "      <td>-0.224662</td>\n",
       "      <td>-0.325388</td>\n",
       "      <td>-0.433723</td>\n",
       "      <td>-0.471233</td>\n",
       "      <td>-0.432086</td>\n",
       "      <td>-0.632110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1916</td>\n",
       "      <td>-0.472811</td>\n",
       "      <td>-0.501135</td>\n",
       "      <td>-1.678236</td>\n",
       "      <td>-1.468089</td>\n",
       "      <td>-1.765294</td>\n",
       "      <td>-1.493154</td>\n",
       "      <td>-0.461807</td>\n",
       "      <td>2.568229</td>\n",
       "      <td>1.476803</td>\n",
       "      <td>0.013385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687947</td>\n",
       "      <td>-0.880715</td>\n",
       "      <td>-0.999735</td>\n",
       "      <td>-0.827771</td>\n",
       "      <td>-0.562081</td>\n",
       "      <td>-0.024493</td>\n",
       "      <td>0.750085</td>\n",
       "      <td>0.925657</td>\n",
       "      <td>1.003065</td>\n",
       "      <td>0.877646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1917</td>\n",
       "      <td>0.235871</td>\n",
       "      <td>-0.418426</td>\n",
       "      <td>-1.464982</td>\n",
       "      <td>-1.169518</td>\n",
       "      <td>-1.491746</td>\n",
       "      <td>-1.505286</td>\n",
       "      <td>-0.224902</td>\n",
       "      <td>1.555987</td>\n",
       "      <td>1.671021</td>\n",
       "      <td>1.492042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201635</td>\n",
       "      <td>0.030787</td>\n",
       "      <td>-0.078105</td>\n",
       "      <td>-0.009030</td>\n",
       "      <td>-0.106703</td>\n",
       "      <td>-0.099288</td>\n",
       "      <td>0.101175</td>\n",
       "      <td>0.275604</td>\n",
       "      <td>0.413081</td>\n",
       "      <td>0.490802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1918</td>\n",
       "      <td>0.078038</td>\n",
       "      <td>-0.461103</td>\n",
       "      <td>-1.322956</td>\n",
       "      <td>-1.146629</td>\n",
       "      <td>-1.455190</td>\n",
       "      <td>-1.351931</td>\n",
       "      <td>-0.247179</td>\n",
       "      <td>1.080362</td>\n",
       "      <td>1.340503</td>\n",
       "      <td>1.473578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145370</td>\n",
       "      <td>0.244803</td>\n",
       "      <td>0.419039</td>\n",
       "      <td>0.498078</td>\n",
       "      <td>0.611865</td>\n",
       "      <td>0.418976</td>\n",
       "      <td>0.309938</td>\n",
       "      <td>0.477051</td>\n",
       "      <td>0.614190</td>\n",
       "      <td>0.547424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1919</td>\n",
       "      <td>-0.708209</td>\n",
       "      <td>-0.451273</td>\n",
       "      <td>-1.430797</td>\n",
       "      <td>-1.287609</td>\n",
       "      <td>-1.431220</td>\n",
       "      <td>-1.383055</td>\n",
       "      <td>-0.212750</td>\n",
       "      <td>1.790145</td>\n",
       "      <td>0.732889</td>\n",
       "      <td>1.708872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556049</td>\n",
       "      <td>-0.732836</td>\n",
       "      <td>-0.760337</td>\n",
       "      <td>-0.613422</td>\n",
       "      <td>-0.605268</td>\n",
       "      <td>-0.530073</td>\n",
       "      <td>-0.391759</td>\n",
       "      <td>-0.189954</td>\n",
       "      <td>-0.023526</td>\n",
       "      <td>-0.033540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.050767 -0.451380  0.235196  0.330093  0.246012  0.553425 -0.123271   \n",
       "1     0.144805 -0.410528  0.849566  0.582633  0.754155  1.084621  0.032491   \n",
       "2     0.589915 -0.541763  0.846208  0.566740  0.725282  1.679957 -0.823599   \n",
       "3     0.004612 -0.421048  1.150799  0.768277  0.999392  1.079817  0.129838   \n",
       "4     1.395018 -0.538216  1.247470  0.816737  1.046210  0.900618 -0.926977   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1915  0.065017 -0.442485 -1.696024 -1.636782 -1.808798 -1.574454 -0.485173   \n",
       "1916 -0.472811 -0.501135 -1.678236 -1.468089 -1.765294 -1.493154 -0.461807   \n",
       "1917  0.235871 -0.418426 -1.464982 -1.169518 -1.491746 -1.505286 -0.224902   \n",
       "1918  0.078038 -0.461103 -1.322956 -1.146629 -1.455190 -1.351931 -0.247179   \n",
       "1919 -0.708209 -0.451273 -1.430797 -1.287609 -1.431220 -1.383055 -0.212750   \n",
       "\n",
       "            7         8         9   ...        76        77        78  \\\n",
       "0    -0.288072 -0.747081 -0.627370  ...  0.733906  0.859391  0.422104   \n",
       "1    -0.449098 -0.598399 -0.517907  ...  0.249795  0.484933  0.469621   \n",
       "2    -0.216466 -0.016831  0.296825  ... -0.004511  0.594416  0.618808   \n",
       "3    -0.750749 -0.378736 -0.432065  ...  0.261210  0.130091 -0.172490   \n",
       "4    -0.462237 -0.154147 -0.427835  ...  1.462393  1.374910  0.790236   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1915  1.408264  1.916686  2.374902  ... -0.377518 -0.243309  0.164454   \n",
       "1916  2.568229  1.476803  0.013385  ... -0.687947 -0.880715 -0.999735   \n",
       "1917  1.555987  1.671021  1.492042  ...  0.201635  0.030787 -0.078105   \n",
       "1918  1.080362  1.340503  1.473578  ...  0.145370  0.244803  0.419039   \n",
       "1919  1.790145  0.732889  1.708872  ... -0.556049 -0.732836 -0.760337   \n",
       "\n",
       "            79        80        81        82        83        84        85  \n",
       "0     0.883082  0.813325 -0.026577 -0.290855 -0.358060 -0.486113 -0.500753  \n",
       "1     0.608471  0.558546  0.285196  0.135579 -0.152802 -0.354809 -0.760362  \n",
       "2     0.573971  0.598626  0.583537  0.719621  0.664028  0.434182  0.853439  \n",
       "3    -0.219450 -0.102715 -0.324912 -0.373046 -0.403320 -0.239736 -0.263910  \n",
       "4     0.449564  0.377744  0.479285  0.810225  1.101032  0.777751  0.749764  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1915  0.168096 -0.224662 -0.325388 -0.433723 -0.471233 -0.432086 -0.632110  \n",
       "1916 -0.827771 -0.562081 -0.024493  0.750085  0.925657  1.003065  0.877646  \n",
       "1917 -0.009030 -0.106703 -0.099288  0.101175  0.275604  0.413081  0.490802  \n",
       "1918  0.498078  0.611865  0.418976  0.309938  0.477051  0.614190  0.547424  \n",
       "1919 -0.613422 -0.605268 -0.530073 -0.391759 -0.189954 -0.023526 -0.033540  \n",
       "\n",
       "[1920 rows x 86 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansh/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svm_model=SVC(kernel='rbf',C=11,degree=3).fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pr=svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=svm_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.640625"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=2,weights='distance',algorithm='kd_tree').fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=knn.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb=GaussianNB().fit(x_train,y_train)\n",
    "gnb_pr=gnb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=gnb.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2916666666666667"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size=16, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(600,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=MLPClassifier(alpha=0.01, batch_size=16, hidden_layer_sizes=(600,), learning_rate='adaptive', max_iter=500)\n",
    "model.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.640625"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akansh/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(x_train,y_train)\n",
    "logistic_pred = logistic.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy 41.41%\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Test Accuracy {:.2f}%\".format(logistic.score(x_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(criterion= 'entropy', n_estimators= 800, max_depth= 20, min_samples_split= 5, random_state=101)\n",
    "forest.fit(x_train, y_train)\n",
    "forest_pred = forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Test Accuracy 54.43%\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Test Accuracy {:.2f}%\".format(forest.score(x_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MLPClassifier(alpha=0.01, batch_size=100, epsilon=1e-08, hidden_layer_sizes=(1000,), learning_rate='constant', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size=100, beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(1000,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl=accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.9375"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 3, 6, 5, 8, 3, 1, 1, 1, 3, 6, 7, 8, 6, 5, 7, 8, 3, 1, 5, 2, 2,\n",
       "       1, 2, 1, 4, 7, 1, 3, 7, 5, 7, 8, 3, 3, 2, 3, 4, 2, 8, 4, 1, 1, 8,\n",
       "       1, 7, 7, 2, 8, 7, 4, 2, 8, 5, 4, 5, 6, 6, 2, 6, 6, 7, 5, 6, 8, 1,\n",
       "       5, 2, 3, 6, 4, 8, 6, 3, 5, 6, 7, 1, 3, 5, 3, 3, 8, 3, 2, 5, 2, 5,\n",
       "       1, 4, 8, 5, 6, 8, 4, 4, 1, 7, 1, 7, 1, 7, 8, 3, 6, 6, 8, 2, 4, 2,\n",
       "       2, 7, 8, 3, 3, 7, 8, 7, 1, 2, 7, 8, 8, 4, 6, 5, 2, 7, 4, 4, 3, 7,\n",
       "       4, 1, 3, 6, 6, 2, 3, 7, 4, 4, 8, 5, 6, 6, 1, 2, 5, 4, 4, 3, 3, 6,\n",
       "       3, 8, 3, 4, 4, 3, 7, 5, 5, 5, 5, 3, 7, 4, 1, 5, 7, 8, 4, 8, 8, 1,\n",
       "       7, 7, 6, 5, 8, 4, 4, 4, 5, 5, 2, 6, 8, 6, 4, 1, 2, 8, 7, 3, 8, 3,\n",
       "       5, 6, 4, 7, 6, 7, 1, 5, 4, 5, 6, 6, 7, 4, 3, 2, 7, 4, 5, 3, 4, 7,\n",
       "       1, 1, 7, 6, 6, 3, 8, 6, 4, 6, 5, 4, 7, 4, 5, 5, 8, 2, 4, 7, 4, 6,\n",
       "       3, 7, 3, 4, 3, 3, 2, 4, 4, 6, 7, 5, 5, 1, 3, 8, 1, 7, 2, 5, 6, 4,\n",
       "       5, 8, 8, 5, 4, 8, 1, 7, 3, 8, 8, 2, 3, 2, 1, 2, 6, 2, 6, 1, 3, 6,\n",
       "       2, 7, 1, 7, 3, 5, 2, 4, 4, 3, 7, 3, 5, 5, 1, 7, 2, 7, 1, 3, 5, 7,\n",
       "       3, 5, 8, 1, 7, 6, 6, 8, 8, 6, 5, 8, 3, 6, 2, 8, 5, 4, 3, 6, 7, 3,\n",
       "       8, 4, 5, 7, 1, 5, 3, 6, 1, 1, 4, 7, 2, 3, 4, 7, 4, 6, 2, 5, 5, 6,\n",
       "       8, 1, 8, 4, 1, 6, 8, 2, 2, 7, 5, 8, 5, 5, 6, 2, 5, 7, 6, 1, 4, 6,\n",
       "       8, 3, 1, 2, 8, 8, 1, 1, 6, 6])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 7, 8, 5, 8, 3, 1, 8, 1, 3, 4, 1, 8, 4, 5, 7, 6, 3, 1, 5, 2, 2,\n",
       "       1, 2, 4, 4, 1, 7, 3, 7, 5, 7, 4, 3, 3, 2, 2, 6, 2, 8, 4, 1, 2, 1,\n",
       "       1, 7, 7, 2, 3, 7, 4, 2, 6, 7, 4, 5, 6, 4, 1, 3, 8, 4, 8, 3, 8, 1,\n",
       "       3, 2, 5, 6, 3, 8, 6, 1, 5, 6, 8, 1, 7, 5, 5, 5, 8, 3, 2, 7, 2, 5,\n",
       "       4, 1, 8, 5, 7, 8, 4, 4, 4, 7, 1, 7, 6, 5, 8, 1, 6, 8, 8, 2, 4, 2,\n",
       "       2, 4, 5, 5, 2, 7, 8, 1, 1, 4, 5, 8, 8, 6, 8, 7, 2, 3, 2, 4, 2, 8,\n",
       "       4, 1, 3, 6, 6, 2, 3, 8, 4, 1, 3, 5, 6, 6, 1, 2, 5, 4, 1, 3, 5, 6,\n",
       "       8, 8, 3, 3, 4, 3, 7, 5, 5, 5, 5, 3, 3, 4, 3, 7, 5, 8, 6, 8, 6, 1,\n",
       "       7, 2, 6, 5, 6, 8, 4, 4, 5, 5, 2, 6, 8, 7, 6, 1, 2, 8, 1, 3, 8, 3,\n",
       "       5, 3, 4, 8, 6, 8, 1, 5, 2, 3, 7, 6, 5, 4, 3, 2, 7, 6, 7, 7, 4, 5,\n",
       "       1, 4, 6, 6, 6, 3, 7, 6, 6, 6, 5, 4, 3, 4, 5, 5, 8, 4, 8, 7, 6, 5,\n",
       "       5, 2, 6, 5, 6, 3, 2, 4, 4, 6, 7, 5, 5, 1, 3, 8, 4, 7, 1, 5, 7, 4,\n",
       "       2, 8, 4, 5, 1, 3, 1, 4, 6, 8, 6, 2, 3, 7, 1, 2, 5, 4, 6, 1, 3, 6,\n",
       "       4, 8, 1, 7, 3, 7, 2, 2, 2, 3, 7, 3, 5, 5, 1, 3, 2, 7, 1, 3, 5, 1,\n",
       "       8, 7, 8, 1, 7, 6, 6, 5, 7, 6, 3, 4, 3, 6, 4, 8, 5, 4, 3, 6, 5, 4,\n",
       "       8, 8, 5, 7, 1, 5, 3, 6, 1, 1, 4, 7, 2, 3, 4, 8, 4, 6, 4, 5, 7, 6,\n",
       "       8, 1, 8, 4, 1, 7, 8, 4, 2, 7, 5, 8, 5, 5, 6, 4, 5, 7, 4, 7, 1, 3,\n",
       "       7, 8, 1, 2, 8, 3, 1, 1, 6, 7])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=pd.read_csv('saavvee.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma31</th>\n",
       "      <th>chroma32</th>\n",
       "      <th>chroma33</th>\n",
       "      <th>chroma34</th>\n",
       "      <th>chroma35</th>\n",
       "      <th>chroma36</th>\n",
       "      <th>chroma37</th>\n",
       "      <th>chroma38</th>\n",
       "      <th>chroma39</th>\n",
       "      <th>chroma40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>d01.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.393920</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>813.782244</td>\n",
       "      <td>1196.672323</td>\n",
       "      <td>1306.106940</td>\n",
       "      <td>0.014997</td>\n",
       "      <td>-608.06670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364996</td>\n",
       "      <td>0.379896</td>\n",
       "      <td>0.415330</td>\n",
       "      <td>0.416510</td>\n",
       "      <td>0.380505</td>\n",
       "      <td>0.372216</td>\n",
       "      <td>0.363030</td>\n",
       "      <td>0.354653</td>\n",
       "      <td>0.358105</td>\n",
       "      <td>0.340235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>476</td>\n",
       "      <td>n17.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>nuetral</td>\n",
       "      <td>0.354278</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>830.164313</td>\n",
       "      <td>1296.456247</td>\n",
       "      <td>1384.222898</td>\n",
       "      <td>0.023844</td>\n",
       "      <td>-604.96920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337089</td>\n",
       "      <td>0.324475</td>\n",
       "      <td>0.316751</td>\n",
       "      <td>0.331846</td>\n",
       "      <td>0.352019</td>\n",
       "      <td>0.397303</td>\n",
       "      <td>0.458941</td>\n",
       "      <td>0.467767</td>\n",
       "      <td>0.474734</td>\n",
       "      <td>0.461751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>477</td>\n",
       "      <td>su09.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.406514</td>\n",
       "      <td>0.009833</td>\n",
       "      <td>1026.556384</td>\n",
       "      <td>1473.063327</td>\n",
       "      <td>1875.413161</td>\n",
       "      <td>0.022524</td>\n",
       "      <td>-573.56490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417060</td>\n",
       "      <td>0.403727</td>\n",
       "      <td>0.394791</td>\n",
       "      <td>0.401452</td>\n",
       "      <td>0.390464</td>\n",
       "      <td>0.391067</td>\n",
       "      <td>0.406367</td>\n",
       "      <td>0.415129</td>\n",
       "      <td>0.426788</td>\n",
       "      <td>0.430615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478</td>\n",
       "      <td>su08.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.394880</td>\n",
       "      <td>0.007730</td>\n",
       "      <td>1157.352920</td>\n",
       "      <td>1486.602507</td>\n",
       "      <td>1941.054267</td>\n",
       "      <td>0.039211</td>\n",
       "      <td>-576.51794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412002</td>\n",
       "      <td>0.422335</td>\n",
       "      <td>0.436887</td>\n",
       "      <td>0.444563</td>\n",
       "      <td>0.451129</td>\n",
       "      <td>0.434277</td>\n",
       "      <td>0.423281</td>\n",
       "      <td>0.431441</td>\n",
       "      <td>0.443131</td>\n",
       "      <td>0.435172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>479</td>\n",
       "      <td>h12.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.336927</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>1058.038644</td>\n",
       "      <td>1403.211297</td>\n",
       "      <td>1984.094063</td>\n",
       "      <td>0.035824</td>\n",
       "      <td>-571.95404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348946</td>\n",
       "      <td>0.337333</td>\n",
       "      <td>0.337022</td>\n",
       "      <td>0.350069</td>\n",
       "      <td>0.348373</td>\n",
       "      <td>0.355150</td>\n",
       "      <td>0.366430</td>\n",
       "      <td>0.377430</td>\n",
       "      <td>0.391307</td>\n",
       "      <td>0.388412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         name  label    emotion  chroma_stft_mean  rmse_mean  spec_cent_mean  \\\n",
       "475   d01.wav      7    disgust          0.393920   0.008647      813.782244   \n",
       "476   n17.wav      1    nuetral          0.354278   0.005757      830.164313   \n",
       "477  su09.wav      8  surprised          0.406514   0.009833     1026.556384   \n",
       "478  su08.wav      8  surprised          0.394880   0.007730     1157.352920   \n",
       "479   h12.wav      3      happy          0.336927   0.008214     1058.038644   \n",
       "\n",
       "     spec_bw_mean  rolloff_mean  zcr_mean      mfcc1  ...  chroma31  chroma32  \\\n",
       "475   1196.672323   1306.106940  0.014997 -608.06670  ...  0.364996  0.379896   \n",
       "476   1296.456247   1384.222898  0.023844 -604.96920  ...  0.337089  0.324475   \n",
       "477   1473.063327   1875.413161  0.022524 -573.56490  ...  0.417060  0.403727   \n",
       "478   1486.602507   1941.054267  0.039211 -576.51794  ...  0.412002  0.422335   \n",
       "479   1403.211297   1984.094063  0.035824 -571.95404  ...  0.348946  0.337333   \n",
       "\n",
       "     chroma33  chroma34  chroma35  chroma36  chroma37  chroma38  chroma39  \\\n",
       "475  0.415330  0.416510  0.380505  0.372216  0.363030  0.354653  0.358105   \n",
       "476  0.316751  0.331846  0.352019  0.397303  0.458941  0.467767  0.474734   \n",
       "477  0.394791  0.401452  0.390464  0.391067  0.406367  0.415129  0.426788   \n",
       "478  0.436887  0.444563  0.451129  0.434277  0.423281  0.431441  0.443131   \n",
       "479  0.337022  0.350069  0.348373  0.355150  0.366430  0.377430  0.391307   \n",
       "\n",
       "     chroma40  \n",
       "475  0.340235  \n",
       "476  0.461751  \n",
       "477  0.430615  \n",
       "478  0.435172  \n",
       "479  0.388412  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('myexp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma31</th>\n",
       "      <th>chroma32</th>\n",
       "      <th>chroma33</th>\n",
       "      <th>chroma34</th>\n",
       "      <th>chroma35</th>\n",
       "      <th>chroma36</th>\n",
       "      <th>chroma37</th>\n",
       "      <th>chroma38</th>\n",
       "      <th>chroma39</th>\n",
       "      <th>chroma40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1435</td>\n",
       "      <td>03-01-07-02-01-02-03.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.332952</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>2847.874450</td>\n",
       "      <td>2541.621839</td>\n",
       "      <td>5492.061706</td>\n",
       "      <td>0.169652</td>\n",
       "      <td>-516.15630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372774</td>\n",
       "      <td>0.383578</td>\n",
       "      <td>0.405652</td>\n",
       "      <td>0.377539</td>\n",
       "      <td>0.309720</td>\n",
       "      <td>0.300858</td>\n",
       "      <td>0.318441</td>\n",
       "      <td>0.310022</td>\n",
       "      <td>0.312238</td>\n",
       "      <td>0.303578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1436</td>\n",
       "      <td>03-01-05-01-02-01-03.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.329320</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>2945.353252</td>\n",
       "      <td>2417.867577</td>\n",
       "      <td>5467.989294</td>\n",
       "      <td>0.203441</td>\n",
       "      <td>-526.08580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304812</td>\n",
       "      <td>0.315020</td>\n",
       "      <td>0.332258</td>\n",
       "      <td>0.338550</td>\n",
       "      <td>0.370293</td>\n",
       "      <td>0.381263</td>\n",
       "      <td>0.373701</td>\n",
       "      <td>0.353058</td>\n",
       "      <td>0.372548</td>\n",
       "      <td>0.363753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1437</td>\n",
       "      <td>03-01-05-01-01-01-03.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.399238</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>2960.675871</td>\n",
       "      <td>2643.400309</td>\n",
       "      <td>5821.557476</td>\n",
       "      <td>0.234829</td>\n",
       "      <td>-612.28955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457882</td>\n",
       "      <td>0.507040</td>\n",
       "      <td>0.499057</td>\n",
       "      <td>0.521603</td>\n",
       "      <td>0.487483</td>\n",
       "      <td>0.456211</td>\n",
       "      <td>0.455603</td>\n",
       "      <td>0.407726</td>\n",
       "      <td>0.359949</td>\n",
       "      <td>0.344216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1438</td>\n",
       "      <td>03-01-08-02-01-01-03.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.381489</td>\n",
       "      <td>0.013720</td>\n",
       "      <td>2911.762989</td>\n",
       "      <td>2503.437496</td>\n",
       "      <td>5653.534845</td>\n",
       "      <td>0.220083</td>\n",
       "      <td>-502.70844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298025</td>\n",
       "      <td>0.318704</td>\n",
       "      <td>0.309690</td>\n",
       "      <td>0.315289</td>\n",
       "      <td>0.334114</td>\n",
       "      <td>0.362409</td>\n",
       "      <td>0.411555</td>\n",
       "      <td>0.407700</td>\n",
       "      <td>0.372919</td>\n",
       "      <td>0.368946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1439</td>\n",
       "      <td>03-01-02-02-02-01-03.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>calm</td>\n",
       "      <td>0.378002</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>2631.754377</td>\n",
       "      <td>2437.602781</td>\n",
       "      <td>5177.532379</td>\n",
       "      <td>0.187950</td>\n",
       "      <td>-526.35706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363128</td>\n",
       "      <td>0.349147</td>\n",
       "      <td>0.356236</td>\n",
       "      <td>0.374016</td>\n",
       "      <td>0.385883</td>\n",
       "      <td>0.392970</td>\n",
       "      <td>0.410922</td>\n",
       "      <td>0.444881</td>\n",
       "      <td>0.448292</td>\n",
       "      <td>0.434641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  label    emotion  chroma_stft_mean  rmse_mean  \\\n",
       "1435  03-01-07-02-01-02-03.wav      7    disgust          0.332952   0.004596   \n",
       "1436  03-01-05-01-02-01-03.wav      5      angry          0.329320   0.007015   \n",
       "1437  03-01-05-01-01-01-03.wav      5      angry          0.399238   0.002378   \n",
       "1438  03-01-08-02-01-01-03.wav      8  surprised          0.381489   0.013720   \n",
       "1439  03-01-02-02-02-01-03.wav      2       calm          0.378002   0.009350   \n",
       "\n",
       "      spec_cent_mean  spec_bw_mean  rolloff_mean  zcr_mean      mfcc1  ...  \\\n",
       "1435     2847.874450   2541.621839   5492.061706  0.169652 -516.15630  ...   \n",
       "1436     2945.353252   2417.867577   5467.989294  0.203441 -526.08580  ...   \n",
       "1437     2960.675871   2643.400309   5821.557476  0.234829 -612.28955  ...   \n",
       "1438     2911.762989   2503.437496   5653.534845  0.220083 -502.70844  ...   \n",
       "1439     2631.754377   2437.602781   5177.532379  0.187950 -526.35706  ...   \n",
       "\n",
       "      chroma31  chroma32  chroma33  chroma34  chroma35  chroma36  chroma37  \\\n",
       "1435  0.372774  0.383578  0.405652  0.377539  0.309720  0.300858  0.318441   \n",
       "1436  0.304812  0.315020  0.332258  0.338550  0.370293  0.381263  0.373701   \n",
       "1437  0.457882  0.507040  0.499057  0.521603  0.487483  0.456211  0.455603   \n",
       "1438  0.298025  0.318704  0.309690  0.315289  0.334114  0.362409  0.411555   \n",
       "1439  0.363128  0.349147  0.356236  0.374016  0.385883  0.392970  0.410922   \n",
       "\n",
       "      chroma38  chroma39  chroma40  \n",
       "1435  0.310022  0.312238  0.303578  \n",
       "1436  0.353058  0.372548  0.363753  \n",
       "1437  0.407726  0.359949  0.344216  \n",
       "1438  0.407700  0.372919  0.368946  \n",
       "1439  0.444881  0.448292  0.434641  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in first 10 lines of surveys table\n",
    "data1 = data\n",
    "# Grab the last 10 rows\n",
    "data2 = data2\n",
    "# Reset the index values to the second dataframe appends properly\n",
    "data2=data2.reset_index(drop=True)\n",
    "# drop=True option avoids adding new index column with old index values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.concat([data1, data2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.to_csv('myexpfinal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('myexpfinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma31</th>\n",
       "      <th>chroma32</th>\n",
       "      <th>chroma33</th>\n",
       "      <th>chroma34</th>\n",
       "      <th>chroma35</th>\n",
       "      <th>chroma36</th>\n",
       "      <th>chroma37</th>\n",
       "      <th>chroma38</th>\n",
       "      <th>chroma39</th>\n",
       "      <th>chroma40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>03-01-03-02-01-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.385386</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>2592.308325</td>\n",
       "      <td>2360.097245</td>\n",
       "      <td>4995.771702</td>\n",
       "      <td>0.246548</td>\n",
       "      <td>-560.09265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464910</td>\n",
       "      <td>0.475772</td>\n",
       "      <td>0.437146</td>\n",
       "      <td>0.477294</td>\n",
       "      <td>0.468137</td>\n",
       "      <td>0.397129</td>\n",
       "      <td>0.374605</td>\n",
       "      <td>0.363818</td>\n",
       "      <td>0.353714</td>\n",
       "      <td>0.350808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>03-01-03-02-02-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.399802</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>3158.102896</td>\n",
       "      <td>2509.477352</td>\n",
       "      <td>5908.204274</td>\n",
       "      <td>0.304351</td>\n",
       "      <td>-539.44464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>0.443214</td>\n",
       "      <td>0.441170</td>\n",
       "      <td>0.453948</td>\n",
       "      <td>0.446627</td>\n",
       "      <td>0.423123</td>\n",
       "      <td>0.409154</td>\n",
       "      <td>0.380438</td>\n",
       "      <td>0.364385</td>\n",
       "      <td>0.329913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>03-01-03-01-02-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.432610</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>3155.010040</td>\n",
       "      <td>2500.076212</td>\n",
       "      <td>5856.358337</td>\n",
       "      <td>0.369135</td>\n",
       "      <td>-652.92870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398528</td>\n",
       "      <td>0.452733</td>\n",
       "      <td>0.453803</td>\n",
       "      <td>0.451015</td>\n",
       "      <td>0.450011</td>\n",
       "      <td>0.447997</td>\n",
       "      <td>0.456473</td>\n",
       "      <td>0.446582</td>\n",
       "      <td>0.428503</td>\n",
       "      <td>0.459803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>03-01-05-01-01-02-01.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.389468</td>\n",
       "      <td>0.009704</td>\n",
       "      <td>3435.518747</td>\n",
       "      <td>2619.287507</td>\n",
       "      <td>6348.558278</td>\n",
       "      <td>0.303829</td>\n",
       "      <td>-526.54034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422416</td>\n",
       "      <td>0.412361</td>\n",
       "      <td>0.386799</td>\n",
       "      <td>0.383563</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>0.372256</td>\n",
       "      <td>0.367946</td>\n",
       "      <td>0.360153</td>\n",
       "      <td>0.373736</td>\n",
       "      <td>0.369871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>03-01-08-01-02-02-01.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.491953</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>3524.545799</td>\n",
       "      <td>2647.952102</td>\n",
       "      <td>6432.624460</td>\n",
       "      <td>0.284329</td>\n",
       "      <td>-666.63245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530399</td>\n",
       "      <td>0.520594</td>\n",
       "      <td>0.468319</td>\n",
       "      <td>0.440439</td>\n",
       "      <td>0.431363</td>\n",
       "      <td>0.439305</td>\n",
       "      <td>0.463814</td>\n",
       "      <td>0.481968</td>\n",
       "      <td>0.456423</td>\n",
       "      <td>0.451458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  label    emotion  chroma_stft_mean  rmse_mean  \\\n",
       "0  03-01-03-02-01-02-01.wav      3      happy          0.385386   0.008209   \n",
       "1  03-01-03-02-02-02-01.wav      3      happy          0.399802   0.010222   \n",
       "2  03-01-03-01-02-02-01.wav      3      happy          0.432610   0.003754   \n",
       "3  03-01-05-01-01-02-01.wav      5      angry          0.389468   0.009704   \n",
       "4  03-01-08-01-02-02-01.wav      8  surprised          0.491953   0.003929   \n",
       "\n",
       "   spec_cent_mean  spec_bw_mean  rolloff_mean  zcr_mean      mfcc1  ...  \\\n",
       "0     2592.308325   2360.097245   4995.771702  0.246548 -560.09265  ...   \n",
       "1     3158.102896   2509.477352   5908.204274  0.304351 -539.44464  ...   \n",
       "2     3155.010040   2500.076212   5856.358337  0.369135 -652.92870  ...   \n",
       "3     3435.518747   2619.287507   6348.558278  0.303829 -526.54034  ...   \n",
       "4     3524.545799   2647.952102   6432.624460  0.284329 -666.63245  ...   \n",
       "\n",
       "   chroma31  chroma32  chroma33  chroma34  chroma35  chroma36  chroma37  \\\n",
       "0  0.464910  0.475772  0.437146  0.477294  0.468137  0.397129  0.374605   \n",
       "1  0.421389  0.443214  0.441170  0.453948  0.446627  0.423123  0.409154   \n",
       "2  0.398528  0.452733  0.453803  0.451015  0.450011  0.447997  0.456473   \n",
       "3  0.422416  0.412361  0.386799  0.383563  0.390801  0.372256  0.367946   \n",
       "4  0.530399  0.520594  0.468319  0.440439  0.431363  0.439305  0.463814   \n",
       "\n",
       "   chroma38  chroma39  chroma40  \n",
       "0  0.363818  0.353714  0.350808  \n",
       "1  0.380438  0.364385  0.329913  \n",
       "2  0.446582  0.428503  0.459803  \n",
       "3  0.360153  0.373736  0.369871  \n",
       "4  0.481968  0.456423  0.451458  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma31</th>\n",
       "      <th>chroma32</th>\n",
       "      <th>chroma33</th>\n",
       "      <th>chroma34</th>\n",
       "      <th>chroma35</th>\n",
       "      <th>chroma36</th>\n",
       "      <th>chroma37</th>\n",
       "      <th>chroma38</th>\n",
       "      <th>chroma39</th>\n",
       "      <th>chroma40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1915</td>\n",
       "      <td>d01.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.393920</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>813.782244</td>\n",
       "      <td>1196.672323</td>\n",
       "      <td>1306.106940</td>\n",
       "      <td>0.014997</td>\n",
       "      <td>-608.06670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364996</td>\n",
       "      <td>0.379896</td>\n",
       "      <td>0.415330</td>\n",
       "      <td>0.416510</td>\n",
       "      <td>0.380505</td>\n",
       "      <td>0.372216</td>\n",
       "      <td>0.363030</td>\n",
       "      <td>0.354653</td>\n",
       "      <td>0.358105</td>\n",
       "      <td>0.340235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1916</td>\n",
       "      <td>n17.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>nuetral</td>\n",
       "      <td>0.354278</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>830.164313</td>\n",
       "      <td>1296.456247</td>\n",
       "      <td>1384.222898</td>\n",
       "      <td>0.023844</td>\n",
       "      <td>-604.96920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337089</td>\n",
       "      <td>0.324475</td>\n",
       "      <td>0.316751</td>\n",
       "      <td>0.331846</td>\n",
       "      <td>0.352019</td>\n",
       "      <td>0.397303</td>\n",
       "      <td>0.458941</td>\n",
       "      <td>0.467767</td>\n",
       "      <td>0.474734</td>\n",
       "      <td>0.461751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1917</td>\n",
       "      <td>su09.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.406514</td>\n",
       "      <td>0.009833</td>\n",
       "      <td>1026.556384</td>\n",
       "      <td>1473.063327</td>\n",
       "      <td>1875.413161</td>\n",
       "      <td>0.022524</td>\n",
       "      <td>-573.56490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417060</td>\n",
       "      <td>0.403727</td>\n",
       "      <td>0.394791</td>\n",
       "      <td>0.401452</td>\n",
       "      <td>0.390464</td>\n",
       "      <td>0.391067</td>\n",
       "      <td>0.406367</td>\n",
       "      <td>0.415129</td>\n",
       "      <td>0.426788</td>\n",
       "      <td>0.430615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1918</td>\n",
       "      <td>su08.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.394880</td>\n",
       "      <td>0.007730</td>\n",
       "      <td>1157.352920</td>\n",
       "      <td>1486.602507</td>\n",
       "      <td>1941.054267</td>\n",
       "      <td>0.039211</td>\n",
       "      <td>-576.51794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412002</td>\n",
       "      <td>0.422335</td>\n",
       "      <td>0.436887</td>\n",
       "      <td>0.444563</td>\n",
       "      <td>0.451129</td>\n",
       "      <td>0.434277</td>\n",
       "      <td>0.423281</td>\n",
       "      <td>0.431441</td>\n",
       "      <td>0.443131</td>\n",
       "      <td>0.435172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1919</td>\n",
       "      <td>h12.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.336927</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>1058.038644</td>\n",
       "      <td>1403.211297</td>\n",
       "      <td>1984.094063</td>\n",
       "      <td>0.035824</td>\n",
       "      <td>-571.95404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348946</td>\n",
       "      <td>0.337333</td>\n",
       "      <td>0.337022</td>\n",
       "      <td>0.350069</td>\n",
       "      <td>0.348373</td>\n",
       "      <td>0.355150</td>\n",
       "      <td>0.366430</td>\n",
       "      <td>0.377430</td>\n",
       "      <td>0.391307</td>\n",
       "      <td>0.388412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  label    emotion  chroma_stft_mean  rmse_mean  spec_cent_mean  \\\n",
       "1915   d01.wav      7    disgust          0.393920   0.008647      813.782244   \n",
       "1916   n17.wav      1    nuetral          0.354278   0.005757      830.164313   \n",
       "1917  su09.wav      8  surprised          0.406514   0.009833     1026.556384   \n",
       "1918  su08.wav      8  surprised          0.394880   0.007730     1157.352920   \n",
       "1919   h12.wav      3      happy          0.336927   0.008214     1058.038644   \n",
       "\n",
       "      spec_bw_mean  rolloff_mean  zcr_mean      mfcc1  ...  chroma31  \\\n",
       "1915   1196.672323   1306.106940  0.014997 -608.06670  ...  0.364996   \n",
       "1916   1296.456247   1384.222898  0.023844 -604.96920  ...  0.337089   \n",
       "1917   1473.063327   1875.413161  0.022524 -573.56490  ...  0.417060   \n",
       "1918   1486.602507   1941.054267  0.039211 -576.51794  ...  0.412002   \n",
       "1919   1403.211297   1984.094063  0.035824 -571.95404  ...  0.348946   \n",
       "\n",
       "      chroma32  chroma33  chroma34  chroma35  chroma36  chroma37  chroma38  \\\n",
       "1915  0.379896  0.415330  0.416510  0.380505  0.372216  0.363030  0.354653   \n",
       "1916  0.324475  0.316751  0.331846  0.352019  0.397303  0.458941  0.467767   \n",
       "1917  0.403727  0.394791  0.401452  0.390464  0.391067  0.406367  0.415129   \n",
       "1918  0.422335  0.436887  0.444563  0.451129  0.434277  0.423281  0.431441   \n",
       "1919  0.337333  0.337022  0.350069  0.348373  0.355150  0.366430  0.377430   \n",
       "\n",
       "      chroma39  chroma40  \n",
       "1915  0.358105  0.340235  \n",
       "1916  0.474734  0.461751  \n",
       "1917  0.426788  0.430615  \n",
       "1918  0.443131  0.435172  \n",
       "1919  0.391307  0.388412  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 89)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>emotion</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>spec_cent_mean</th>\n",
       "      <th>spec_bw_mean</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma31</th>\n",
       "      <th>chroma32</th>\n",
       "      <th>chroma33</th>\n",
       "      <th>chroma34</th>\n",
       "      <th>chroma35</th>\n",
       "      <th>chroma36</th>\n",
       "      <th>chroma37</th>\n",
       "      <th>chroma38</th>\n",
       "      <th>chroma39</th>\n",
       "      <th>chroma40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>03-01-03-02-01-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.385386</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>2592.308325</td>\n",
       "      <td>2360.097245</td>\n",
       "      <td>4995.771702</td>\n",
       "      <td>0.246548</td>\n",
       "      <td>-560.09265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464910</td>\n",
       "      <td>0.475772</td>\n",
       "      <td>0.437146</td>\n",
       "      <td>0.477294</td>\n",
       "      <td>0.468137</td>\n",
       "      <td>0.397129</td>\n",
       "      <td>0.374605</td>\n",
       "      <td>0.363818</td>\n",
       "      <td>0.353714</td>\n",
       "      <td>0.350808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>03-01-03-02-02-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.399802</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>3158.102896</td>\n",
       "      <td>2509.477352</td>\n",
       "      <td>5908.204274</td>\n",
       "      <td>0.304351</td>\n",
       "      <td>-539.44464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>0.443214</td>\n",
       "      <td>0.441170</td>\n",
       "      <td>0.453948</td>\n",
       "      <td>0.446627</td>\n",
       "      <td>0.423123</td>\n",
       "      <td>0.409154</td>\n",
       "      <td>0.380438</td>\n",
       "      <td>0.364385</td>\n",
       "      <td>0.329913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>03-01-03-01-02-02-01.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.432610</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>3155.010040</td>\n",
       "      <td>2500.076212</td>\n",
       "      <td>5856.358337</td>\n",
       "      <td>0.369135</td>\n",
       "      <td>-652.92870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398528</td>\n",
       "      <td>0.452733</td>\n",
       "      <td>0.453803</td>\n",
       "      <td>0.451015</td>\n",
       "      <td>0.450011</td>\n",
       "      <td>0.447997</td>\n",
       "      <td>0.456473</td>\n",
       "      <td>0.446582</td>\n",
       "      <td>0.428503</td>\n",
       "      <td>0.459803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>03-01-05-01-01-02-01.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>angry</td>\n",
       "      <td>0.389468</td>\n",
       "      <td>0.009704</td>\n",
       "      <td>3435.518747</td>\n",
       "      <td>2619.287507</td>\n",
       "      <td>6348.558278</td>\n",
       "      <td>0.303829</td>\n",
       "      <td>-526.54034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422416</td>\n",
       "      <td>0.412361</td>\n",
       "      <td>0.386799</td>\n",
       "      <td>0.383563</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>0.372256</td>\n",
       "      <td>0.367946</td>\n",
       "      <td>0.360153</td>\n",
       "      <td>0.373736</td>\n",
       "      <td>0.369871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>03-01-08-01-02-02-01.wav</td>\n",
       "      <td>8</td>\n",
       "      <td>surprised</td>\n",
       "      <td>0.491953</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>3524.545799</td>\n",
       "      <td>2647.952102</td>\n",
       "      <td>6432.624460</td>\n",
       "      <td>0.284329</td>\n",
       "      <td>-666.63245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530399</td>\n",
       "      <td>0.520594</td>\n",
       "      <td>0.468319</td>\n",
       "      <td>0.440439</td>\n",
       "      <td>0.431363</td>\n",
       "      <td>0.439305</td>\n",
       "      <td>0.463814</td>\n",
       "      <td>0.481968</td>\n",
       "      <td>0.456423</td>\n",
       "      <td>0.451458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  label    emotion  chroma_stft_mean  rmse_mean  \\\n",
       "0  03-01-03-02-01-02-01.wav      3      happy          0.385386   0.008209   \n",
       "1  03-01-03-02-02-02-01.wav      3      happy          0.399802   0.010222   \n",
       "2  03-01-03-01-02-02-01.wav      3      happy          0.432610   0.003754   \n",
       "3  03-01-05-01-01-02-01.wav      5      angry          0.389468   0.009704   \n",
       "4  03-01-08-01-02-02-01.wav      8  surprised          0.491953   0.003929   \n",
       "\n",
       "   spec_cent_mean  spec_bw_mean  rolloff_mean  zcr_mean      mfcc1  ...  \\\n",
       "0     2592.308325   2360.097245   4995.771702  0.246548 -560.09265  ...   \n",
       "1     3158.102896   2509.477352   5908.204274  0.304351 -539.44464  ...   \n",
       "2     3155.010040   2500.076212   5856.358337  0.369135 -652.92870  ...   \n",
       "3     3435.518747   2619.287507   6348.558278  0.303829 -526.54034  ...   \n",
       "4     3524.545799   2647.952102   6432.624460  0.284329 -666.63245  ...   \n",
       "\n",
       "   chroma31  chroma32  chroma33  chroma34  chroma35  chroma36  chroma37  \\\n",
       "0  0.464910  0.475772  0.437146  0.477294  0.468137  0.397129  0.374605   \n",
       "1  0.421389  0.443214  0.441170  0.453948  0.446627  0.423123  0.409154   \n",
       "2  0.398528  0.452733  0.453803  0.451015  0.450011  0.447997  0.456473   \n",
       "3  0.422416  0.412361  0.386799  0.383563  0.390801  0.372256  0.367946   \n",
       "4  0.530399  0.520594  0.468319  0.440439  0.431363  0.439305  0.463814   \n",
       "\n",
       "   chroma38  chroma39  chroma40  \n",
       "0  0.363818  0.353714  0.350808  \n",
       "1  0.380438  0.364385  0.329913  \n",
       "2  0.446582  0.428503  0.459803  \n",
       "3  0.360153  0.373736  0.369871  \n",
       "4  0.481968  0.456423  0.451458  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x= scaler.fit_transform(np.array(data_copy.iloc[:, 9:], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.123271</td>\n",
       "      <td>-0.288072</td>\n",
       "      <td>-0.747081</td>\n",
       "      <td>-0.627370</td>\n",
       "      <td>0.067294</td>\n",
       "      <td>0.312925</td>\n",
       "      <td>-0.510812</td>\n",
       "      <td>-0.053274</td>\n",
       "      <td>-1.623166</td>\n",
       "      <td>-0.883179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733906</td>\n",
       "      <td>0.859391</td>\n",
       "      <td>0.422104</td>\n",
       "      <td>0.883082</td>\n",
       "      <td>0.813325</td>\n",
       "      <td>-0.026577</td>\n",
       "      <td>-0.290855</td>\n",
       "      <td>-0.358060</td>\n",
       "      <td>-0.486113</td>\n",
       "      <td>-0.500753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.032491</td>\n",
       "      <td>-0.449098</td>\n",
       "      <td>-0.598399</td>\n",
       "      <td>-0.517907</td>\n",
       "      <td>-0.311068</td>\n",
       "      <td>0.115859</td>\n",
       "      <td>-0.345679</td>\n",
       "      <td>-0.383540</td>\n",
       "      <td>-2.184343</td>\n",
       "      <td>-0.804625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249795</td>\n",
       "      <td>0.484933</td>\n",
       "      <td>0.469621</td>\n",
       "      <td>0.608471</td>\n",
       "      <td>0.558546</td>\n",
       "      <td>0.285196</td>\n",
       "      <td>0.135579</td>\n",
       "      <td>-0.152802</td>\n",
       "      <td>-0.354809</td>\n",
       "      <td>-0.760362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.823599</td>\n",
       "      <td>-0.216466</td>\n",
       "      <td>-0.016831</td>\n",
       "      <td>0.296825</td>\n",
       "      <td>0.080879</td>\n",
       "      <td>0.661427</td>\n",
       "      <td>0.647993</td>\n",
       "      <td>0.191073</td>\n",
       "      <td>-1.425583</td>\n",
       "      <td>-0.112583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004511</td>\n",
       "      <td>0.594416</td>\n",
       "      <td>0.618808</td>\n",
       "      <td>0.573971</td>\n",
       "      <td>0.598626</td>\n",
       "      <td>0.583537</td>\n",
       "      <td>0.719621</td>\n",
       "      <td>0.664028</td>\n",
       "      <td>0.434182</td>\n",
       "      <td>0.853439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.129838</td>\n",
       "      <td>-0.750749</td>\n",
       "      <td>-0.378736</td>\n",
       "      <td>-0.432065</td>\n",
       "      <td>-0.548518</td>\n",
       "      <td>0.071505</td>\n",
       "      <td>0.026371</td>\n",
       "      <td>-0.200033</td>\n",
       "      <td>-1.371373</td>\n",
       "      <td>-0.688096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261210</td>\n",
       "      <td>0.130091</td>\n",
       "      <td>-0.172490</td>\n",
       "      <td>-0.219450</td>\n",
       "      <td>-0.102715</td>\n",
       "      <td>-0.324912</td>\n",
       "      <td>-0.373046</td>\n",
       "      <td>-0.403320</td>\n",
       "      <td>-0.239736</td>\n",
       "      <td>-0.263910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.926977</td>\n",
       "      <td>-0.462237</td>\n",
       "      <td>-0.154147</td>\n",
       "      <td>-0.427835</td>\n",
       "      <td>-0.240376</td>\n",
       "      <td>0.027356</td>\n",
       "      <td>0.403734</td>\n",
       "      <td>0.026622</td>\n",
       "      <td>-0.633045</td>\n",
       "      <td>-0.478457</td>\n",
       "      <td>...</td>\n",
       "      <td>1.462393</td>\n",
       "      <td>1.374910</td>\n",
       "      <td>0.790236</td>\n",
       "      <td>0.449564</td>\n",
       "      <td>0.377744</td>\n",
       "      <td>0.479285</td>\n",
       "      <td>0.810225</td>\n",
       "      <td>1.101032</td>\n",
       "      <td>0.777751</td>\n",
       "      <td>0.749764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1915</td>\n",
       "      <td>-0.485173</td>\n",
       "      <td>1.408264</td>\n",
       "      <td>1.916686</td>\n",
       "      <td>2.374902</td>\n",
       "      <td>1.492352</td>\n",
       "      <td>-0.261187</td>\n",
       "      <td>-0.710830</td>\n",
       "      <td>1.183662</td>\n",
       "      <td>0.193541</td>\n",
       "      <td>-0.802939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.377518</td>\n",
       "      <td>-0.243309</td>\n",
       "      <td>0.164454</td>\n",
       "      <td>0.168096</td>\n",
       "      <td>-0.224662</td>\n",
       "      <td>-0.325388</td>\n",
       "      <td>-0.433723</td>\n",
       "      <td>-0.471233</td>\n",
       "      <td>-0.432086</td>\n",
       "      <td>-0.632110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1916</td>\n",
       "      <td>-0.461807</td>\n",
       "      <td>2.568229</td>\n",
       "      <td>1.476803</td>\n",
       "      <td>0.013385</td>\n",
       "      <td>0.920132</td>\n",
       "      <td>0.025714</td>\n",
       "      <td>0.287563</td>\n",
       "      <td>1.265769</td>\n",
       "      <td>-0.578306</td>\n",
       "      <td>-1.510732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687947</td>\n",
       "      <td>-0.880715</td>\n",
       "      <td>-0.999735</td>\n",
       "      <td>-0.827771</td>\n",
       "      <td>-0.562081</td>\n",
       "      <td>-0.024493</td>\n",
       "      <td>0.750085</td>\n",
       "      <td>0.925657</td>\n",
       "      <td>1.003065</td>\n",
       "      <td>0.877646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1917</td>\n",
       "      <td>-0.224902</td>\n",
       "      <td>1.555987</td>\n",
       "      <td>1.671021</td>\n",
       "      <td>1.492042</td>\n",
       "      <td>-0.042609</td>\n",
       "      <td>-0.413785</td>\n",
       "      <td>-0.089088</td>\n",
       "      <td>1.290629</td>\n",
       "      <td>-0.755057</td>\n",
       "      <td>-2.455698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201635</td>\n",
       "      <td>0.030787</td>\n",
       "      <td>-0.078105</td>\n",
       "      <td>-0.009030</td>\n",
       "      <td>-0.106703</td>\n",
       "      <td>-0.099288</td>\n",
       "      <td>0.101175</td>\n",
       "      <td>0.275604</td>\n",
       "      <td>0.413081</td>\n",
       "      <td>0.490802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1918</td>\n",
       "      <td>-0.247179</td>\n",
       "      <td>1.080362</td>\n",
       "      <td>1.340503</td>\n",
       "      <td>1.473578</td>\n",
       "      <td>-0.196594</td>\n",
       "      <td>0.627191</td>\n",
       "      <td>0.022078</td>\n",
       "      <td>0.368820</td>\n",
       "      <td>-1.302320</td>\n",
       "      <td>-2.024074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145370</td>\n",
       "      <td>0.244803</td>\n",
       "      <td>0.419039</td>\n",
       "      <td>0.498078</td>\n",
       "      <td>0.611865</td>\n",
       "      <td>0.418976</td>\n",
       "      <td>0.309938</td>\n",
       "      <td>0.477051</td>\n",
       "      <td>0.614190</td>\n",
       "      <td>0.547424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1919</td>\n",
       "      <td>-0.212750</td>\n",
       "      <td>1.790145</td>\n",
       "      <td>0.732889</td>\n",
       "      <td>1.708872</td>\n",
       "      <td>1.185949</td>\n",
       "      <td>0.310186</td>\n",
       "      <td>-1.152223</td>\n",
       "      <td>0.276989</td>\n",
       "      <td>-0.503986</td>\n",
       "      <td>-2.552100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.556049</td>\n",
       "      <td>-0.732836</td>\n",
       "      <td>-0.760337</td>\n",
       "      <td>-0.613422</td>\n",
       "      <td>-0.605268</td>\n",
       "      <td>-0.530073</td>\n",
       "      <td>-0.391759</td>\n",
       "      <td>-0.189954</td>\n",
       "      <td>-0.023526</td>\n",
       "      <td>-0.033540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.123271 -0.288072 -0.747081 -0.627370  0.067294  0.312925 -0.510812   \n",
       "1     0.032491 -0.449098 -0.598399 -0.517907 -0.311068  0.115859 -0.345679   \n",
       "2    -0.823599 -0.216466 -0.016831  0.296825  0.080879  0.661427  0.647993   \n",
       "3     0.129838 -0.750749 -0.378736 -0.432065 -0.548518  0.071505  0.026371   \n",
       "4    -0.926977 -0.462237 -0.154147 -0.427835 -0.240376  0.027356  0.403734   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1915 -0.485173  1.408264  1.916686  2.374902  1.492352 -0.261187 -0.710830   \n",
       "1916 -0.461807  2.568229  1.476803  0.013385  0.920132  0.025714  0.287563   \n",
       "1917 -0.224902  1.555987  1.671021  1.492042 -0.042609 -0.413785 -0.089088   \n",
       "1918 -0.247179  1.080362  1.340503  1.473578 -0.196594  0.627191  0.022078   \n",
       "1919 -0.212750  1.790145  0.732889  1.708872  1.185949  0.310186 -1.152223   \n",
       "\n",
       "            7         8         9   ...        70        71        72  \\\n",
       "0    -0.053274 -1.623166 -0.883179  ...  0.733906  0.859391  0.422104   \n",
       "1    -0.383540 -2.184343 -0.804625  ...  0.249795  0.484933  0.469621   \n",
       "2     0.191073 -1.425583 -0.112583  ... -0.004511  0.594416  0.618808   \n",
       "3    -0.200033 -1.371373 -0.688096  ...  0.261210  0.130091 -0.172490   \n",
       "4     0.026622 -0.633045 -0.478457  ...  1.462393  1.374910  0.790236   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1915  1.183662  0.193541 -0.802939  ... -0.377518 -0.243309  0.164454   \n",
       "1916  1.265769 -0.578306 -1.510732  ... -0.687947 -0.880715 -0.999735   \n",
       "1917  1.290629 -0.755057 -2.455698  ...  0.201635  0.030787 -0.078105   \n",
       "1918  0.368820 -1.302320 -2.024074  ...  0.145370  0.244803  0.419039   \n",
       "1919  0.276989 -0.503986 -2.552100  ... -0.556049 -0.732836 -0.760337   \n",
       "\n",
       "            73        74        75        76        77        78        79  \n",
       "0     0.883082  0.813325 -0.026577 -0.290855 -0.358060 -0.486113 -0.500753  \n",
       "1     0.608471  0.558546  0.285196  0.135579 -0.152802 -0.354809 -0.760362  \n",
       "2     0.573971  0.598626  0.583537  0.719621  0.664028  0.434182  0.853439  \n",
       "3    -0.219450 -0.102715 -0.324912 -0.373046 -0.403320 -0.239736 -0.263910  \n",
       "4     0.449564  0.377744  0.479285  0.810225  1.101032  0.777751  0.749764  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1915  0.168096 -0.224662 -0.325388 -0.433723 -0.471233 -0.432086 -0.632110  \n",
       "1916 -0.827771 -0.562081 -0.024493  0.750085  0.925657  1.003065  0.877646  \n",
       "1917 -0.009030 -0.106703 -0.099288  0.101175  0.275604  0.413081  0.490802  \n",
       "1918  0.498078  0.611865  0.418976  0.309938  0.477051  0.614190  0.547424  \n",
       "1919 -0.613422 -0.605268 -0.530073 -0.391759 -0.189954 -0.023526 -0.033540  \n",
       "\n",
       "[1920 rows x 80 columns]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy=data_copy.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.drop(columns=['name','emotion','label','chroma_stft_mean','rmse_mean','spec_cent_mean','spec_bw_mean'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.drop(columns=['zcr_mean','rolloff_mean'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>mfcc10</th>\n",
       "      <th>...</th>\n",
       "      <th>chroma31</th>\n",
       "      <th>chroma32</th>\n",
       "      <th>chroma33</th>\n",
       "      <th>chroma34</th>\n",
       "      <th>chroma35</th>\n",
       "      <th>chroma36</th>\n",
       "      <th>chroma37</th>\n",
       "      <th>chroma38</th>\n",
       "      <th>chroma39</th>\n",
       "      <th>chroma40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-560.09265</td>\n",
       "      <td>55.183110</td>\n",
       "      <td>-11.826187</td>\n",
       "      <td>5.802595</td>\n",
       "      <td>2.109796</td>\n",
       "      <td>-1.559523</td>\n",
       "      <td>-11.414464</td>\n",
       "      <td>-7.296623</td>\n",
       "      <td>-14.805033</td>\n",
       "      <td>-7.140440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464910</td>\n",
       "      <td>0.475772</td>\n",
       "      <td>0.437146</td>\n",
       "      <td>0.477294</td>\n",
       "      <td>0.468137</td>\n",
       "      <td>0.397129</td>\n",
       "      <td>0.374605</td>\n",
       "      <td>0.363818</td>\n",
       "      <td>0.353714</td>\n",
       "      <td>0.350808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-539.44464</td>\n",
       "      <td>50.090363</td>\n",
       "      <td>-9.412655</td>\n",
       "      <td>7.331817</td>\n",
       "      <td>-1.538751</td>\n",
       "      <td>-2.915135</td>\n",
       "      <td>-10.203468</td>\n",
       "      <td>-9.219710</td>\n",
       "      <td>-17.610708</td>\n",
       "      <td>-6.740697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421389</td>\n",
       "      <td>0.443214</td>\n",
       "      <td>0.441170</td>\n",
       "      <td>0.453948</td>\n",
       "      <td>0.446627</td>\n",
       "      <td>0.423123</td>\n",
       "      <td>0.409154</td>\n",
       "      <td>0.380438</td>\n",
       "      <td>0.364385</td>\n",
       "      <td>0.329913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-652.92870</td>\n",
       "      <td>57.447765</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>18.713766</td>\n",
       "      <td>2.240795</td>\n",
       "      <td>0.837826</td>\n",
       "      <td>-2.916430</td>\n",
       "      <td>-5.873826</td>\n",
       "      <td>-13.817194</td>\n",
       "      <td>-3.219101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398528</td>\n",
       "      <td>0.452733</td>\n",
       "      <td>0.453803</td>\n",
       "      <td>0.451015</td>\n",
       "      <td>0.450011</td>\n",
       "      <td>0.447997</td>\n",
       "      <td>0.456473</td>\n",
       "      <td>0.446582</td>\n",
       "      <td>0.428503</td>\n",
       "      <td>0.459803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-526.54034</td>\n",
       "      <td>40.550125</td>\n",
       "      <td>-5.846923</td>\n",
       "      <td>8.531040</td>\n",
       "      <td>-3.828484</td>\n",
       "      <td>-3.220251</td>\n",
       "      <td>-7.475059</td>\n",
       "      <td>-8.151176</td>\n",
       "      <td>-13.546168</td>\n",
       "      <td>-6.147716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422416</td>\n",
       "      <td>0.412361</td>\n",
       "      <td>0.386799</td>\n",
       "      <td>0.383563</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>0.372256</td>\n",
       "      <td>0.367946</td>\n",
       "      <td>0.360153</td>\n",
       "      <td>0.373736</td>\n",
       "      <td>0.369871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-666.63245</td>\n",
       "      <td>49.674820</td>\n",
       "      <td>-2.201217</td>\n",
       "      <td>8.590131</td>\n",
       "      <td>-0.857066</td>\n",
       "      <td>-3.523950</td>\n",
       "      <td>-4.707689</td>\n",
       "      <td>-6.831404</td>\n",
       "      <td>-9.854806</td>\n",
       "      <td>-5.080925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530399</td>\n",
       "      <td>0.520594</td>\n",
       "      <td>0.468319</td>\n",
       "      <td>0.440439</td>\n",
       "      <td>0.431363</td>\n",
       "      <td>0.439305</td>\n",
       "      <td>0.463814</td>\n",
       "      <td>0.481968</td>\n",
       "      <td>0.456423</td>\n",
       "      <td>0.451458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mfcc1      mfcc2      mfcc3      mfcc4     mfcc5     mfcc6      mfcc7  \\\n",
       "0 -560.09265  55.183110 -11.826187   5.802595  2.109796 -1.559523 -11.414464   \n",
       "1 -539.44464  50.090363  -9.412655   7.331817 -1.538751 -2.915135 -10.203468   \n",
       "2 -652.92870  57.447765   0.027809  18.713766  2.240795  0.837826  -2.916430   \n",
       "3 -526.54034  40.550125  -5.846923   8.531040 -3.828484 -3.220251  -7.475059   \n",
       "4 -666.63245  49.674820  -2.201217   8.590131 -0.857066 -3.523950  -4.707689   \n",
       "\n",
       "      mfcc8      mfcc9    mfcc10  ...  chroma31  chroma32  chroma33  chroma34  \\\n",
       "0 -7.296623 -14.805033 -7.140440  ...  0.464910  0.475772  0.437146  0.477294   \n",
       "1 -9.219710 -17.610708 -6.740697  ...  0.421389  0.443214  0.441170  0.453948   \n",
       "2 -5.873826 -13.817194 -3.219101  ...  0.398528  0.452733  0.453803  0.451015   \n",
       "3 -8.151176 -13.546168 -6.147716  ...  0.422416  0.412361  0.386799  0.383563   \n",
       "4 -6.831404  -9.854806 -5.080925  ...  0.530399  0.520594  0.468319  0.440439   \n",
       "\n",
       "   chroma35  chroma36  chroma37  chroma38  chroma39  chroma40  \n",
       "0  0.468137  0.397129  0.374605  0.363818  0.353714  0.350808  \n",
       "1  0.446627  0.423123  0.409154  0.380438  0.364385  0.329913  \n",
       "2  0.450011  0.447997  0.456473  0.446582  0.428503  0.459803  \n",
       "3  0.390801  0.372256  0.367946  0.360153  0.373736  0.369871  \n",
       "4  0.431363  0.439305  0.463814  0.481968  0.456423  0.451458  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 7, 7, 2])"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tried the encoder of sklearn and compared with manual encoding. results had no huge difference.\n",
    "encoder = LabelEncoder()\n",
    "y =  encoder.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(data_copy,y,random_state=1,stratify=y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn = np.expand_dims(x_train, axis=2)\n",
    "x_testcnn = np.expand_dims(x_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1536, 80, 1), (384, 80, 1))"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincnn.shape, x_testcnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 8,padding='same',\n",
    "                 input_shape=(80,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(5)))\n",
    "model.add(Conv1D(256, 8,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D(pool_size=(5)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr=0.00003, rho=0.9, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1536 samples, validate on 384 samples\n",
      "Epoch 1/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 3.2824 - accuracy: 0.1419 - val_loss: 2.0327 - val_accuracy: 0.1771\n",
      "Epoch 2/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 2.2242 - accuracy: 0.2129 - val_loss: 1.9648 - val_accuracy: 0.2161\n",
      "Epoch 3/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 2.0661 - accuracy: 0.2188 - val_loss: 1.8775 - val_accuracy: 0.2656\n",
      "Epoch 4/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.9622 - accuracy: 0.2337 - val_loss: 1.9355 - val_accuracy: 0.2005\n",
      "Epoch 5/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.9255 - accuracy: 0.2728 - val_loss: 1.8555 - val_accuracy: 0.2682\n",
      "Epoch 6/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.8672 - accuracy: 0.2891 - val_loss: 1.8736 - val_accuracy: 0.2865\n",
      "Epoch 7/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.8660 - accuracy: 0.2891 - val_loss: 1.8285 - val_accuracy: 0.3073\n",
      "Epoch 8/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.8307 - accuracy: 0.2904 - val_loss: 1.8497 - val_accuracy: 0.3073\n",
      "Epoch 9/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.8189 - accuracy: 0.3151 - val_loss: 1.8276 - val_accuracy: 0.3099\n",
      "Epoch 10/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.8045 - accuracy: 0.3008 - val_loss: 1.7673 - val_accuracy: 0.3359\n",
      "Epoch 11/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.7716 - accuracy: 0.3294 - val_loss: 1.7754 - val_accuracy: 0.3151\n",
      "Epoch 12/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.7604 - accuracy: 0.3294 - val_loss: 1.8591 - val_accuracy: 0.2786\n",
      "Epoch 13/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.7370 - accuracy: 0.3411 - val_loss: 1.7865 - val_accuracy: 0.3307\n",
      "Epoch 14/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.7311 - accuracy: 0.3464 - val_loss: 1.7607 - val_accuracy: 0.2969\n",
      "Epoch 15/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.7177 - accuracy: 0.3516 - val_loss: 1.7418 - val_accuracy: 0.3151\n",
      "Epoch 16/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.7096 - accuracy: 0.3685 - val_loss: 1.7309 - val_accuracy: 0.3229\n",
      "Epoch 17/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.6858 - accuracy: 0.3600 - val_loss: 1.7443 - val_accuracy: 0.2943\n",
      "Epoch 18/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.6819 - accuracy: 0.3626 - val_loss: 1.6695 - val_accuracy: 0.3516\n",
      "Epoch 19/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.6515 - accuracy: 0.3802 - val_loss: 1.7086 - val_accuracy: 0.2943\n",
      "Epoch 20/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.6572 - accuracy: 0.3750 - val_loss: 1.7039 - val_accuracy: 0.3750\n",
      "Epoch 21/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.6472 - accuracy: 0.3750 - val_loss: 1.6622 - val_accuracy: 0.3646\n",
      "Epoch 22/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.6406 - accuracy: 0.3796 - val_loss: 1.7188 - val_accuracy: 0.3229\n",
      "Epoch 23/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.6168 - accuracy: 0.3835 - val_loss: 1.6812 - val_accuracy: 0.3568\n",
      "Epoch 24/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.6115 - accuracy: 0.3939 - val_loss: 1.6328 - val_accuracy: 0.3828\n",
      "Epoch 25/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.5881 - accuracy: 0.3958 - val_loss: 1.6518 - val_accuracy: 0.3464\n",
      "Epoch 26/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.5707 - accuracy: 0.4076 - val_loss: 1.6677 - val_accuracy: 0.3385\n",
      "Epoch 27/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.5765 - accuracy: 0.4082 - val_loss: 1.6770 - val_accuracy: 0.3203\n",
      "Epoch 28/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.5616 - accuracy: 0.4160 - val_loss: 1.6042 - val_accuracy: 0.3958\n",
      "Epoch 29/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.5449 - accuracy: 0.4297 - val_loss: 1.6172 - val_accuracy: 0.4193\n",
      "Epoch 30/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.5402 - accuracy: 0.4251 - val_loss: 1.5927 - val_accuracy: 0.3828\n",
      "Epoch 31/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.5270 - accuracy: 0.4355 - val_loss: 1.6281 - val_accuracy: 0.3750\n",
      "Epoch 32/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.5114 - accuracy: 0.4440 - val_loss: 1.5420 - val_accuracy: 0.4193\n",
      "Epoch 33/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.4997 - accuracy: 0.4368 - val_loss: 1.6151 - val_accuracy: 0.3750\n",
      "Epoch 34/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.4844 - accuracy: 0.4395 - val_loss: 1.5779 - val_accuracy: 0.4219\n",
      "Epoch 35/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.5015 - accuracy: 0.4427 - val_loss: 1.5589 - val_accuracy: 0.4062\n",
      "Epoch 36/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.4859 - accuracy: 0.4303 - val_loss: 1.5371 - val_accuracy: 0.4323\n",
      "Epoch 37/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.4717 - accuracy: 0.4544 - val_loss: 1.5431 - val_accuracy: 0.4141\n",
      "Epoch 38/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.4542 - accuracy: 0.4486 - val_loss: 1.5961 - val_accuracy: 0.3516\n",
      "Epoch 39/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.4590 - accuracy: 0.4525 - val_loss: 1.5325 - val_accuracy: 0.4036\n",
      "Epoch 40/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.4431 - accuracy: 0.4707 - val_loss: 1.4818 - val_accuracy: 0.4427\n",
      "Epoch 41/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.4271 - accuracy: 0.4531 - val_loss: 1.5200 - val_accuracy: 0.4479\n",
      "Epoch 42/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.4335 - accuracy: 0.4707 - val_loss: 1.4917 - val_accuracy: 0.4141\n",
      "Epoch 43/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.4085 - accuracy: 0.4889 - val_loss: 1.4780 - val_accuracy: 0.4401\n",
      "Epoch 44/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.4029 - accuracy: 0.4785 - val_loss: 1.5106 - val_accuracy: 0.4193\n",
      "Epoch 45/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.3946 - accuracy: 0.4837 - val_loss: 1.5815 - val_accuracy: 0.3646\n",
      "Epoch 46/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.3956 - accuracy: 0.4818 - val_loss: 1.4927 - val_accuracy: 0.4661\n",
      "Epoch 47/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.3748 - accuracy: 0.4902 - val_loss: 1.4507 - val_accuracy: 0.4479\n",
      "Epoch 48/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.3571 - accuracy: 0.4857 - val_loss: 1.5513 - val_accuracy: 0.3906\n",
      "Epoch 49/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.3594 - accuracy: 0.4883 - val_loss: 1.4708 - val_accuracy: 0.4531\n",
      "Epoch 50/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.3364 - accuracy: 0.5020 - val_loss: 1.4517 - val_accuracy: 0.4635\n",
      "Epoch 51/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.3420 - accuracy: 0.5033 - val_loss: 1.4672 - val_accuracy: 0.4453\n",
      "Epoch 52/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.3361 - accuracy: 0.4954 - val_loss: 1.4226 - val_accuracy: 0.4714\n",
      "Epoch 53/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.3312 - accuracy: 0.5065 - val_loss: 1.4520 - val_accuracy: 0.4583\n",
      "Epoch 54/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.3324 - accuracy: 0.5085 - val_loss: 1.4399 - val_accuracy: 0.4349\n",
      "Epoch 55/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.3011 - accuracy: 0.5221 - val_loss: 1.4964 - val_accuracy: 0.4271\n",
      "Epoch 56/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.2944 - accuracy: 0.5221 - val_loss: 1.4447 - val_accuracy: 0.4609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.3101 - accuracy: 0.5078 - val_loss: 1.4878 - val_accuracy: 0.4427\n",
      "Epoch 58/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.2862 - accuracy: 0.5260 - val_loss: 1.4962 - val_accuracy: 0.4766\n",
      "Epoch 59/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.2735 - accuracy: 0.5202 - val_loss: 1.4938 - val_accuracy: 0.4583\n",
      "Epoch 60/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.2755 - accuracy: 0.5260 - val_loss: 1.4117 - val_accuracy: 0.4714\n",
      "Epoch 61/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.2622 - accuracy: 0.5260 - val_loss: 1.4986 - val_accuracy: 0.4401\n",
      "Epoch 62/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.2653 - accuracy: 0.5215 - val_loss: 1.4488 - val_accuracy: 0.4844\n",
      "Epoch 63/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.2685 - accuracy: 0.5273 - val_loss: 1.3907 - val_accuracy: 0.5026\n",
      "Epoch 64/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.2531 - accuracy: 0.5339 - val_loss: 1.4297 - val_accuracy: 0.4688\n",
      "Epoch 65/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.2204 - accuracy: 0.5592 - val_loss: 1.4513 - val_accuracy: 0.4557\n",
      "Epoch 66/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.2287 - accuracy: 0.5384 - val_loss: 1.3814 - val_accuracy: 0.4635\n",
      "Epoch 67/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.2165 - accuracy: 0.5560 - val_loss: 1.3875 - val_accuracy: 0.4792\n",
      "Epoch 68/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.2005 - accuracy: 0.5391 - val_loss: 1.3646 - val_accuracy: 0.4922\n",
      "Epoch 69/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.2159 - accuracy: 0.5469 - val_loss: 1.3775 - val_accuracy: 0.4844\n",
      "Epoch 70/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.2067 - accuracy: 0.5612 - val_loss: 1.3821 - val_accuracy: 0.4792\n",
      "Epoch 71/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1862 - accuracy: 0.5658 - val_loss: 1.3881 - val_accuracy: 0.4661\n",
      "Epoch 72/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1905 - accuracy: 0.5632 - val_loss: 1.4259 - val_accuracy: 0.4375\n",
      "Epoch 73/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1753 - accuracy: 0.5723 - val_loss: 1.4194 - val_accuracy: 0.4661\n",
      "Epoch 74/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1707 - accuracy: 0.5716 - val_loss: 1.3717 - val_accuracy: 0.5234\n",
      "Epoch 75/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1532 - accuracy: 0.5645 - val_loss: 1.3721 - val_accuracy: 0.4844\n",
      "Epoch 76/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1593 - accuracy: 0.5599 - val_loss: 1.3289 - val_accuracy: 0.5130\n",
      "Epoch 77/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1639 - accuracy: 0.5775 - val_loss: 1.4520 - val_accuracy: 0.4714\n",
      "Epoch 78/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1738 - accuracy: 0.5618 - val_loss: 1.3821 - val_accuracy: 0.4948\n",
      "Epoch 79/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1365 - accuracy: 0.5794 - val_loss: 1.3539 - val_accuracy: 0.5052\n",
      "Epoch 80/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1357 - accuracy: 0.5964 - val_loss: 1.3892 - val_accuracy: 0.4974\n",
      "Epoch 81/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1305 - accuracy: 0.5801 - val_loss: 1.4010 - val_accuracy: 0.4401\n",
      "Epoch 82/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1205 - accuracy: 0.5833 - val_loss: 1.3451 - val_accuracy: 0.5078\n",
      "Epoch 83/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1156 - accuracy: 0.5898 - val_loss: 1.3722 - val_accuracy: 0.4792\n",
      "Epoch 84/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1179 - accuracy: 0.5846 - val_loss: 1.3529 - val_accuracy: 0.4792\n",
      "Epoch 85/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.1113 - accuracy: 0.5924 - val_loss: 1.3337 - val_accuracy: 0.5026\n",
      "Epoch 86/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0943 - accuracy: 0.5846 - val_loss: 1.3230 - val_accuracy: 0.5260\n",
      "Epoch 87/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0815 - accuracy: 0.6003 - val_loss: 1.3932 - val_accuracy: 0.4896\n",
      "Epoch 88/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0846 - accuracy: 0.5951 - val_loss: 1.3164 - val_accuracy: 0.4766\n",
      "Epoch 89/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0740 - accuracy: 0.6003 - val_loss: 1.3029 - val_accuracy: 0.5469\n",
      "Epoch 90/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0734 - accuracy: 0.5983 - val_loss: 1.3427 - val_accuracy: 0.5078\n",
      "Epoch 91/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0577 - accuracy: 0.6087 - val_loss: 1.3062 - val_accuracy: 0.5234\n",
      "Epoch 92/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0944 - accuracy: 0.5905 - val_loss: 1.2997 - val_accuracy: 0.5443\n",
      "Epoch 93/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0314 - accuracy: 0.6270 - val_loss: 1.2955 - val_accuracy: 0.5260\n",
      "Epoch 94/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0684 - accuracy: 0.5931 - val_loss: 1.2948 - val_accuracy: 0.5078\n",
      "Epoch 95/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0454 - accuracy: 0.6094 - val_loss: 1.3703 - val_accuracy: 0.4870\n",
      "Epoch 96/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0311 - accuracy: 0.6243 - val_loss: 1.3166 - val_accuracy: 0.5312\n",
      "Epoch 97/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0167 - accuracy: 0.6257 - val_loss: 1.2700 - val_accuracy: 0.5469\n",
      "Epoch 98/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0283 - accuracy: 0.6289 - val_loss: 1.2703 - val_accuracy: 0.5547\n",
      "Epoch 99/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0212 - accuracy: 0.6257 - val_loss: 1.2881 - val_accuracy: 0.5443\n",
      "Epoch 100/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0240 - accuracy: 0.6263 - val_loss: 1.3017 - val_accuracy: 0.5391\n",
      "Epoch 101/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0117 - accuracy: 0.6374 - val_loss: 1.2736 - val_accuracy: 0.5312\n",
      "Epoch 102/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1.0117 - accuracy: 0.6309 - val_loss: 1.3133 - val_accuracy: 0.5234\n",
      "Epoch 103/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9837 - accuracy: 0.6491 - val_loss: 1.2981 - val_accuracy: 0.5156\n",
      "Epoch 104/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9713 - accuracy: 0.6354 - val_loss: 1.4651 - val_accuracy: 0.4427\n",
      "Epoch 105/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9834 - accuracy: 0.6374 - val_loss: 1.3147 - val_accuracy: 0.5182\n",
      "Epoch 106/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9732 - accuracy: 0.6367 - val_loss: 1.2638 - val_accuracy: 0.5208\n",
      "Epoch 107/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9711 - accuracy: 0.6432 - val_loss: 1.2629 - val_accuracy: 0.5547\n",
      "Epoch 108/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9645 - accuracy: 0.6562 - val_loss: 1.3367 - val_accuracy: 0.5182\n",
      "Epoch 109/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9611 - accuracy: 0.6569 - val_loss: 1.4506 - val_accuracy: 0.4557\n",
      "Epoch 110/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9361 - accuracy: 0.6595 - val_loss: 1.3476 - val_accuracy: 0.5156\n",
      "Epoch 111/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9758 - accuracy: 0.6393 - val_loss: 1.2945 - val_accuracy: 0.5078\n",
      "Epoch 112/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9408 - accuracy: 0.6621 - val_loss: 1.2699 - val_accuracy: 0.5286\n",
      "Epoch 113/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9414 - accuracy: 0.6556 - val_loss: 1.2509 - val_accuracy: 0.5417\n",
      "Epoch 114/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9187 - accuracy: 0.6589 - val_loss: 1.2792 - val_accuracy: 0.5573\n",
      "Epoch 115/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9341 - accuracy: 0.6615 - val_loss: 1.2507 - val_accuracy: 0.5755\n",
      "Epoch 116/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9121 - accuracy: 0.6771 - val_loss: 1.3357 - val_accuracy: 0.5182\n",
      "Epoch 117/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9216 - accuracy: 0.6849 - val_loss: 1.3579 - val_accuracy: 0.4870\n",
      "Epoch 118/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9300 - accuracy: 0.6621 - val_loss: 1.2851 - val_accuracy: 0.5312\n",
      "Epoch 119/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9218 - accuracy: 0.6667 - val_loss: 1.2359 - val_accuracy: 0.5573\n",
      "Epoch 120/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9036 - accuracy: 0.6686 - val_loss: 1.2342 - val_accuracy: 0.5729\n",
      "Epoch 121/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9186 - accuracy: 0.6556 - val_loss: 1.2963 - val_accuracy: 0.5052\n",
      "Epoch 122/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8944 - accuracy: 0.6673 - val_loss: 1.3337 - val_accuracy: 0.5156\n",
      "Epoch 123/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.9091 - accuracy: 0.6602 - val_loss: 1.2383 - val_accuracy: 0.5755\n",
      "Epoch 124/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8794 - accuracy: 0.6745 - val_loss: 1.2777 - val_accuracy: 0.5339\n",
      "Epoch 125/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8890 - accuracy: 0.6712 - val_loss: 1.2161 - val_accuracy: 0.5625\n",
      "Epoch 126/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8588 - accuracy: 0.6953 - val_loss: 1.2695 - val_accuracy: 0.5365\n",
      "Epoch 127/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8735 - accuracy: 0.6927 - val_loss: 1.2373 - val_accuracy: 0.5625\n",
      "Epoch 128/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8524 - accuracy: 0.6836 - val_loss: 1.2530 - val_accuracy: 0.5469\n",
      "Epoch 129/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8728 - accuracy: 0.6719 - val_loss: 1.2236 - val_accuracy: 0.5599\n",
      "Epoch 130/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8551 - accuracy: 0.7129 - val_loss: 1.3002 - val_accuracy: 0.5312\n",
      "Epoch 131/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8362 - accuracy: 0.7025 - val_loss: 1.2509 - val_accuracy: 0.5781\n",
      "Epoch 132/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8478 - accuracy: 0.6908 - val_loss: 1.2666 - val_accuracy: 0.5443\n",
      "Epoch 133/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8339 - accuracy: 0.6934 - val_loss: 1.2860 - val_accuracy: 0.5078\n",
      "Epoch 134/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8275 - accuracy: 0.7038 - val_loss: 1.3296 - val_accuracy: 0.5286\n",
      "Epoch 135/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8122 - accuracy: 0.7077 - val_loss: 1.2536 - val_accuracy: 0.5703\n",
      "Epoch 136/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8368 - accuracy: 0.6921 - val_loss: 1.2283 - val_accuracy: 0.5885\n",
      "Epoch 137/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8275 - accuracy: 0.7031 - val_loss: 1.2837 - val_accuracy: 0.5286\n",
      "Epoch 138/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8190 - accuracy: 0.6979 - val_loss: 1.2431 - val_accuracy: 0.5703\n",
      "Epoch 139/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8087 - accuracy: 0.7083 - val_loss: 1.1963 - val_accuracy: 0.5625\n",
      "Epoch 140/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8147 - accuracy: 0.6927 - val_loss: 1.3765 - val_accuracy: 0.4922\n",
      "Epoch 141/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.8134 - accuracy: 0.7025 - val_loss: 1.2919 - val_accuracy: 0.5286\n",
      "Epoch 142/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7881 - accuracy: 0.7129 - val_loss: 1.5022 - val_accuracy: 0.5026\n",
      "Epoch 143/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7817 - accuracy: 0.7129 - val_loss: 1.3165 - val_accuracy: 0.5104\n",
      "Epoch 144/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7838 - accuracy: 0.7109 - val_loss: 1.3391 - val_accuracy: 0.5417\n",
      "Epoch 145/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7970 - accuracy: 0.7188 - val_loss: 1.2088 - val_accuracy: 0.5703\n",
      "Epoch 146/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7942 - accuracy: 0.7044 - val_loss: 1.3544 - val_accuracy: 0.5156\n",
      "Epoch 147/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7849 - accuracy: 0.7103 - val_loss: 1.2272 - val_accuracy: 0.5885\n",
      "Epoch 148/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7803 - accuracy: 0.7161 - val_loss: 1.3919 - val_accuracy: 0.5052\n",
      "Epoch 149/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7547 - accuracy: 0.7207 - val_loss: 1.2974 - val_accuracy: 0.5495\n",
      "Epoch 150/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7429 - accuracy: 0.7350 - val_loss: 1.3841 - val_accuracy: 0.4922\n",
      "Epoch 151/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7463 - accuracy: 0.7402 - val_loss: 1.2489 - val_accuracy: 0.5807\n",
      "Epoch 152/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7552 - accuracy: 0.7298 - val_loss: 1.2645 - val_accuracy: 0.5365\n",
      "Epoch 153/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7338 - accuracy: 0.7253 - val_loss: 1.3052 - val_accuracy: 0.5599\n",
      "Epoch 154/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7424 - accuracy: 0.7331 - val_loss: 1.2618 - val_accuracy: 0.5260\n",
      "Epoch 155/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7288 - accuracy: 0.7402 - val_loss: 1.2434 - val_accuracy: 0.5573\n",
      "Epoch 156/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7453 - accuracy: 0.7214 - val_loss: 1.2030 - val_accuracy: 0.5755\n",
      "Epoch 157/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7247 - accuracy: 0.7461 - val_loss: 1.3066 - val_accuracy: 0.5547\n",
      "Epoch 158/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7356 - accuracy: 0.7409 - val_loss: 1.2315 - val_accuracy: 0.5651\n",
      "Epoch 159/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7243 - accuracy: 0.7370 - val_loss: 1.2114 - val_accuracy: 0.5599\n",
      "Epoch 160/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7001 - accuracy: 0.7507 - val_loss: 1.2215 - val_accuracy: 0.5807\n",
      "Epoch 161/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7153 - accuracy: 0.7487 - val_loss: 1.1764 - val_accuracy: 0.6016\n",
      "Epoch 162/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7072 - accuracy: 0.7441 - val_loss: 1.2839 - val_accuracy: 0.5495\n",
      "Epoch 163/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.7068 - accuracy: 0.7480 - val_loss: 1.2250 - val_accuracy: 0.5651\n",
      "Epoch 164/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6978 - accuracy: 0.7467 - val_loss: 1.3351 - val_accuracy: 0.5312\n",
      "Epoch 165/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6881 - accuracy: 0.7559 - val_loss: 1.2103 - val_accuracy: 0.5807\n",
      "Epoch 166/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6943 - accuracy: 0.7454 - val_loss: 1.1948 - val_accuracy: 0.5833\n",
      "Epoch 167/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6848 - accuracy: 0.7526 - val_loss: 1.2779 - val_accuracy: 0.5781\n",
      "Epoch 168/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6679 - accuracy: 0.7559 - val_loss: 1.2800 - val_accuracy: 0.5573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6785 - accuracy: 0.7611 - val_loss: 1.2954 - val_accuracy: 0.5547\n",
      "Epoch 170/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6795 - accuracy: 0.7598 - val_loss: 1.2074 - val_accuracy: 0.5677\n",
      "Epoch 171/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6739 - accuracy: 0.7643 - val_loss: 1.2850 - val_accuracy: 0.5807\n",
      "Epoch 172/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6554 - accuracy: 0.7637 - val_loss: 1.2562 - val_accuracy: 0.5599\n",
      "Epoch 173/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6580 - accuracy: 0.7598 - val_loss: 1.1750 - val_accuracy: 0.6016\n",
      "Epoch 174/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6539 - accuracy: 0.7624 - val_loss: 1.2944 - val_accuracy: 0.5599\n",
      "Epoch 175/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6352 - accuracy: 0.7786 - val_loss: 1.2484 - val_accuracy: 0.5755\n",
      "Epoch 176/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6663 - accuracy: 0.7676 - val_loss: 1.2109 - val_accuracy: 0.5885\n",
      "Epoch 177/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6640 - accuracy: 0.7650 - val_loss: 1.2402 - val_accuracy: 0.5755\n",
      "Epoch 178/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6359 - accuracy: 0.7715 - val_loss: 1.2141 - val_accuracy: 0.5755\n",
      "Epoch 179/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6463 - accuracy: 0.7591 - val_loss: 1.3516 - val_accuracy: 0.5625\n",
      "Epoch 180/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6371 - accuracy: 0.7741 - val_loss: 1.1996 - val_accuracy: 0.6146\n",
      "Epoch 181/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5984 - accuracy: 0.7865 - val_loss: 1.2228 - val_accuracy: 0.5833\n",
      "Epoch 182/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6058 - accuracy: 0.7943 - val_loss: 1.3156 - val_accuracy: 0.5573\n",
      "Epoch 183/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6142 - accuracy: 0.7910 - val_loss: 1.2646 - val_accuracy: 0.5938\n",
      "Epoch 184/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6307 - accuracy: 0.7708 - val_loss: 1.2340 - val_accuracy: 0.6016\n",
      "Epoch 185/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6172 - accuracy: 0.7884 - val_loss: 1.2527 - val_accuracy: 0.5495\n",
      "Epoch 186/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6050 - accuracy: 0.7819 - val_loss: 1.2336 - val_accuracy: 0.5859\n",
      "Epoch 187/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6232 - accuracy: 0.7747 - val_loss: 1.2118 - val_accuracy: 0.5911\n",
      "Epoch 188/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6007 - accuracy: 0.7799 - val_loss: 1.3597 - val_accuracy: 0.5417\n",
      "Epoch 189/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6069 - accuracy: 0.7773 - val_loss: 1.1670 - val_accuracy: 0.5807\n",
      "Epoch 190/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5901 - accuracy: 0.7910 - val_loss: 1.2436 - val_accuracy: 0.5573\n",
      "Epoch 191/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.6014 - accuracy: 0.7852 - val_loss: 1.2604 - val_accuracy: 0.5677\n",
      "Epoch 192/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5874 - accuracy: 0.8027 - val_loss: 1.3795 - val_accuracy: 0.5286\n",
      "Epoch 193/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5962 - accuracy: 0.7858 - val_loss: 1.2343 - val_accuracy: 0.5833\n",
      "Epoch 194/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5966 - accuracy: 0.7773 - val_loss: 1.2754 - val_accuracy: 0.5703\n",
      "Epoch 195/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5932 - accuracy: 0.7943 - val_loss: 1.2342 - val_accuracy: 0.5625\n",
      "Epoch 196/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5734 - accuracy: 0.7982 - val_loss: 1.3262 - val_accuracy: 0.5443\n",
      "Epoch 197/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5734 - accuracy: 0.7995 - val_loss: 1.2205 - val_accuracy: 0.5807\n",
      "Epoch 198/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5798 - accuracy: 0.7917 - val_loss: 1.2518 - val_accuracy: 0.5651\n",
      "Epoch 199/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5574 - accuracy: 0.7923 - val_loss: 1.2894 - val_accuracy: 0.5729\n",
      "Epoch 200/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5578 - accuracy: 0.8066 - val_loss: 1.2811 - val_accuracy: 0.5781\n",
      "Epoch 201/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5547 - accuracy: 0.8008 - val_loss: 1.3350 - val_accuracy: 0.5495\n",
      "Epoch 202/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5800 - accuracy: 0.7949 - val_loss: 1.2425 - val_accuracy: 0.5781\n",
      "Epoch 203/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5513 - accuracy: 0.8073 - val_loss: 1.2473 - val_accuracy: 0.6042\n",
      "Epoch 204/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5380 - accuracy: 0.8008 - val_loss: 1.1970 - val_accuracy: 0.6042\n",
      "Epoch 205/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5473 - accuracy: 0.8040 - val_loss: 1.1929 - val_accuracy: 0.5964\n",
      "Epoch 206/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5451 - accuracy: 0.7975 - val_loss: 1.2219 - val_accuracy: 0.6042\n",
      "Epoch 207/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5379 - accuracy: 0.8118 - val_loss: 1.2777 - val_accuracy: 0.5729\n",
      "Epoch 208/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5238 - accuracy: 0.8164 - val_loss: 1.2435 - val_accuracy: 0.5990\n",
      "Epoch 209/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5394 - accuracy: 0.8125 - val_loss: 1.2876 - val_accuracy: 0.5885\n",
      "Epoch 210/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5298 - accuracy: 0.8118 - val_loss: 1.3645 - val_accuracy: 0.5286\n",
      "Epoch 211/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5383 - accuracy: 0.8021 - val_loss: 1.3587 - val_accuracy: 0.5781\n",
      "Epoch 212/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5168 - accuracy: 0.8151 - val_loss: 1.2458 - val_accuracy: 0.6016\n",
      "Epoch 213/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5300 - accuracy: 0.8138 - val_loss: 1.2822 - val_accuracy: 0.5755\n",
      "Epoch 214/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5187 - accuracy: 0.8210 - val_loss: 1.1640 - val_accuracy: 0.6094\n",
      "Epoch 215/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5072 - accuracy: 0.8242 - val_loss: 1.3402 - val_accuracy: 0.5547\n",
      "Epoch 216/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4991 - accuracy: 0.8151 - val_loss: 1.2051 - val_accuracy: 0.6042\n",
      "Epoch 217/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5165 - accuracy: 0.8275 - val_loss: 1.2152 - val_accuracy: 0.6120\n",
      "Epoch 218/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5055 - accuracy: 0.8268 - val_loss: 1.2131 - val_accuracy: 0.5938\n",
      "Epoch 219/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4964 - accuracy: 0.8314 - val_loss: 1.2735 - val_accuracy: 0.5729\n",
      "Epoch 220/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4937 - accuracy: 0.8294 - val_loss: 1.3351 - val_accuracy: 0.5807\n",
      "Epoch 221/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.5028 - accuracy: 0.8236 - val_loss: 1.2289 - val_accuracy: 0.5938\n",
      "Epoch 222/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4861 - accuracy: 0.8288 - val_loss: 1.2795 - val_accuracy: 0.5729\n",
      "Epoch 223/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4792 - accuracy: 0.8333 - val_loss: 1.2181 - val_accuracy: 0.5938\n",
      "Epoch 224/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4743 - accuracy: 0.8327 - val_loss: 1.2992 - val_accuracy: 0.5781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4717 - accuracy: 0.8405 - val_loss: 1.3012 - val_accuracy: 0.5729\n",
      "Epoch 226/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4529 - accuracy: 0.8444 - val_loss: 1.4003 - val_accuracy: 0.5599\n",
      "Epoch 227/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4726 - accuracy: 0.8366 - val_loss: 1.3303 - val_accuracy: 0.5859\n",
      "Epoch 228/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4818 - accuracy: 0.8268 - val_loss: 1.2298 - val_accuracy: 0.6094\n",
      "Epoch 229/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4579 - accuracy: 0.8301 - val_loss: 1.3086 - val_accuracy: 0.5807\n",
      "Epoch 230/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4578 - accuracy: 0.8418 - val_loss: 1.2749 - val_accuracy: 0.5885\n",
      "Epoch 231/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4562 - accuracy: 0.8320 - val_loss: 1.2567 - val_accuracy: 0.5964\n",
      "Epoch 232/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4511 - accuracy: 0.8464 - val_loss: 1.2986 - val_accuracy: 0.6016\n",
      "Epoch 233/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4640 - accuracy: 0.8372 - val_loss: 1.4067 - val_accuracy: 0.5781\n",
      "Epoch 234/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4369 - accuracy: 0.8470 - val_loss: 1.6037 - val_accuracy: 0.5443\n",
      "Epoch 235/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4625 - accuracy: 0.8353 - val_loss: 1.2776 - val_accuracy: 0.6094\n",
      "Epoch 236/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4475 - accuracy: 0.8483 - val_loss: 1.2447 - val_accuracy: 0.5911\n",
      "Epoch 237/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4601 - accuracy: 0.8320 - val_loss: 1.2847 - val_accuracy: 0.5859\n",
      "Epoch 238/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4522 - accuracy: 0.8451 - val_loss: 1.3187 - val_accuracy: 0.5938\n",
      "Epoch 239/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4344 - accuracy: 0.8490 - val_loss: 1.1979 - val_accuracy: 0.6120\n",
      "Epoch 240/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4429 - accuracy: 0.8470 - val_loss: 1.2468 - val_accuracy: 0.6146\n",
      "Epoch 241/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4151 - accuracy: 0.8490 - val_loss: 1.3438 - val_accuracy: 0.5755\n",
      "Epoch 242/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4364 - accuracy: 0.8464 - val_loss: 1.4264 - val_accuracy: 0.5573\n",
      "Epoch 243/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4070 - accuracy: 0.8587 - val_loss: 1.2480 - val_accuracy: 0.5911\n",
      "Epoch 244/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4210 - accuracy: 0.8457 - val_loss: 1.2328 - val_accuracy: 0.5911\n",
      "Epoch 245/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4095 - accuracy: 0.8613 - val_loss: 1.2031 - val_accuracy: 0.6224\n",
      "Epoch 246/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4124 - accuracy: 0.8626 - val_loss: 1.2803 - val_accuracy: 0.6172\n",
      "Epoch 247/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4190 - accuracy: 0.8581 - val_loss: 1.2217 - val_accuracy: 0.6094\n",
      "Epoch 248/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4044 - accuracy: 0.8555 - val_loss: 1.6474 - val_accuracy: 0.5495\n",
      "Epoch 249/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4080 - accuracy: 0.8600 - val_loss: 1.3927 - val_accuracy: 0.5677\n",
      "Epoch 250/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4045 - accuracy: 0.8587 - val_loss: 1.2831 - val_accuracy: 0.5781\n",
      "Epoch 251/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4255 - accuracy: 0.8535 - val_loss: 1.3725 - val_accuracy: 0.5729\n",
      "Epoch 252/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.4042 - accuracy: 0.8548 - val_loss: 1.3290 - val_accuracy: 0.5859\n",
      "Epoch 253/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3971 - accuracy: 0.8711 - val_loss: 1.3173 - val_accuracy: 0.5885\n",
      "Epoch 254/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3987 - accuracy: 0.8613 - val_loss: 1.2207 - val_accuracy: 0.6120\n",
      "Epoch 255/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3933 - accuracy: 0.8672 - val_loss: 1.3737 - val_accuracy: 0.5885\n",
      "Epoch 256/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3869 - accuracy: 0.8522 - val_loss: 1.4039 - val_accuracy: 0.5651\n",
      "Epoch 257/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3959 - accuracy: 0.8613 - val_loss: 1.2522 - val_accuracy: 0.6172\n",
      "Epoch 258/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3719 - accuracy: 0.8730 - val_loss: 1.2904 - val_accuracy: 0.6068\n",
      "Epoch 259/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3882 - accuracy: 0.8607 - val_loss: 1.2925 - val_accuracy: 0.6146\n",
      "Epoch 260/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3665 - accuracy: 0.8698 - val_loss: 1.3279 - val_accuracy: 0.5755\n",
      "Epoch 261/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3673 - accuracy: 0.8757 - val_loss: 1.4598 - val_accuracy: 0.5807\n",
      "Epoch 262/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3776 - accuracy: 0.8607 - val_loss: 1.4552 - val_accuracy: 0.5599\n",
      "Epoch 263/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3855 - accuracy: 0.8639 - val_loss: 1.2390 - val_accuracy: 0.6276\n",
      "Epoch 264/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3695 - accuracy: 0.8691 - val_loss: 1.2414 - val_accuracy: 0.6146\n",
      "Epoch 265/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3595 - accuracy: 0.8639 - val_loss: 1.4379 - val_accuracy: 0.5573\n",
      "Epoch 266/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3520 - accuracy: 0.8796 - val_loss: 1.2763 - val_accuracy: 0.6302\n",
      "Epoch 267/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3599 - accuracy: 0.8724 - val_loss: 1.3411 - val_accuracy: 0.6250\n",
      "Epoch 268/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3735 - accuracy: 0.8626 - val_loss: 1.3050 - val_accuracy: 0.6146\n",
      "Epoch 269/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3699 - accuracy: 0.8672 - val_loss: 1.2111 - val_accuracy: 0.6276\n",
      "Epoch 270/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3534 - accuracy: 0.8815 - val_loss: 1.4414 - val_accuracy: 0.5885\n",
      "Epoch 271/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3485 - accuracy: 0.8783 - val_loss: 1.2527 - val_accuracy: 0.5938\n",
      "Epoch 272/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3522 - accuracy: 0.8750 - val_loss: 1.2605 - val_accuracy: 0.6302\n",
      "Epoch 273/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3479 - accuracy: 0.8783 - val_loss: 1.2540 - val_accuracy: 0.6198\n",
      "Epoch 274/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3482 - accuracy: 0.8802 - val_loss: 1.2869 - val_accuracy: 0.5990\n",
      "Epoch 275/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3470 - accuracy: 0.8796 - val_loss: 1.3345 - val_accuracy: 0.6198\n",
      "Epoch 276/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3403 - accuracy: 0.8867 - val_loss: 1.4399 - val_accuracy: 0.5807\n",
      "Epoch 277/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3348 - accuracy: 0.8854 - val_loss: 1.2045 - val_accuracy: 0.6224\n",
      "Epoch 278/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3361 - accuracy: 0.8893 - val_loss: 1.3827 - val_accuracy: 0.5885\n",
      "Epoch 279/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3243 - accuracy: 0.8776 - val_loss: 1.5978 - val_accuracy: 0.5443\n",
      "Epoch 280/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3281 - accuracy: 0.8900 - val_loss: 1.3535 - val_accuracy: 0.5911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3185 - accuracy: 0.8991 - val_loss: 1.4877 - val_accuracy: 0.5859\n",
      "Epoch 282/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3434 - accuracy: 0.8809 - val_loss: 1.2791 - val_accuracy: 0.6198\n",
      "Epoch 283/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3410 - accuracy: 0.8770 - val_loss: 1.3551 - val_accuracy: 0.5807\n",
      "Epoch 284/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3132 - accuracy: 0.8880 - val_loss: 1.3321 - val_accuracy: 0.5990\n",
      "Epoch 285/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3186 - accuracy: 0.8919 - val_loss: 1.2488 - val_accuracy: 0.6406\n",
      "Epoch 286/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3173 - accuracy: 0.8958 - val_loss: 1.2458 - val_accuracy: 0.6302\n",
      "Epoch 287/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3229 - accuracy: 0.8880 - val_loss: 1.3331 - val_accuracy: 0.5938\n",
      "Epoch 288/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3046 - accuracy: 0.8913 - val_loss: 1.3241 - val_accuracy: 0.6380\n",
      "Epoch 289/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3187 - accuracy: 0.8939 - val_loss: 1.3169 - val_accuracy: 0.6172\n",
      "Epoch 290/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2972 - accuracy: 0.8939 - val_loss: 1.3338 - val_accuracy: 0.6068\n",
      "Epoch 291/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3125 - accuracy: 0.8932 - val_loss: 1.3020 - val_accuracy: 0.6198\n",
      "Epoch 292/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2950 - accuracy: 0.9004 - val_loss: 1.3743 - val_accuracy: 0.6120\n",
      "Epoch 293/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3018 - accuracy: 0.8906 - val_loss: 1.4192 - val_accuracy: 0.5911\n",
      "Epoch 294/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2936 - accuracy: 0.8926 - val_loss: 1.3801 - val_accuracy: 0.5859\n",
      "Epoch 295/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2902 - accuracy: 0.8997 - val_loss: 1.3755 - val_accuracy: 0.5885\n",
      "Epoch 296/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2917 - accuracy: 0.9043 - val_loss: 1.3501 - val_accuracy: 0.5938\n",
      "Epoch 297/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.3082 - accuracy: 0.8880 - val_loss: 1.3924 - val_accuracy: 0.6094\n",
      "Epoch 298/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2847 - accuracy: 0.8965 - val_loss: 1.4173 - val_accuracy: 0.6146\n",
      "Epoch 299/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2967 - accuracy: 0.8971 - val_loss: 1.3526 - val_accuracy: 0.6146\n",
      "Epoch 300/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2839 - accuracy: 0.9102 - val_loss: 1.3251 - val_accuracy: 0.6172\n",
      "Epoch 301/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2936 - accuracy: 0.9023 - val_loss: 1.7998 - val_accuracy: 0.5260\n",
      "Epoch 302/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2835 - accuracy: 0.9095 - val_loss: 1.3855 - val_accuracy: 0.6068\n",
      "Epoch 303/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2932 - accuracy: 0.8945 - val_loss: 1.6027 - val_accuracy: 0.5677\n",
      "Epoch 304/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2780 - accuracy: 0.9036 - val_loss: 1.6223 - val_accuracy: 0.5495\n",
      "Epoch 305/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2824 - accuracy: 0.9069 - val_loss: 1.3841 - val_accuracy: 0.6120\n",
      "Epoch 306/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2803 - accuracy: 0.9069 - val_loss: 1.4171 - val_accuracy: 0.6120\n",
      "Epoch 307/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2626 - accuracy: 0.9108 - val_loss: 1.3670 - val_accuracy: 0.6172\n",
      "Epoch 308/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2855 - accuracy: 0.9004 - val_loss: 1.4224 - val_accuracy: 0.6146\n",
      "Epoch 309/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2812 - accuracy: 0.9036 - val_loss: 1.8762 - val_accuracy: 0.5312\n",
      "Epoch 310/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2789 - accuracy: 0.9062 - val_loss: 1.3272 - val_accuracy: 0.6250\n",
      "Epoch 311/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2577 - accuracy: 0.9108 - val_loss: 1.4346 - val_accuracy: 0.5885\n",
      "Epoch 312/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2638 - accuracy: 0.9128 - val_loss: 1.4349 - val_accuracy: 0.5964\n",
      "Epoch 313/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2551 - accuracy: 0.9108 - val_loss: 1.4601 - val_accuracy: 0.5964\n",
      "Epoch 314/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2693 - accuracy: 0.9108 - val_loss: 1.3509 - val_accuracy: 0.5964\n",
      "Epoch 315/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2535 - accuracy: 0.9082 - val_loss: 1.4107 - val_accuracy: 0.5990\n",
      "Epoch 316/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2609 - accuracy: 0.9160 - val_loss: 1.5020 - val_accuracy: 0.5911\n",
      "Epoch 317/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2527 - accuracy: 0.9193 - val_loss: 1.4217 - val_accuracy: 0.6068\n",
      "Epoch 318/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2624 - accuracy: 0.9095 - val_loss: 1.3768 - val_accuracy: 0.6146\n",
      "Epoch 319/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2411 - accuracy: 0.9180 - val_loss: 1.5173 - val_accuracy: 0.6120\n",
      "Epoch 320/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2372 - accuracy: 0.9225 - val_loss: 1.4909 - val_accuracy: 0.6146\n",
      "Epoch 321/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2369 - accuracy: 0.9173 - val_loss: 1.7622 - val_accuracy: 0.5781\n",
      "Epoch 322/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2482 - accuracy: 0.9154 - val_loss: 1.4596 - val_accuracy: 0.5938\n",
      "Epoch 323/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2537 - accuracy: 0.9056 - val_loss: 1.3045 - val_accuracy: 0.6198\n",
      "Epoch 324/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2419 - accuracy: 0.9193 - val_loss: 1.5594 - val_accuracy: 0.5833\n",
      "Epoch 325/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2414 - accuracy: 0.9134 - val_loss: 1.4485 - val_accuracy: 0.6328\n",
      "Epoch 326/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2307 - accuracy: 0.9212 - val_loss: 1.4108 - val_accuracy: 0.6328\n",
      "Epoch 327/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2438 - accuracy: 0.9199 - val_loss: 1.4373 - val_accuracy: 0.6068\n",
      "Epoch 328/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2483 - accuracy: 0.9154 - val_loss: 1.4311 - val_accuracy: 0.6172\n",
      "Epoch 329/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2418 - accuracy: 0.9141 - val_loss: 1.7162 - val_accuracy: 0.5781\n",
      "Epoch 330/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2416 - accuracy: 0.9219 - val_loss: 1.3946 - val_accuracy: 0.6042\n",
      "Epoch 331/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2303 - accuracy: 0.9251 - val_loss: 1.4594 - val_accuracy: 0.6224\n",
      "Epoch 332/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2364 - accuracy: 0.9147 - val_loss: 1.3924 - val_accuracy: 0.6120\n",
      "Epoch 333/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2358 - accuracy: 0.9238 - val_loss: 1.4762 - val_accuracy: 0.6146\n",
      "Epoch 334/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2307 - accuracy: 0.9160 - val_loss: 1.4894 - val_accuracy: 0.5885\n",
      "Epoch 335/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2035 - accuracy: 0.9323 - val_loss: 1.5199 - val_accuracy: 0.6146\n",
      "Epoch 336/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2247 - accuracy: 0.9193 - val_loss: 1.4295 - val_accuracy: 0.6276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2140 - accuracy: 0.9277 - val_loss: 1.5876 - val_accuracy: 0.6094\n",
      "Epoch 338/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2259 - accuracy: 0.9245 - val_loss: 1.3918 - val_accuracy: 0.6354\n",
      "Epoch 339/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2139 - accuracy: 0.9290 - val_loss: 1.5073 - val_accuracy: 0.6276\n",
      "Epoch 340/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2205 - accuracy: 0.9173 - val_loss: 1.6021 - val_accuracy: 0.6042\n",
      "Epoch 341/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2147 - accuracy: 0.9238 - val_loss: 1.4341 - val_accuracy: 0.6224\n",
      "Epoch 342/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2131 - accuracy: 0.9277 - val_loss: 1.5681 - val_accuracy: 0.6094\n",
      "Epoch 343/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2227 - accuracy: 0.9199 - val_loss: 1.3876 - val_accuracy: 0.6510\n",
      "Epoch 344/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2064 - accuracy: 0.9238 - val_loss: 1.4843 - val_accuracy: 0.6458\n",
      "Epoch 345/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2090 - accuracy: 0.9297 - val_loss: 1.4750 - val_accuracy: 0.6172\n",
      "Epoch 346/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2160 - accuracy: 0.9199 - val_loss: 1.4725 - val_accuracy: 0.6198\n",
      "Epoch 347/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2040 - accuracy: 0.9264 - val_loss: 1.3617 - val_accuracy: 0.6432\n",
      "Epoch 348/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1977 - accuracy: 0.9375 - val_loss: 1.3967 - val_accuracy: 0.6146\n",
      "Epoch 349/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2028 - accuracy: 0.9310 - val_loss: 1.5724 - val_accuracy: 0.5938\n",
      "Epoch 350/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1947 - accuracy: 0.9368 - val_loss: 1.6534 - val_accuracy: 0.6120\n",
      "Epoch 351/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1964 - accuracy: 0.9375 - val_loss: 1.5236 - val_accuracy: 0.6120\n",
      "Epoch 352/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1943 - accuracy: 0.9349 - val_loss: 1.6030 - val_accuracy: 0.6068\n",
      "Epoch 353/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1908 - accuracy: 0.9382 - val_loss: 1.5379 - val_accuracy: 0.6146\n",
      "Epoch 354/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2034 - accuracy: 0.9258 - val_loss: 1.7485 - val_accuracy: 0.5521\n",
      "Epoch 355/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1864 - accuracy: 0.9401 - val_loss: 1.4353 - val_accuracy: 0.6250\n",
      "Epoch 356/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2152 - accuracy: 0.9316 - val_loss: 1.5297 - val_accuracy: 0.6016\n",
      "Epoch 357/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2008 - accuracy: 0.9310 - val_loss: 1.4172 - val_accuracy: 0.6354\n",
      "Epoch 358/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.2043 - accuracy: 0.9342 - val_loss: 1.5719 - val_accuracy: 0.6094\n",
      "Epoch 359/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1960 - accuracy: 0.9408 - val_loss: 1.5685 - val_accuracy: 0.6224\n",
      "Epoch 360/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1942 - accuracy: 0.9349 - val_loss: 1.4738 - val_accuracy: 0.6172\n",
      "Epoch 361/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1698 - accuracy: 0.9401 - val_loss: 1.4674 - val_accuracy: 0.6406\n",
      "Epoch 362/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1738 - accuracy: 0.9408 - val_loss: 1.4942 - val_accuracy: 0.6380\n",
      "Epoch 363/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1828 - accuracy: 0.9336 - val_loss: 1.5553 - val_accuracy: 0.6094\n",
      "Epoch 364/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1729 - accuracy: 0.9499 - val_loss: 1.5877 - val_accuracy: 0.6042\n",
      "Epoch 365/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1814 - accuracy: 0.9414 - val_loss: 1.6369 - val_accuracy: 0.6146\n",
      "Epoch 366/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1901 - accuracy: 0.9310 - val_loss: 1.4598 - val_accuracy: 0.6380\n",
      "Epoch 367/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1795 - accuracy: 0.9329 - val_loss: 1.6836 - val_accuracy: 0.6016\n",
      "Epoch 368/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1730 - accuracy: 0.9395 - val_loss: 1.5356 - val_accuracy: 0.6354\n",
      "Epoch 369/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1916 - accuracy: 0.9368 - val_loss: 1.4024 - val_accuracy: 0.6406\n",
      "Epoch 370/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1789 - accuracy: 0.9447 - val_loss: 1.4998 - val_accuracy: 0.6302\n",
      "Epoch 371/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1924 - accuracy: 0.9290 - val_loss: 1.4037 - val_accuracy: 0.6536\n",
      "Epoch 372/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1796 - accuracy: 0.9375 - val_loss: 1.8587 - val_accuracy: 0.5755\n",
      "Epoch 373/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1815 - accuracy: 0.9414 - val_loss: 1.5344 - val_accuracy: 0.6094\n",
      "Epoch 374/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1750 - accuracy: 0.9368 - val_loss: 1.6781 - val_accuracy: 0.6120\n",
      "Epoch 375/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1682 - accuracy: 0.9414 - val_loss: 1.5618 - val_accuracy: 0.6328\n",
      "Epoch 376/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1866 - accuracy: 0.9414 - val_loss: 1.6093 - val_accuracy: 0.6328\n",
      "Epoch 377/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1688 - accuracy: 0.9479 - val_loss: 1.7334 - val_accuracy: 0.6172\n",
      "Epoch 378/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1745 - accuracy: 0.9440 - val_loss: 1.5804 - val_accuracy: 0.6328\n",
      "Epoch 379/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1609 - accuracy: 0.9473 - val_loss: 1.6418 - val_accuracy: 0.6198\n",
      "Epoch 380/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1608 - accuracy: 0.9447 - val_loss: 1.6362 - val_accuracy: 0.6094\n",
      "Epoch 381/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1703 - accuracy: 0.9375 - val_loss: 1.5833 - val_accuracy: 0.6172\n",
      "Epoch 382/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1589 - accuracy: 0.9427 - val_loss: 1.4988 - val_accuracy: 0.6432\n",
      "Epoch 383/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1424 - accuracy: 0.9642 - val_loss: 1.5421 - val_accuracy: 0.6198\n",
      "Epoch 384/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1578 - accuracy: 0.9518 - val_loss: 1.7077 - val_accuracy: 0.6042\n",
      "Epoch 385/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1482 - accuracy: 0.9479 - val_loss: 1.5812 - val_accuracy: 0.6250\n",
      "Epoch 386/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1710 - accuracy: 0.9427 - val_loss: 1.7517 - val_accuracy: 0.6016\n",
      "Epoch 387/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1688 - accuracy: 0.9401 - val_loss: 1.5917 - val_accuracy: 0.6250\n",
      "Epoch 388/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1647 - accuracy: 0.9427 - val_loss: 1.4807 - val_accuracy: 0.6172\n",
      "Epoch 389/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1546 - accuracy: 0.9544 - val_loss: 1.5524 - val_accuracy: 0.6302\n",
      "Epoch 390/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1557 - accuracy: 0.9486 - val_loss: 1.8983 - val_accuracy: 0.5677\n",
      "Epoch 391/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1582 - accuracy: 0.9486 - val_loss: 1.6648 - val_accuracy: 0.6250\n",
      "Epoch 392/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1396 - accuracy: 0.9531 - val_loss: 1.7525 - val_accuracy: 0.5703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1470 - accuracy: 0.9479 - val_loss: 1.5778 - val_accuracy: 0.6250\n",
      "Epoch 394/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1406 - accuracy: 0.9499 - val_loss: 1.5594 - val_accuracy: 0.6224\n",
      "Epoch 395/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1642 - accuracy: 0.9466 - val_loss: 1.5649 - val_accuracy: 0.6380\n",
      "Epoch 396/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1536 - accuracy: 0.9518 - val_loss: 1.7893 - val_accuracy: 0.6042\n",
      "Epoch 397/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1456 - accuracy: 0.9512 - val_loss: 1.5581 - val_accuracy: 0.6380\n",
      "Epoch 398/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1517 - accuracy: 0.9466 - val_loss: 1.7257 - val_accuracy: 0.6068\n",
      "Epoch 399/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1313 - accuracy: 0.9557 - val_loss: 1.9414 - val_accuracy: 0.5911\n",
      "Epoch 400/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1587 - accuracy: 0.9414 - val_loss: 1.6635 - val_accuracy: 0.6146\n",
      "Epoch 401/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1351 - accuracy: 0.9518 - val_loss: 1.6931 - val_accuracy: 0.6068\n",
      "Epoch 402/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1313 - accuracy: 0.9590 - val_loss: 1.6469 - val_accuracy: 0.6302\n",
      "Epoch 403/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1398 - accuracy: 0.9492 - val_loss: 1.7427 - val_accuracy: 0.5990\n",
      "Epoch 404/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1420 - accuracy: 0.9479 - val_loss: 1.5797 - val_accuracy: 0.6328\n",
      "Epoch 405/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1405 - accuracy: 0.9531 - val_loss: 1.6015 - val_accuracy: 0.6458\n",
      "Epoch 406/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1257 - accuracy: 0.9629 - val_loss: 1.6680 - val_accuracy: 0.6302\n",
      "Epoch 407/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1407 - accuracy: 0.9603 - val_loss: 1.5231 - val_accuracy: 0.6510\n",
      "Epoch 408/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1265 - accuracy: 0.9590 - val_loss: 1.6941 - val_accuracy: 0.6094\n",
      "Epoch 409/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1302 - accuracy: 0.9616 - val_loss: 1.7749 - val_accuracy: 0.6146\n",
      "Epoch 410/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1265 - accuracy: 0.9564 - val_loss: 1.6591 - val_accuracy: 0.6302\n",
      "Epoch 411/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1333 - accuracy: 0.9577 - val_loss: 1.5526 - val_accuracy: 0.6380\n",
      "Epoch 412/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1280 - accuracy: 0.9531 - val_loss: 1.7334 - val_accuracy: 0.6094\n",
      "Epoch 413/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1432 - accuracy: 0.9544 - val_loss: 1.5554 - val_accuracy: 0.6354\n",
      "Epoch 414/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1190 - accuracy: 0.9622 - val_loss: 1.6821 - val_accuracy: 0.6016\n",
      "Epoch 415/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1397 - accuracy: 0.9551 - val_loss: 1.6819 - val_accuracy: 0.6250\n",
      "Epoch 416/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1236 - accuracy: 0.9557 - val_loss: 1.7694 - val_accuracy: 0.5990\n",
      "Epoch 417/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1229 - accuracy: 0.9596 - val_loss: 1.6848 - val_accuracy: 0.6250\n",
      "Epoch 418/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1214 - accuracy: 0.9583 - val_loss: 1.6621 - val_accuracy: 0.6224\n",
      "Epoch 419/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1267 - accuracy: 0.9557 - val_loss: 2.0081 - val_accuracy: 0.5859\n",
      "Epoch 420/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1425 - accuracy: 0.9557 - val_loss: 1.7170 - val_accuracy: 0.5990\n",
      "Epoch 421/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1181 - accuracy: 0.9596 - val_loss: 1.6228 - val_accuracy: 0.6458\n",
      "Epoch 422/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1331 - accuracy: 0.9544 - val_loss: 1.6049 - val_accuracy: 0.6380\n",
      "Epoch 423/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1310 - accuracy: 0.9538 - val_loss: 1.7550 - val_accuracy: 0.6276\n",
      "Epoch 424/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1092 - accuracy: 0.9609 - val_loss: 1.5941 - val_accuracy: 0.6198\n",
      "Epoch 425/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1234 - accuracy: 0.9590 - val_loss: 1.9392 - val_accuracy: 0.5781\n",
      "Epoch 426/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1306 - accuracy: 0.9622 - val_loss: 1.9187 - val_accuracy: 0.5938\n",
      "Epoch 427/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1182 - accuracy: 0.9609 - val_loss: 1.7668 - val_accuracy: 0.6068\n",
      "Epoch 428/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1125 - accuracy: 0.9622 - val_loss: 1.8251 - val_accuracy: 0.6094\n",
      "Epoch 429/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1101 - accuracy: 0.9674 - val_loss: 1.6140 - val_accuracy: 0.6432\n",
      "Epoch 430/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1118 - accuracy: 0.9655 - val_loss: 1.9218 - val_accuracy: 0.6120\n",
      "Epoch 431/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1182 - accuracy: 0.9557 - val_loss: 1.6133 - val_accuracy: 0.6458\n",
      "Epoch 432/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1203 - accuracy: 0.9635 - val_loss: 1.7332 - val_accuracy: 0.6380\n",
      "Epoch 433/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1217 - accuracy: 0.9551 - val_loss: 1.7077 - val_accuracy: 0.6354\n",
      "Epoch 434/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1125 - accuracy: 0.9655 - val_loss: 1.7178 - val_accuracy: 0.6302\n",
      "Epoch 435/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1177 - accuracy: 0.9544 - val_loss: 1.7257 - val_accuracy: 0.6354\n",
      "Epoch 436/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1089 - accuracy: 0.9655 - val_loss: 1.8127 - val_accuracy: 0.6354\n",
      "Epoch 437/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1002 - accuracy: 0.9720 - val_loss: 2.2966 - val_accuracy: 0.5859\n",
      "Epoch 438/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1054 - accuracy: 0.9681 - val_loss: 1.9179 - val_accuracy: 0.5990\n",
      "Epoch 439/700\n",
      "1536/1536 [==============================] - 2s 2ms/step - loss: 0.1159 - accuracy: 0.9590 - val_loss: 1.7229 - val_accuracy: 0.6380\n",
      "Epoch 440/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1104 - accuracy: 0.9635 - val_loss: 1.8861 - val_accuracy: 0.5938\n",
      "Epoch 441/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1007 - accuracy: 0.9694 - val_loss: 1.8119 - val_accuracy: 0.6250\n",
      "Epoch 442/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1125 - accuracy: 0.9577 - val_loss: 1.6776 - val_accuracy: 0.6198\n",
      "Epoch 443/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1174 - accuracy: 0.9661 - val_loss: 1.6588 - val_accuracy: 0.6354\n",
      "Epoch 444/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1115 - accuracy: 0.9616 - val_loss: 1.6948 - val_accuracy: 0.6068\n",
      "Epoch 445/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1183 - accuracy: 0.9596 - val_loss: 1.7531 - val_accuracy: 0.6120\n",
      "Epoch 446/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1217 - accuracy: 0.9622 - val_loss: 1.7339 - val_accuracy: 0.6276\n",
      "Epoch 447/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0960 - accuracy: 0.9668 - val_loss: 1.8094 - val_accuracy: 0.6302\n",
      "Epoch 448/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1036 - accuracy: 0.9714 - val_loss: 1.6669 - val_accuracy: 0.6458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0916 - accuracy: 0.9668 - val_loss: 1.7297 - val_accuracy: 0.6406\n",
      "Epoch 450/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1063 - accuracy: 0.9642 - val_loss: 1.8263 - val_accuracy: 0.6198\n",
      "Epoch 451/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0991 - accuracy: 0.9661 - val_loss: 1.8611 - val_accuracy: 0.6432\n",
      "Epoch 452/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0984 - accuracy: 0.9668 - val_loss: 1.6636 - val_accuracy: 0.6250\n",
      "Epoch 453/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1105 - accuracy: 0.9668 - val_loss: 1.6809 - val_accuracy: 0.6276\n",
      "Epoch 454/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0889 - accuracy: 0.9766 - val_loss: 1.9725 - val_accuracy: 0.6094\n",
      "Epoch 455/700\n",
      "1536/1536 [==============================] - 3s 2ms/step - loss: 0.1077 - accuracy: 0.9609 - val_loss: 1.6657 - val_accuracy: 0.6458\n",
      "Epoch 456/700\n",
      "1536/1536 [==============================] - 5s 3ms/step - loss: 0.1026 - accuracy: 0.9694 - val_loss: 1.7302 - val_accuracy: 0.6302\n",
      "Epoch 457/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0872 - accuracy: 0.9720 - val_loss: 1.7843 - val_accuracy: 0.6432\n",
      "Epoch 458/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1055 - accuracy: 0.9642 - val_loss: 1.7934 - val_accuracy: 0.6458\n",
      "Epoch 459/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0989 - accuracy: 0.9707 - val_loss: 1.8642 - val_accuracy: 0.6354\n",
      "Epoch 460/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1029 - accuracy: 0.9655 - val_loss: 2.2262 - val_accuracy: 0.5755\n",
      "Epoch 461/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0976 - accuracy: 0.9701 - val_loss: 1.8210 - val_accuracy: 0.6224\n",
      "Epoch 462/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0812 - accuracy: 0.9714 - val_loss: 2.0362 - val_accuracy: 0.6172\n",
      "Epoch 463/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0980 - accuracy: 0.9674 - val_loss: 1.8202 - val_accuracy: 0.6328\n",
      "Epoch 464/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1056 - accuracy: 0.9603 - val_loss: 1.6941 - val_accuracy: 0.6328\n",
      "Epoch 465/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1076 - accuracy: 0.9629 - val_loss: 1.5933 - val_accuracy: 0.6510\n",
      "Epoch 466/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0948 - accuracy: 0.9694 - val_loss: 1.9877 - val_accuracy: 0.6224\n",
      "Epoch 467/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0962 - accuracy: 0.9635 - val_loss: 2.4042 - val_accuracy: 0.5677\n",
      "Epoch 468/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0837 - accuracy: 0.9746 - val_loss: 1.8397 - val_accuracy: 0.6302\n",
      "Epoch 469/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0871 - accuracy: 0.9759 - val_loss: 2.0001 - val_accuracy: 0.6224\n",
      "Epoch 470/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0922 - accuracy: 0.9688 - val_loss: 1.8576 - val_accuracy: 0.6380\n",
      "Epoch 471/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0888 - accuracy: 0.9694 - val_loss: 1.7347 - val_accuracy: 0.6458\n",
      "Epoch 472/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0906 - accuracy: 0.9694 - val_loss: 2.4430 - val_accuracy: 0.5885\n",
      "Epoch 473/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0709 - accuracy: 0.9811 - val_loss: 2.2210 - val_accuracy: 0.5573\n",
      "Epoch 474/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0825 - accuracy: 0.9740 - val_loss: 1.8874 - val_accuracy: 0.6172\n",
      "Epoch 475/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0906 - accuracy: 0.9707 - val_loss: 1.7480 - val_accuracy: 0.6276\n",
      "Epoch 476/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0897 - accuracy: 0.9674 - val_loss: 1.8583 - val_accuracy: 0.6250\n",
      "Epoch 477/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0795 - accuracy: 0.9733 - val_loss: 1.7279 - val_accuracy: 0.6589\n",
      "Epoch 478/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0884 - accuracy: 0.9701 - val_loss: 1.9293 - val_accuracy: 0.6380\n",
      "Epoch 479/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0814 - accuracy: 0.9674 - val_loss: 2.0688 - val_accuracy: 0.6146\n",
      "Epoch 480/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0812 - accuracy: 0.9753 - val_loss: 1.7938 - val_accuracy: 0.6380\n",
      "Epoch 481/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0739 - accuracy: 0.9753 - val_loss: 1.9593 - val_accuracy: 0.6016\n",
      "Epoch 482/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0726 - accuracy: 0.9805 - val_loss: 1.7871 - val_accuracy: 0.6406\n",
      "Epoch 483/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0887 - accuracy: 0.9766 - val_loss: 2.0131 - val_accuracy: 0.6198\n",
      "Epoch 484/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0885 - accuracy: 0.9740 - val_loss: 1.8139 - val_accuracy: 0.6380\n",
      "Epoch 485/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0805 - accuracy: 0.9746 - val_loss: 1.7331 - val_accuracy: 0.6328\n",
      "Epoch 486/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0788 - accuracy: 0.9701 - val_loss: 1.7982 - val_accuracy: 0.6354\n",
      "Epoch 487/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0796 - accuracy: 0.9727 - val_loss: 1.8388 - val_accuracy: 0.6458\n",
      "Epoch 488/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0751 - accuracy: 0.9818 - val_loss: 2.7058 - val_accuracy: 0.5573\n",
      "Epoch 489/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0865 - accuracy: 0.9707 - val_loss: 2.0826 - val_accuracy: 0.6068\n",
      "Epoch 490/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0824 - accuracy: 0.9733 - val_loss: 2.1178 - val_accuracy: 0.5911\n",
      "Epoch 491/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0951 - accuracy: 0.9720 - val_loss: 1.8528 - val_accuracy: 0.6224\n",
      "Epoch 492/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0777 - accuracy: 0.9772 - val_loss: 1.9906 - val_accuracy: 0.6146\n",
      "Epoch 493/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0794 - accuracy: 0.9753 - val_loss: 1.9441 - val_accuracy: 0.6120\n",
      "Epoch 494/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0697 - accuracy: 0.9740 - val_loss: 1.9868 - val_accuracy: 0.5911\n",
      "Epoch 495/700\n",
      "1536/1536 [==============================] - 3s 2ms/step - loss: 0.0864 - accuracy: 0.9707 - val_loss: 2.0027 - val_accuracy: 0.6302\n",
      "Epoch 496/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0780 - accuracy: 0.9746 - val_loss: 1.8552 - val_accuracy: 0.6302\n",
      "Epoch 497/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0578 - accuracy: 0.9818 - val_loss: 1.7917 - val_accuracy: 0.6198\n",
      "Epoch 498/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0810 - accuracy: 0.9805 - val_loss: 1.7734 - val_accuracy: 0.6484\n",
      "Epoch 499/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0901 - accuracy: 0.9720 - val_loss: 2.0562 - val_accuracy: 0.6120\n",
      "Epoch 500/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0780 - accuracy: 0.9766 - val_loss: 1.8466 - val_accuracy: 0.6432\n",
      "Epoch 501/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0760 - accuracy: 0.9746 - val_loss: 1.8859 - val_accuracy: 0.6432\n",
      "Epoch 502/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0731 - accuracy: 0.9766 - val_loss: 1.8479 - val_accuracy: 0.6536\n",
      "Epoch 503/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0729 - accuracy: 0.9753 - val_loss: 1.8238 - val_accuracy: 0.6432\n",
      "Epoch 504/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0841 - accuracy: 0.9766 - val_loss: 2.0325 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0797 - accuracy: 0.9720 - val_loss: 2.1615 - val_accuracy: 0.6120\n",
      "Epoch 506/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0748 - accuracy: 0.9785 - val_loss: 1.7968 - val_accuracy: 0.6380\n",
      "Epoch 507/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0741 - accuracy: 0.9785 - val_loss: 1.8133 - val_accuracy: 0.6510\n",
      "Epoch 508/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0738 - accuracy: 0.9772 - val_loss: 1.8483 - val_accuracy: 0.6589\n",
      "Epoch 509/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0672 - accuracy: 0.9818 - val_loss: 2.0909 - val_accuracy: 0.6120\n",
      "Epoch 510/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0641 - accuracy: 0.9779 - val_loss: 1.9317 - val_accuracy: 0.6224\n",
      "Epoch 511/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0729 - accuracy: 0.9779 - val_loss: 1.9404 - val_accuracy: 0.6302\n",
      "Epoch 512/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.1003 - accuracy: 0.9681 - val_loss: 1.8100 - val_accuracy: 0.6536\n",
      "Epoch 513/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0712 - accuracy: 0.9792 - val_loss: 1.8382 - val_accuracy: 0.6406\n",
      "Epoch 514/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0769 - accuracy: 0.9753 - val_loss: 2.1397 - val_accuracy: 0.6172\n",
      "Epoch 515/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0540 - accuracy: 0.9876 - val_loss: 1.7847 - val_accuracy: 0.6510\n",
      "Epoch 516/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0673 - accuracy: 0.9766 - val_loss: 1.9525 - val_accuracy: 0.6328\n",
      "Epoch 517/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0670 - accuracy: 0.9785 - val_loss: 2.2724 - val_accuracy: 0.6016\n",
      "Epoch 518/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0811 - accuracy: 0.9720 - val_loss: 2.1614 - val_accuracy: 0.6094\n",
      "Epoch 519/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0692 - accuracy: 0.9766 - val_loss: 2.2513 - val_accuracy: 0.5911\n",
      "Epoch 520/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0656 - accuracy: 0.9772 - val_loss: 1.9474 - val_accuracy: 0.6354\n",
      "Epoch 521/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0709 - accuracy: 0.9746 - val_loss: 2.4569 - val_accuracy: 0.5859\n",
      "Epoch 522/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0710 - accuracy: 0.9779 - val_loss: 1.8557 - val_accuracy: 0.6510\n",
      "Epoch 523/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0611 - accuracy: 0.9785 - val_loss: 1.9952 - val_accuracy: 0.6406\n",
      "Epoch 524/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0786 - accuracy: 0.9707 - val_loss: 1.9346 - val_accuracy: 0.6302\n",
      "Epoch 525/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0681 - accuracy: 0.9753 - val_loss: 2.2387 - val_accuracy: 0.6224\n",
      "Epoch 526/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0784 - accuracy: 0.9779 - val_loss: 1.8426 - val_accuracy: 0.6380\n",
      "Epoch 527/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0763 - accuracy: 0.9733 - val_loss: 1.8724 - val_accuracy: 0.6458\n",
      "Epoch 528/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0580 - accuracy: 0.9818 - val_loss: 2.0931 - val_accuracy: 0.6198\n",
      "Epoch 529/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0734 - accuracy: 0.9746 - val_loss: 1.9104 - val_accuracy: 0.6302\n",
      "Epoch 530/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0609 - accuracy: 0.9792 - val_loss: 2.0734 - val_accuracy: 0.6068\n",
      "Epoch 531/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0641 - accuracy: 0.9798 - val_loss: 1.9755 - val_accuracy: 0.6302\n",
      "Epoch 532/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0799 - accuracy: 0.9805 - val_loss: 2.1559 - val_accuracy: 0.6016\n",
      "Epoch 533/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0608 - accuracy: 0.9850 - val_loss: 2.0110 - val_accuracy: 0.6198\n",
      "Epoch 534/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0619 - accuracy: 0.9805 - val_loss: 2.3189 - val_accuracy: 0.5990\n",
      "Epoch 535/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0774 - accuracy: 0.9792 - val_loss: 2.0783 - val_accuracy: 0.6250\n",
      "Epoch 536/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0580 - accuracy: 0.9811 - val_loss: 1.8935 - val_accuracy: 0.6458\n",
      "Epoch 537/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0706 - accuracy: 0.9766 - val_loss: 2.3796 - val_accuracy: 0.6042\n",
      "Epoch 538/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0586 - accuracy: 0.9831 - val_loss: 2.0667 - val_accuracy: 0.6432\n",
      "Epoch 539/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0669 - accuracy: 0.9772 - val_loss: 1.9759 - val_accuracy: 0.6510\n",
      "Epoch 540/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0690 - accuracy: 0.9792 - val_loss: 1.9000 - val_accuracy: 0.6458\n",
      "Epoch 541/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0580 - accuracy: 0.9811 - val_loss: 2.1955 - val_accuracy: 0.6224\n",
      "Epoch 542/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0529 - accuracy: 0.9896 - val_loss: 1.9723 - val_accuracy: 0.6432\n",
      "Epoch 543/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0650 - accuracy: 0.9759 - val_loss: 2.1706 - val_accuracy: 0.6198\n",
      "Epoch 544/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0643 - accuracy: 0.9837 - val_loss: 2.0570 - val_accuracy: 0.6224\n",
      "Epoch 545/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0653 - accuracy: 0.9785 - val_loss: 2.0015 - val_accuracy: 0.6615\n",
      "Epoch 546/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0607 - accuracy: 0.9792 - val_loss: 1.9509 - val_accuracy: 0.6354\n",
      "Epoch 547/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0554 - accuracy: 0.9844 - val_loss: 2.0779 - val_accuracy: 0.6562\n",
      "Epoch 548/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0625 - accuracy: 0.9837 - val_loss: 1.9392 - val_accuracy: 0.6562\n",
      "Epoch 549/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0829 - accuracy: 0.9746 - val_loss: 2.0221 - val_accuracy: 0.6094\n",
      "Epoch 550/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0561 - accuracy: 0.9824 - val_loss: 2.1273 - val_accuracy: 0.6198\n",
      "Epoch 551/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0467 - accuracy: 0.9870 - val_loss: 1.9968 - val_accuracy: 0.6484\n",
      "Epoch 552/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0655 - accuracy: 0.9785 - val_loss: 2.1312 - val_accuracy: 0.6432\n",
      "Epoch 553/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0680 - accuracy: 0.9766 - val_loss: 2.1242 - val_accuracy: 0.6042\n",
      "Epoch 554/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0650 - accuracy: 0.9805 - val_loss: 2.0031 - val_accuracy: 0.6536\n",
      "Epoch 555/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0679 - accuracy: 0.9805 - val_loss: 2.0538 - val_accuracy: 0.6484\n",
      "Epoch 556/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0665 - accuracy: 0.9785 - val_loss: 2.1490 - val_accuracy: 0.6302\n",
      "Epoch 557/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0548 - accuracy: 0.9818 - val_loss: 1.9464 - val_accuracy: 0.6484\n",
      "Epoch 558/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0444 - accuracy: 0.9850 - val_loss: 2.1397 - val_accuracy: 0.6172\n",
      "Epoch 559/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0496 - accuracy: 0.9831 - val_loss: 2.0956 - val_accuracy: 0.6406\n",
      "Epoch 560/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0548 - accuracy: 0.9837 - val_loss: 1.9879 - val_accuracy: 0.6536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0486 - accuracy: 0.9850 - val_loss: 1.9733 - val_accuracy: 0.6432\n",
      "Epoch 562/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0617 - accuracy: 0.9746 - val_loss: 2.0100 - val_accuracy: 0.6328\n",
      "Epoch 563/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0516 - accuracy: 0.9824 - val_loss: 2.0320 - val_accuracy: 0.6406\n",
      "Epoch 564/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0498 - accuracy: 0.9850 - val_loss: 2.6517 - val_accuracy: 0.6016\n",
      "Epoch 565/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0586 - accuracy: 0.9831 - val_loss: 2.1702 - val_accuracy: 0.6328\n",
      "Epoch 566/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0516 - accuracy: 0.9857 - val_loss: 2.0334 - val_accuracy: 0.6380\n",
      "Epoch 567/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0418 - accuracy: 0.9857 - val_loss: 1.9606 - val_accuracy: 0.6562\n",
      "Epoch 568/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0575 - accuracy: 0.9837 - val_loss: 2.8667 - val_accuracy: 0.5807\n",
      "Epoch 569/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0594 - accuracy: 0.9792 - val_loss: 1.8714 - val_accuracy: 0.6667\n",
      "Epoch 570/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0589 - accuracy: 0.9811 - val_loss: 2.1934 - val_accuracy: 0.6276\n",
      "Epoch 571/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0528 - accuracy: 0.9863 - val_loss: 2.9327 - val_accuracy: 0.5469\n",
      "Epoch 572/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0617 - accuracy: 0.9772 - val_loss: 2.3790 - val_accuracy: 0.6016\n",
      "Epoch 573/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0578 - accuracy: 0.9824 - val_loss: 2.1583 - val_accuracy: 0.6328\n",
      "Epoch 574/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0538 - accuracy: 0.9831 - val_loss: 2.3074 - val_accuracy: 0.6224\n",
      "Epoch 575/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0705 - accuracy: 0.9785 - val_loss: 2.1251 - val_accuracy: 0.6328\n",
      "Epoch 576/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0569 - accuracy: 0.9824 - val_loss: 2.2135 - val_accuracy: 0.6224\n",
      "Epoch 577/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0503 - accuracy: 0.9818 - val_loss: 2.3498 - val_accuracy: 0.6146\n",
      "Epoch 578/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0556 - accuracy: 0.9831 - val_loss: 2.1092 - val_accuracy: 0.6276\n",
      "Epoch 579/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0416 - accuracy: 0.9883 - val_loss: 2.1290 - val_accuracy: 0.6328\n",
      "Epoch 580/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0832 - accuracy: 0.9766 - val_loss: 2.0988 - val_accuracy: 0.6250\n",
      "Epoch 581/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0431 - accuracy: 0.9883 - val_loss: 2.1892 - val_accuracy: 0.6224\n",
      "Epoch 582/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0585 - accuracy: 0.9857 - val_loss: 2.0293 - val_accuracy: 0.6458\n",
      "Epoch 583/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0509 - accuracy: 0.9837 - val_loss: 1.9886 - val_accuracy: 0.6510\n",
      "Epoch 584/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0568 - accuracy: 0.9831 - val_loss: 2.1888 - val_accuracy: 0.6328\n",
      "Epoch 585/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0617 - accuracy: 0.9811 - val_loss: 2.0406 - val_accuracy: 0.6458\n",
      "Epoch 586/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0479 - accuracy: 0.9883 - val_loss: 2.0645 - val_accuracy: 0.6536\n",
      "Epoch 587/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0544 - accuracy: 0.9837 - val_loss: 2.3868 - val_accuracy: 0.6016\n",
      "Epoch 588/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0583 - accuracy: 0.9837 - val_loss: 2.1990 - val_accuracy: 0.6406\n",
      "Epoch 589/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0511 - accuracy: 0.9850 - val_loss: 2.0759 - val_accuracy: 0.6458\n",
      "Epoch 590/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0677 - accuracy: 0.9772 - val_loss: 2.2310 - val_accuracy: 0.6016\n",
      "Epoch 591/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0395 - accuracy: 0.9876 - val_loss: 2.6775 - val_accuracy: 0.6068\n",
      "Epoch 592/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0548 - accuracy: 0.9831 - val_loss: 2.2702 - val_accuracy: 0.6198\n",
      "Epoch 593/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0463 - accuracy: 0.9831 - val_loss: 2.2559 - val_accuracy: 0.6302\n",
      "Epoch 594/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0467 - accuracy: 0.9857 - val_loss: 2.0948 - val_accuracy: 0.6406\n",
      "Epoch 595/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0558 - accuracy: 0.9811 - val_loss: 2.8976 - val_accuracy: 0.5807\n",
      "Epoch 596/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0474 - accuracy: 0.9876 - val_loss: 2.2944 - val_accuracy: 0.6198\n",
      "Epoch 597/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0478 - accuracy: 0.9831 - val_loss: 2.1886 - val_accuracy: 0.6302\n",
      "Epoch 598/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0507 - accuracy: 0.9837 - val_loss: 2.2451 - val_accuracy: 0.6406\n",
      "Epoch 599/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0430 - accuracy: 0.9844 - val_loss: 2.1917 - val_accuracy: 0.6224\n",
      "Epoch 600/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0531 - accuracy: 0.9850 - val_loss: 2.2729 - val_accuracy: 0.6354\n",
      "Epoch 601/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0484 - accuracy: 0.9844 - val_loss: 2.1195 - val_accuracy: 0.6302\n",
      "Epoch 602/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0688 - accuracy: 0.9805 - val_loss: 2.0534 - val_accuracy: 0.6458\n",
      "Epoch 603/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0530 - accuracy: 0.9870 - val_loss: 2.0943 - val_accuracy: 0.6380\n",
      "Epoch 604/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0494 - accuracy: 0.9876 - val_loss: 2.3184 - val_accuracy: 0.6406\n",
      "Epoch 605/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0430 - accuracy: 0.9883 - val_loss: 2.1806 - val_accuracy: 0.6250\n",
      "Epoch 606/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0371 - accuracy: 0.9883 - val_loss: 2.2159 - val_accuracy: 0.6302\n",
      "Epoch 607/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0596 - accuracy: 0.9766 - val_loss: 2.1400 - val_accuracy: 0.6562\n",
      "Epoch 608/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0351 - accuracy: 0.9863 - val_loss: 2.4919 - val_accuracy: 0.6302\n",
      "Epoch 609/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0548 - accuracy: 0.9811 - val_loss: 2.0804 - val_accuracy: 0.6458\n",
      "Epoch 610/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 3.0691 - val_accuracy: 0.5495\n",
      "Epoch 611/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0587 - accuracy: 0.9824 - val_loss: 2.2238 - val_accuracy: 0.6432\n",
      "Epoch 612/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0523 - accuracy: 0.9844 - val_loss: 2.1599 - val_accuracy: 0.6510\n",
      "Epoch 613/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0596 - accuracy: 0.9824 - val_loss: 2.1681 - val_accuracy: 0.6536\n",
      "Epoch 614/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0535 - accuracy: 0.9870 - val_loss: 2.2848 - val_accuracy: 0.6146\n",
      "Epoch 615/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0535 - accuracy: 0.9863 - val_loss: 2.5383 - val_accuracy: 0.6172\n",
      "Epoch 616/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0466 - accuracy: 0.9844 - val_loss: 2.1633 - val_accuracy: 0.6406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0583 - accuracy: 0.9831 - val_loss: 2.4134 - val_accuracy: 0.6276\n",
      "Epoch 618/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0463 - accuracy: 0.9844 - val_loss: 2.3109 - val_accuracy: 0.6250\n",
      "Epoch 619/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0535 - accuracy: 0.9818 - val_loss: 2.4887 - val_accuracy: 0.6224\n",
      "Epoch 620/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0447 - accuracy: 0.9883 - val_loss: 2.2176 - val_accuracy: 0.6536\n",
      "Epoch 621/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0420 - accuracy: 0.9876 - val_loss: 2.6691 - val_accuracy: 0.6016\n",
      "Epoch 622/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0383 - accuracy: 0.9902 - val_loss: 3.4299 - val_accuracy: 0.5312\n",
      "Epoch 623/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0447 - accuracy: 0.9857 - val_loss: 2.1919 - val_accuracy: 0.6562\n",
      "Epoch 624/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0415 - accuracy: 0.9870 - val_loss: 2.5497 - val_accuracy: 0.6198\n",
      "Epoch 625/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0564 - accuracy: 0.9811 - val_loss: 2.2226 - val_accuracy: 0.6510\n",
      "Epoch 626/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0416 - accuracy: 0.9889 - val_loss: 2.1494 - val_accuracy: 0.6510\n",
      "Epoch 627/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 2.4001 - val_accuracy: 0.6250\n",
      "Epoch 628/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0499 - accuracy: 0.9818 - val_loss: 2.1573 - val_accuracy: 0.6615\n",
      "Epoch 629/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0436 - accuracy: 0.9889 - val_loss: 2.1320 - val_accuracy: 0.6589\n",
      "Epoch 630/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0307 - accuracy: 0.9876 - val_loss: 2.1099 - val_accuracy: 0.6589\n",
      "Epoch 631/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0386 - accuracy: 0.9857 - val_loss: 2.2384 - val_accuracy: 0.6589\n",
      "Epoch 632/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0496 - accuracy: 0.9850 - val_loss: 2.9613 - val_accuracy: 0.5521\n",
      "Epoch 633/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0424 - accuracy: 0.9857 - val_loss: 2.6438 - val_accuracy: 0.6198\n",
      "Epoch 634/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0453 - accuracy: 0.9896 - val_loss: 2.2295 - val_accuracy: 0.6615\n",
      "Epoch 635/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0385 - accuracy: 0.9889 - val_loss: 2.3280 - val_accuracy: 0.6406\n",
      "Epoch 636/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0508 - accuracy: 0.9818 - val_loss: 2.1804 - val_accuracy: 0.6615\n",
      "Epoch 637/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0464 - accuracy: 0.9876 - val_loss: 2.7407 - val_accuracy: 0.6250\n",
      "Epoch 638/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0445 - accuracy: 0.9837 - val_loss: 2.2699 - val_accuracy: 0.6406\n",
      "Epoch 639/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0535 - accuracy: 0.9811 - val_loss: 2.2757 - val_accuracy: 0.6406\n",
      "Epoch 640/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0340 - accuracy: 0.9883 - val_loss: 2.3351 - val_accuracy: 0.6224\n",
      "Epoch 641/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0443 - accuracy: 0.9818 - val_loss: 2.3813 - val_accuracy: 0.6276\n",
      "Epoch 642/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0409 - accuracy: 0.9870 - val_loss: 2.6102 - val_accuracy: 0.6120\n",
      "Epoch 643/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0372 - accuracy: 0.9889 - val_loss: 2.2354 - val_accuracy: 0.6458\n",
      "Epoch 644/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0381 - accuracy: 0.9876 - val_loss: 2.6625 - val_accuracy: 0.6354\n",
      "Epoch 645/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0444 - accuracy: 0.9844 - val_loss: 2.4214 - val_accuracy: 0.6354\n",
      "Epoch 646/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0490 - accuracy: 0.9818 - val_loss: 2.3533 - val_accuracy: 0.6172\n",
      "Epoch 647/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0418 - accuracy: 0.9837 - val_loss: 2.4943 - val_accuracy: 0.6068\n",
      "Epoch 648/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 2.2561 - val_accuracy: 0.6589\n",
      "Epoch 649/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0477 - accuracy: 0.9811 - val_loss: 2.1521 - val_accuracy: 0.6510\n",
      "Epoch 650/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0407 - accuracy: 0.9902 - val_loss: 2.2457 - val_accuracy: 0.6328\n",
      "Epoch 651/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0531 - accuracy: 0.9811 - val_loss: 2.4566 - val_accuracy: 0.6250\n",
      "Epoch 652/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0340 - accuracy: 0.9902 - val_loss: 2.1333 - val_accuracy: 0.6510\n",
      "Epoch 653/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0417 - accuracy: 0.9844 - val_loss: 2.5884 - val_accuracy: 0.6406\n",
      "Epoch 654/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0334 - accuracy: 0.9863 - val_loss: 2.3989 - val_accuracy: 0.6536\n",
      "Epoch 655/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0363 - accuracy: 0.9883 - val_loss: 2.4475 - val_accuracy: 0.6224\n",
      "Epoch 656/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0547 - accuracy: 0.9837 - val_loss: 2.8607 - val_accuracy: 0.5938\n",
      "Epoch 657/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0552 - accuracy: 0.9824 - val_loss: 2.1732 - val_accuracy: 0.6693\n",
      "Epoch 658/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0336 - accuracy: 0.9915 - val_loss: 3.4242 - val_accuracy: 0.5703\n",
      "Epoch 659/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0338 - accuracy: 0.9909 - val_loss: 2.1588 - val_accuracy: 0.6641\n",
      "Epoch 660/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0414 - accuracy: 0.9889 - val_loss: 2.2050 - val_accuracy: 0.6354\n",
      "Epoch 661/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0368 - accuracy: 0.9876 - val_loss: 2.4123 - val_accuracy: 0.6354\n",
      "Epoch 662/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0479 - accuracy: 0.9870 - val_loss: 2.3034 - val_accuracy: 0.6406\n",
      "Epoch 663/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 2.8561 - val_accuracy: 0.6042\n",
      "Epoch 664/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0460 - accuracy: 0.9850 - val_loss: 2.5685 - val_accuracy: 0.6354\n",
      "Epoch 665/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0469 - accuracy: 0.9850 - val_loss: 2.3205 - val_accuracy: 0.6458\n",
      "Epoch 666/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 2.3661 - val_accuracy: 0.6432\n",
      "Epoch 667/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0456 - accuracy: 0.9889 - val_loss: 2.3618 - val_accuracy: 0.6354\n",
      "Epoch 668/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0519 - accuracy: 0.9850 - val_loss: 2.2701 - val_accuracy: 0.6354\n",
      "Epoch 669/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0459 - accuracy: 0.9850 - val_loss: 2.5619 - val_accuracy: 0.5990\n",
      "Epoch 670/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0331 - accuracy: 0.9870 - val_loss: 2.3684 - val_accuracy: 0.6406\n",
      "Epoch 671/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0482 - accuracy: 0.9850 - val_loss: 2.1954 - val_accuracy: 0.6693\n",
      "Epoch 672/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0375 - accuracy: 0.9915 - val_loss: 2.3022 - val_accuracy: 0.6354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0317 - accuracy: 0.9896 - val_loss: 2.4270 - val_accuracy: 0.6250\n",
      "Epoch 674/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0506 - accuracy: 0.9850 - val_loss: 2.3716 - val_accuracy: 0.6380\n",
      "Epoch 675/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0504 - accuracy: 0.9883 - val_loss: 2.3140 - val_accuracy: 0.6406\n",
      "Epoch 676/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0318 - accuracy: 0.9883 - val_loss: 2.3252 - val_accuracy: 0.6484\n",
      "Epoch 677/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 3.1616 - val_accuracy: 0.6068\n",
      "Epoch 678/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 2.6197 - val_accuracy: 0.6302\n",
      "Epoch 679/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0384 - accuracy: 0.9889 - val_loss: 2.3840 - val_accuracy: 0.6224\n",
      "Epoch 680/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0458 - accuracy: 0.9857 - val_loss: 2.3237 - val_accuracy: 0.6536\n",
      "Epoch 681/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0289 - accuracy: 0.9915 - val_loss: 2.3698 - val_accuracy: 0.6536\n",
      "Epoch 682/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0509 - accuracy: 0.9870 - val_loss: 2.5260 - val_accuracy: 0.6276\n",
      "Epoch 683/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0652 - accuracy: 0.9824 - val_loss: 2.6062 - val_accuracy: 0.6354\n",
      "Epoch 684/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0391 - accuracy: 0.9883 - val_loss: 2.7151 - val_accuracy: 0.6224\n",
      "Epoch 685/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0410 - accuracy: 0.9857 - val_loss: 2.2531 - val_accuracy: 0.6484\n",
      "Epoch 686/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0403 - accuracy: 0.9844 - val_loss: 2.4716 - val_accuracy: 0.6146\n",
      "Epoch 687/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0335 - accuracy: 0.9870 - val_loss: 2.5446 - val_accuracy: 0.6302\n",
      "Epoch 688/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0314 - accuracy: 0.9941 - val_loss: 2.5609 - val_accuracy: 0.6328\n",
      "Epoch 689/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0571 - accuracy: 0.9837 - val_loss: 2.4434 - val_accuracy: 0.6224\n",
      "Epoch 690/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0291 - accuracy: 0.9902 - val_loss: 2.4469 - val_accuracy: 0.6615\n",
      "Epoch 691/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0331 - accuracy: 0.9902 - val_loss: 2.4677 - val_accuracy: 0.6302\n",
      "Epoch 692/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0460 - accuracy: 0.9883 - val_loss: 2.5879 - val_accuracy: 0.6328\n",
      "Epoch 693/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 2.3611 - val_accuracy: 0.6406\n",
      "Epoch 694/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0366 - accuracy: 0.9883 - val_loss: 2.4892 - val_accuracy: 0.6302\n",
      "Epoch 695/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0466 - accuracy: 0.9876 - val_loss: 2.3568 - val_accuracy: 0.6458\n",
      "Epoch 696/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0384 - accuracy: 0.9863 - val_loss: 2.5109 - val_accuracy: 0.6328\n",
      "Epoch 697/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0381 - accuracy: 0.9876 - val_loss: 2.4227 - val_accuracy: 0.6198\n",
      "Epoch 698/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0367 - accuracy: 0.9837 - val_loss: 2.5095 - val_accuracy: 0.6302\n",
      "Epoch 699/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0357 - accuracy: 0.9876 - val_loss: 2.3573 - val_accuracy: 0.6641\n",
      "Epoch 700/700\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 0.0374 - accuracy: 0.9909 - val_loss: 2.4830 - val_accuracy: 0.6484\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=50, epochs=700, validation_data=(x_testcnn, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
